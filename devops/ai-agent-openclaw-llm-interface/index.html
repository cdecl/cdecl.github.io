<!doctype html><html lang=en dir=auto data-theme=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>AI 에이전트(OpenClaw 등)의 LLM 인터페이스 구현 및 툴 콜링 기술 개요 | cdeclog</title><meta name=keywords content="ai,agent,openclaw,llm,tool-calling,devops"><meta name=description content="OpenClaw, Claude 데스크톱 앱, 혹은 로컬 기반의 여러 AI 에이전트들은 내부적으로 LLM(대형 언어 모델)과 어떻게 소통하고, 로컬 환경의 도구(Tool)들을 사용할까요? 이 글에서는 에이전트가 LLM과 인터페이스를 맺는 기술적 구현 내용과 핵심 요소들을 살펴봅니다.
1. 지침 파일(agent.md 등) 적용 방법
AI 에이전트의 페르소나, 역할, 기본 규칙을 정의하기 위해 주로 .md 형태의 지침 파일을 사용합니다. (예: agent.md, system_prompt.txt, SOUL.md 등)
기술적 구현:
이러한 지침 파일은 LLM에 전달되는 **시스템 프롬프트(System Prompt)**로 로드됩니다. 에이전트 프로그램이 실행될 때 혹은 세션이 시작될 때 파일 시스템에서 문서를 읽어 LLM의 system 역할(role) 메시지에 주입합니다."><meta name=author content="Byung Kyu KIM"><link rel=canonical href=https://cdecl.github.io/devops/ai-agent-openclaw-llm-interface/><link crossorigin=anonymous href=/assets/css/stylesheet.f939c4ffefb264e6fe85e04352266f79db6bb1303c8e16ae9b6064c1247b5e32.css integrity="sha256-+TnE/++yZOb+heBDUiZvedtrsTA8jhaum2BkwSR7XjI=" rel="preload stylesheet" as=style><link rel=icon href=https://cdecl.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://cdecl.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://cdecl.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://cdecl.github.io/apple-touch-icon.png><link rel=mask-icon href=https://cdecl.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://cdecl.github.io/devops/ai-agent-openclaw-llm-interface/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51);color-scheme:dark}.list{background:var(--theme)}.toc{background:var(--entry)}}@media(prefers-color-scheme:light){.list::-webkit-scrollbar-thumb{border-color:var(--code-bg)}}</style></noscript><script>localStorage.getItem("pref-theme")==="dark"?document.querySelector("html").dataset.theme="dark":localStorage.getItem("pref-theme")==="light"?document.querySelector("html").dataset.theme="light":window.matchMedia("(prefers-color-scheme: dark)").matches?document.querySelector("html").dataset.theme="dark":document.querySelector("html").dataset.theme="light"</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-VQQHHYPN7K"></script><script>var doNotTrack=!1,dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes";if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-VQQHHYPN7K")}</script><meta property="og:url" content="https://cdecl.github.io/devops/ai-agent-openclaw-llm-interface/"><meta property="og:site_name" content="cdeclog"><meta property="og:title" content="AI 에이전트(OpenClaw 등)의 LLM 인터페이스 구현 및 툴 콜링 기술 개요"><meta property="og:description" content="OpenClaw, Claude 데스크톱 앱, 혹은 로컬 기반의 여러 AI 에이전트들은 내부적으로 LLM(대형 언어 모델)과 어떻게 소통하고, 로컬 환경의 도구(Tool)들을 사용할까요? 이 글에서는 에이전트가 LLM과 인터페이스를 맺는 기술적 구현 내용과 핵심 요소들을 살펴봅니다.
1. 지침 파일(agent.md 등) 적용 방법 AI 에이전트의 페르소나, 역할, 기본 규칙을 정의하기 위해 주로 .md 형태의 지침 파일을 사용합니다. (예: agent.md, system_prompt.txt, SOUL.md 등)
기술적 구현: 이러한 지침 파일은 LLM에 전달되는 **시스템 프롬프트(System Prompt)**로 로드됩니다. 에이전트 프로그램이 실행될 때 혹은 세션이 시작될 때 파일 시스템에서 문서를 읽어 LLM의 system 역할(role) 메시지에 주입합니다."><meta property="og:locale" content="ko-kr"><meta property="og:type" content="article"><meta property="article:section" content="devops"><meta property="article:published_time" content="2026-02-21T00:00:00+09:00"><meta property="article:modified_time" content="2026-02-21T00:00:00+09:00"><meta property="article:tag" content="Ai"><meta property="article:tag" content="Agent"><meta property="article:tag" content="Openclaw"><meta property="article:tag" content="Llm"><meta property="article:tag" content="Tool-Calling"><meta property="article:tag" content="Devops"><meta name=twitter:card content="summary"><meta name=twitter:title content="AI 에이전트(OpenClaw 등)의 LLM 인터페이스 구현 및 툴 콜링 기술 개요"><meta name=twitter:description content="OpenClaw, Claude 데스크톱 앱, 혹은 로컬 기반의 여러 AI 에이전트들은 내부적으로 LLM(대형 언어 모델)과 어떻게 소통하고, 로컬 환경의 도구(Tool)들을 사용할까요? 이 글에서는 에이전트가 LLM과 인터페이스를 맺는 기술적 구현 내용과 핵심 요소들을 살펴봅니다.
1. 지침 파일(agent.md 등) 적용 방법
AI 에이전트의 페르소나, 역할, 기본 규칙을 정의하기 위해 주로 .md 형태의 지침 파일을 사용합니다. (예: agent.md, system_prompt.txt, SOUL.md 등)
기술적 구현:
이러한 지침 파일은 LLM에 전달되는 **시스템 프롬프트(System Prompt)**로 로드됩니다. 에이전트 프로그램이 실행될 때 혹은 세션이 시작될 때 파일 시스템에서 문서를 읽어 LLM의 system 역할(role) 메시지에 주입합니다."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Devops","item":"https://cdecl.github.io/devops/"},{"@type":"ListItem","position":2,"name":"AI 에이전트(OpenClaw 등)의 LLM 인터페이스 구현 및 툴 콜링 기술 개요","item":"https://cdecl.github.io/devops/ai-agent-openclaw-llm-interface/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"AI 에이전트(OpenClaw 등)의 LLM 인터페이스 구현 및 툴 콜링 기술 개요","name":"AI 에이전트(OpenClaw 등)의 LLM 인터페이스 구현 및 툴 콜링 기술 개요","description":"OpenClaw, Claude 데스크톱 앱, 혹은 로컬 기반의 여러 AI 에이전트들은 내부적으로 LLM(대형 언어 모델)과 어떻게 소통하고, 로컬 환경의 도구(Tool)들을 사용할까요? 이 글에서는 에이전트가 LLM과 인터페이스를 맺는 기술적 구현 내용과 핵심 요소들을 살펴봅니다.\n1. 지침 파일(agent.md 등) 적용 방법 AI 에이전트의 페르소나, 역할, 기본 규칙을 정의하기 위해 주로 .md 형태의 지침 파일을 사용합니다. (예: agent.md, system_prompt.txt, SOUL.md 등)\n기술적 구현: 이러한 지침 파일은 LLM에 전달되는 **시스템 프롬프트(System Prompt)**로 로드됩니다. 에이전트 프로그램이 실행될 때 혹은 세션이 시작될 때 파일 시스템에서 문서를 읽어 LLM의 system 역할(role) 메시지에 주입합니다.\n","keywords":["ai","agent","openclaw","llm","tool-calling","devops"],"articleBody":"OpenClaw, Claude 데스크톱 앱, 혹은 로컬 기반의 여러 AI 에이전트들은 내부적으로 LLM(대형 언어 모델)과 어떻게 소통하고, 로컬 환경의 도구(Tool)들을 사용할까요? 이 글에서는 에이전트가 LLM과 인터페이스를 맺는 기술적 구현 내용과 핵심 요소들을 살펴봅니다.\n1. 지침 파일(agent.md 등) 적용 방법 AI 에이전트의 페르소나, 역할, 기본 규칙을 정의하기 위해 주로 .md 형태의 지침 파일을 사용합니다. (예: agent.md, system_prompt.txt, SOUL.md 등)\n기술적 구현: 이러한 지침 파일은 LLM에 전달되는 **시스템 프롬프트(System Prompt)**로 로드됩니다. 에이전트 프로그램이 실행될 때 혹은 세션이 시작될 때 파일 시스템에서 문서를 읽어 LLM의 system 역할(role) 메시지에 주입합니다.\n구현 샘플 (Python/가상코드):\ndef load_agent_instructions(filepath=\"agent.md\"): with open(filepath, \"r\", encoding=\"utf-8\") as f: return f.read() # LLM API 호출 시 system_instruction = load_agent_instructions() messages = [ {\"role\": \"system\", \"content\": system_instruction}, {\"role\": \"user\", \"content\": \"오늘의 주요 시스템 로그를 요약해줘.\"} ] response = llm_client.chat.completions.create( model=\"gpt-4o\", messages=messages ) 2. 스킬(skills) 파일 적용 방법 단순한 지침을 넘어, 특정 작업(예: “웹 크롤링”, “데이터베이스 조회”)을 수행하기 위한 리소스나 스크립트 모음을 skills 디렉토리로 구성할 수 있습니다.\n기술적 구현: 스킬 파일들은 로컬 시스템에 저장되어 있으며, 사용자의 요청이 들어올 때 일종의 RAG(Retrieval-Augmented Generation) 방식이나 직접 컨텍스트화되어 동적으로 프롬프트에 삽입됩니다.\n스킬 메타데이터 인덱싱: 에이전트는 사용 가능한 스킬 목록과 설명을 미리 읽어 LLM에게 “너는 현재 이러한 스킬들을 알고 있다\"고 프롬프트 상단에 알려줍니다. (프롬프트 주입) 동적 파일 읽기: LLM이 특정 스킬의 세부 내용이 필요하다고 판단하면, 로컬 파일 시스템을 읽는 툴(view_file 등)을 통해 해당 스킬의 .md나 관련 스크립트 내용을 읽어들여 적용합니다. 3. 툴 콜링(Tool Calling)의 판단 및 실행 방법 에이전트 시스템에서 가장 중요한 부분은 “언제 외부 도구를 부를 것인가” 그리고 “어떻게 실행할 것인가\"입니다.\n3.1 Tool Calling 판단 방법 대부분의 현대적인 에이전트는 LLM 자체의 능력(Function Calling 기능)을 활용합니다. 개발자는 LLM API에 **가용한 툴의 명세서(Schema)**를 JSON 형태로 설명(Description), 파라미터(Parameters) 등과 함께 전달합니다. LLM은 사용자의 요청을 분석하다가 자신의 내부 지식만으로 답변할 수 없는 작업(예: 로컬 파일 검색, 터미널 명령 실행, 웹 크롤링 등)이라 판단하면, 일반 텍스트 답변이 아닌 Tool Call 객체를 반환합니다.\n3.2 Tool 호출 및 실행 흐름 Tool 정의 전달: 에이전트 시스템이 LLM에 툴 스키마(이름, 설명, 파라미터 타입)를 전달. LLM의 판단 (Tool Call 반환): LLM이 툴 호출에 필요한 인자(Arguments)를 채워 tool_calls 객체로 시스템에 반환. 도구 실행 (시스템/로컬 환경): 에이전트 시스템이 해당 응답을 파싱하여, 실제 로컬 환경에서 지정된 함수나 쉘 명령어를 단독으로 실행합니다. (이때 사용자의 승인을 받거나, 샌드박스 환경에서 실행하여 보안을 확보합니다.) 결과 반환: 명령어나 함수의 실행 결과(stdout, stderr, 혹은 오류 메시지)를 확보하여 다시 LLM 시스템으로 전달되는 메시지 목록에 추가합니다. 최종 응답 생성: LLM이 해당 결과를 읽고 분석하여 사용자에게 최종적으로 유의미한 텍스트 결과를 보고합니다. 구현 샘플 (툴 실행 주기):\nimport json import subprocess # 1. Tool 정의 tools = [ { \"type\": \"function\", \"function\": { \"name\": \"run_shell_command\", \"description\": \"운영체제 쉘 명령어를 실행합니다.\", \"parameters\": { \"type\": \"object\", \"properties\": { \"command\": { \"type\": \"string\", \"description\": \"실행할 터미널 커맨드\" } }, \"required\": [\"command\"] } } } ] # 2. LLM 호출 및 판단 response = llm_client.chat.completions.create( model=\"gpt-4o\", messages=messages, tools=tools ) # 3. LLM이 Tool Call을 요구한 경우 if response.choices[0].message.tool_calls: for tool_call in response.choices[0].message.tool_calls: if tool_call.function.name == \"run_shell_command\": # 전달받은 파라미터 파싱 args = json.loads(tool_call.function.arguments) cmd = args[\"command\"] # 4. 로컬 도구 실제 실행 result = subprocess.run(cmd, shell=True, capture_output=True, text=True) output = result.stdout if result.returncode == 0 else result.stderr # 5. 결과를 다시 메시지 히스토리에 추가하여 LLM 재호출 messages.append(response.choices[0].message) # 어시스턴트의 Tool Call 기록을 추가 messages.append({ \"role\": \"tool\", \"tool_call_id\": tool_call.id, \"content\": output }) final_response = llm_client.chat.completions.create( model=\"gpt-4o\", messages=messages ) print(final_response.choices[0].message.content) 마무리 OpenClaw나 다양한 코딩 에이전트는 결론적으로 LLM의 Function Calling 메커니즘과 로컬 시스템 간의 인터페이스 다리(Bridge) 역할을 합니다. 단편적인 프롬프팅 기술을 넘어서, agent.md로 기본 캐릭터와 지침을 설정하고, 구조화된 skills 파일로 전문 기능 영역을 확장하며, 동적인 툴 콜링(Tool Calling) 방식을 통해 물리적인 시스템 자원을 자유롭고 유연하게 제어하는 것이 최신 독립형 AI 에이전트 아키텍처의 핵심입니다.\n","wordCount":"585","inLanguage":"en","datePublished":"2026-02-21T00:00:00+09:00","dateModified":"2026-02-21T00:00:00+09:00","author":{"@type":"Person","name":"Byung Kyu KIM"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://cdecl.github.io/devops/ai-agent-openclaw-llm-interface/"},"publisher":{"@type":"Organization","name":"cdeclog","logo":{"@type":"ImageObject","url":"https://cdecl.github.io/favicon.ico"}}}</script></head><body id=top><header class=header><nav class=nav><div class=logo><a href=https://cdecl.github.io/ accesskey=h title="cdeclog (Alt + H)">cdeclog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://cdecl.github.io/dev/ title=Dev><span>Dev</span></a></li><li><a href=https://cdecl.github.io/devops/ title=DevOps><span>DevOps</span></a></li><li><a href=https://cdecl.github.io/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://cdecl.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://cdecl.github.io/tags/ title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://cdecl.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://cdecl.github.io/devops/>Devops</a></div><h1 class="post-title entry-hint-parent">AI 에이전트(OpenClaw 등)의 LLM 인터페이스 구현 및 툴 콜링 기술 개요</h1><div class=post-meta><span title='2026-02-21 00:00:00 +0900 KST'>February 21, 2026</span>&nbsp;·&nbsp;<span>Byung Kyu KIM</span></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#1-%ec%a7%80%ec%b9%a8-%ed%8c%8c%ec%9d%bcagentmd-%eb%93%b1-%ec%a0%81%ec%9a%a9-%eb%b0%a9%eb%b2%95 aria-label="1. 지침 파일(agent.md 등) 적용 방법">1. 지침 파일(agent.md 등) 적용 방법</a></li><li><a href=#2-%ec%8a%a4%ed%82%acskills-%ed%8c%8c%ec%9d%bc-%ec%a0%81%ec%9a%a9-%eb%b0%a9%eb%b2%95 aria-label="2. 스킬(skills) 파일 적용 방법">2. 스킬(skills) 파일 적용 방법</a></li><li><a href=#3-%ed%88%b4-%ec%bd%9c%eb%a7%81tool-calling%ec%9d%98-%ed%8c%90%eb%8b%a8-%eb%b0%8f-%ec%8b%a4%ed%96%89-%eb%b0%a9%eb%b2%95 aria-label="3. 툴 콜링(Tool Calling)의 판단 및 실행 방법">3. 툴 콜링(Tool Calling)의 판단 및 실행 방법</a><ul><li><a href=#31-tool-calling-%ed%8c%90%eb%8b%a8-%eb%b0%a9%eb%b2%95 aria-label="3.1 Tool Calling 판단 방법">3.1 Tool Calling 판단 방법</a></li><li><a href=#32-tool-%ed%98%b8%ec%b6%9c-%eb%b0%8f-%ec%8b%a4%ed%96%89-%ed%9d%90%eb%a6%84 aria-label="3.2 Tool 호출 및 실행 흐름">3.2 Tool 호출 및 실행 흐름</a></li></ul></li><li><a href=#%eb%a7%88%eb%ac%b4%eb%a6%ac aria-label=마무리>마무리</a></li></ul></div></details></div><div class=post-content><p>OpenClaw, Claude 데스크톱 앱, 혹은 로컬 기반의 여러 AI 에이전트들은 내부적으로 LLM(대형 언어 모델)과 어떻게 소통하고, 로컬 환경의 도구(Tool)들을 사용할까요? 이 글에서는 에이전트가 LLM과 인터페이스를 맺는 기술적 구현 내용과 핵심 요소들을 살펴봅니다.</p><h2 id=1-지침-파일agentmd-등-적용-방법>1. 지침 파일(<code>agent.md</code> 등) 적용 방법<a hidden class=anchor aria-hidden=true href=#1-지침-파일agentmd-등-적용-방법>#</a></h2><p>AI 에이전트의 페르소나, 역할, 기본 규칙을 정의하기 위해 주로 <code>.md</code> 형태의 지침 파일을 사용합니다. (예: <code>agent.md</code>, <code>system_prompt.txt</code>, <code>SOUL.md</code> 등)</p><p><strong>기술적 구현:</strong>
이러한 지침 파일은 LLM에 전달되는 **시스템 프롬프트(System Prompt)**로 로드됩니다. 에이전트 프로그램이 실행될 때 혹은 세션이 시작될 때 파일 시스템에서 문서를 읽어 LLM의 <code>system</code> 역할(role) 메시지에 주입합니다.</p><p><strong>구현 샘플 (Python/가상코드):</strong></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#ff79c6>def</span> <span style=color:#50fa7b>load_agent_instructions</span>(filepath<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#34;agent.md&#34;</span>):
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>with</span> <span style=color:#8be9fd;font-style:italic>open</span>(filepath, <span style=color:#f1fa8c>&#34;r&#34;</span>, encoding<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#34;utf-8&#34;</span>) <span style=color:#ff79c6>as</span> f:
</span></span><span style=display:flex><span>         <span style=color:#ff79c6>return</span> f<span style=color:#ff79c6>.</span>read()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># LLM API 호출 시</span>
</span></span><span style=display:flex><span>system_instruction <span style=color:#ff79c6>=</span> load_agent_instructions()
</span></span><span style=display:flex><span>messages <span style=color:#ff79c6>=</span> [
</span></span><span style=display:flex><span>    {<span style=color:#f1fa8c>&#34;role&#34;</span>: <span style=color:#f1fa8c>&#34;system&#34;</span>, <span style=color:#f1fa8c>&#34;content&#34;</span>: system_instruction},
</span></span><span style=display:flex><span>    {<span style=color:#f1fa8c>&#34;role&#34;</span>: <span style=color:#f1fa8c>&#34;user&#34;</span>, <span style=color:#f1fa8c>&#34;content&#34;</span>: <span style=color:#f1fa8c>&#34;오늘의 주요 시스템 로그를 요약해줘.&#34;</span>}
</span></span><span style=display:flex><span>]
</span></span><span style=display:flex><span>response <span style=color:#ff79c6>=</span> llm_client<span style=color:#ff79c6>.</span>chat<span style=color:#ff79c6>.</span>completions<span style=color:#ff79c6>.</span>create(
</span></span><span style=display:flex><span>    model<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#34;gpt-4o&#34;</span>,
</span></span><span style=display:flex><span>    messages<span style=color:#ff79c6>=</span>messages
</span></span><span style=display:flex><span>)
</span></span></code></pre></div><h2 id=2-스킬skills-파일-적용-방법>2. 스킬(<code>skills</code>) 파일 적용 방법<a hidden class=anchor aria-hidden=true href=#2-스킬skills-파일-적용-방법>#</a></h2><p>단순한 지침을 넘어, 특정 작업(예: &ldquo;웹 크롤링&rdquo;, &ldquo;데이터베이스 조회&rdquo;)을 수행하기 위한 리소스나 스크립트 모음을 <code>skills</code> 디렉토리로 구성할 수 있습니다.</p><p><strong>기술적 구현:</strong>
스킬 파일들은 로컬 시스템에 저장되어 있으며, 사용자의 요청이 들어올 때 일종의 RAG(Retrieval-Augmented Generation) 방식이나 직접 컨텍스트화되어 동적으로 프롬프트에 삽입됩니다.</p><ul><li><strong>스킬 메타데이터 인덱싱</strong>: 에이전트는 사용 가능한 스킬 목록과 설명을 미리 읽어 LLM에게 &ldquo;너는 현재 이러한 스킬들을 알고 있다"고 프롬프트 상단에 알려줍니다. (프롬프트 주입)</li><li><strong>동적 파일 읽기</strong>: LLM이 특정 스킬의 세부 내용이 필요하다고 판단하면, 로컬 파일 시스템을 읽는 툴(view_file 등)을 통해 해당 스킬의 <code>.md</code>나 관련 스크립트 내용을 읽어들여 적용합니다.</li></ul><h2 id=3-툴-콜링tool-calling의-판단-및-실행-방법>3. 툴 콜링(Tool Calling)의 판단 및 실행 방법<a hidden class=anchor aria-hidden=true href=#3-툴-콜링tool-calling의-판단-및-실행-방법>#</a></h2><p>에이전트 시스템에서 가장 중요한 부분은 &ldquo;언제 외부 도구를 부를 것인가&rdquo; 그리고 &ldquo;어떻게 실행할 것인가"입니다.</p><h3 id=31-tool-calling-판단-방법>3.1 Tool Calling 판단 방법<a hidden class=anchor aria-hidden=true href=#31-tool-calling-판단-방법>#</a></h3><p>대부분의 현대적인 에이전트는 LLM 자체의 능력(Function Calling 기능)을 활용합니다. 개발자는 LLM API에 **가용한 툴의 명세서(Schema)**를 JSON 형태로 설명(Description), 파라미터(Parameters) 등과 함께 전달합니다.
LLM은 사용자의 요청을 분석하다가 자신의 내부 지식만으로 답변할 수 없는 작업(예: 로컬 파일 검색, 터미널 명령 실행, 웹 크롤링 등)이라 판단하면, 일반 텍스트 답변이 아닌 <strong>Tool Call 객체</strong>를 반환합니다.</p><h3 id=32-tool-호출-및-실행-흐름>3.2 Tool 호출 및 실행 흐름<a hidden class=anchor aria-hidden=true href=#32-tool-호출-및-실행-흐름>#</a></h3><ol><li><strong>Tool 정의 전달</strong>: 에이전트 시스템이 LLM에 툴 스키마(이름, 설명, 파라미터 타입)를 전달.</li><li><strong>LLM의 판단 (Tool Call 반환)</strong>: LLM이 툴 호출에 필요한 인자(Arguments)를 채워 <code>tool_calls</code> 객체로 시스템에 반환.</li><li><strong>도구 실행 (시스템/로컬 환경)</strong>: 에이전트 시스템이 해당 응답을 파싱하여, 실제 로컬 환경에서 지정된 함수나 쉘 명령어를 단독으로 실행합니다. (이때 사용자의 승인을 받거나, 샌드박스 환경에서 실행하여 보안을 확보합니다.)</li><li><strong>결과 반환</strong>: 명령어나 함수의 실행 결과(stdout, stderr, 혹은 오류 메시지)를 확보하여 다시 LLM 시스템으로 전달되는 메시지 목록에 추가합니다.</li><li><strong>최종 응답 생성</strong>: LLM이 해당 결과를 읽고 분석하여 사용자에게 최종적으로 유의미한 텍스트 결과를 보고합니다.</li></ol><p><strong>구현 샘플 (툴 실행 주기):</strong></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#ff79c6>import</span> json
</span></span><span style=display:flex><span><span style=color:#ff79c6>import</span> subprocess
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 1. Tool 정의</span>
</span></span><span style=display:flex><span>tools <span style=color:#ff79c6>=</span> [
</span></span><span style=display:flex><span>    {
</span></span><span style=display:flex><span>        <span style=color:#f1fa8c>&#34;type&#34;</span>: <span style=color:#f1fa8c>&#34;function&#34;</span>,
</span></span><span style=display:flex><span>        <span style=color:#f1fa8c>&#34;function&#34;</span>: {
</span></span><span style=display:flex><span>            <span style=color:#f1fa8c>&#34;name&#34;</span>: <span style=color:#f1fa8c>&#34;run_shell_command&#34;</span>,
</span></span><span style=display:flex><span>            <span style=color:#f1fa8c>&#34;description&#34;</span>: <span style=color:#f1fa8c>&#34;운영체제 쉘 명령어를 실행합니다.&#34;</span>,
</span></span><span style=display:flex><span>            <span style=color:#f1fa8c>&#34;parameters&#34;</span>: {
</span></span><span style=display:flex><span>                <span style=color:#f1fa8c>&#34;type&#34;</span>: <span style=color:#f1fa8c>&#34;object&#34;</span>,
</span></span><span style=display:flex><span>                <span style=color:#f1fa8c>&#34;properties&#34;</span>: {
</span></span><span style=display:flex><span>                    <span style=color:#f1fa8c>&#34;command&#34;</span>: {
</span></span><span style=display:flex><span>                        <span style=color:#f1fa8c>&#34;type&#34;</span>: <span style=color:#f1fa8c>&#34;string&#34;</span>,
</span></span><span style=display:flex><span>                        <span style=color:#f1fa8c>&#34;description&#34;</span>: <span style=color:#f1fa8c>&#34;실행할 터미널 커맨드&#34;</span>
</span></span><span style=display:flex><span>                    }
</span></span><span style=display:flex><span>                },
</span></span><span style=display:flex><span>                <span style=color:#f1fa8c>&#34;required&#34;</span>: [<span style=color:#f1fa8c>&#34;command&#34;</span>]
</span></span><span style=display:flex><span>            }
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 2. LLM 호출 및 판단</span>
</span></span><span style=display:flex><span>response <span style=color:#ff79c6>=</span> llm_client<span style=color:#ff79c6>.</span>chat<span style=color:#ff79c6>.</span>completions<span style=color:#ff79c6>.</span>create(
</span></span><span style=display:flex><span>    model<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#34;gpt-4o&#34;</span>,
</span></span><span style=display:flex><span>    messages<span style=color:#ff79c6>=</span>messages,
</span></span><span style=display:flex><span>    tools<span style=color:#ff79c6>=</span>tools
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 3. LLM이 Tool Call을 요구한 경우</span>
</span></span><span style=display:flex><span><span style=color:#ff79c6>if</span> response<span style=color:#ff79c6>.</span>choices[<span style=color:#bd93f9>0</span>]<span style=color:#ff79c6>.</span>message<span style=color:#ff79c6>.</span>tool_calls:
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>for</span> tool_call <span style=color:#ff79c6>in</span> response<span style=color:#ff79c6>.</span>choices[<span style=color:#bd93f9>0</span>]<span style=color:#ff79c6>.</span>message<span style=color:#ff79c6>.</span>tool_calls:
</span></span><span style=display:flex><span>        <span style=color:#ff79c6>if</span> tool_call<span style=color:#ff79c6>.</span>function<span style=color:#ff79c6>.</span>name <span style=color:#ff79c6>==</span> <span style=color:#f1fa8c>&#34;run_shell_command&#34;</span>:
</span></span><span style=display:flex><span>            <span style=color:#6272a4># 전달받은 파라미터 파싱</span>
</span></span><span style=display:flex><span>            args <span style=color:#ff79c6>=</span> json<span style=color:#ff79c6>.</span>loads(tool_call<span style=color:#ff79c6>.</span>function<span style=color:#ff79c6>.</span>arguments)
</span></span><span style=display:flex><span>            cmd <span style=color:#ff79c6>=</span> args[<span style=color:#f1fa8c>&#34;command&#34;</span>]
</span></span><span style=display:flex><span>            
</span></span><span style=display:flex><span>            <span style=color:#6272a4># 4. 로컬 도구 실제 실행</span>
</span></span><span style=display:flex><span>            result <span style=color:#ff79c6>=</span> subprocess<span style=color:#ff79c6>.</span>run(cmd, shell<span style=color:#ff79c6>=</span><span style=color:#ff79c6>True</span>, capture_output<span style=color:#ff79c6>=</span><span style=color:#ff79c6>True</span>, text<span style=color:#ff79c6>=</span><span style=color:#ff79c6>True</span>)
</span></span><span style=display:flex><span>            output <span style=color:#ff79c6>=</span> result<span style=color:#ff79c6>.</span>stdout <span style=color:#ff79c6>if</span> result<span style=color:#ff79c6>.</span>returncode <span style=color:#ff79c6>==</span> <span style=color:#bd93f9>0</span> <span style=color:#ff79c6>else</span> result<span style=color:#ff79c6>.</span>stderr
</span></span><span style=display:flex><span>            
</span></span><span style=display:flex><span>            <span style=color:#6272a4># 5. 결과를 다시 메시지 히스토리에 추가하여 LLM 재호출</span>
</span></span><span style=display:flex><span>            messages<span style=color:#ff79c6>.</span>append(response<span style=color:#ff79c6>.</span>choices[<span style=color:#bd93f9>0</span>]<span style=color:#ff79c6>.</span>message) <span style=color:#6272a4># 어시스턴트의 Tool Call 기록을 추가</span>
</span></span><span style=display:flex><span>            messages<span style=color:#ff79c6>.</span>append({
</span></span><span style=display:flex><span>                <span style=color:#f1fa8c>&#34;role&#34;</span>: <span style=color:#f1fa8c>&#34;tool&#34;</span>,
</span></span><span style=display:flex><span>                <span style=color:#f1fa8c>&#34;tool_call_id&#34;</span>: tool_call<span style=color:#ff79c6>.</span>id,
</span></span><span style=display:flex><span>                <span style=color:#f1fa8c>&#34;content&#34;</span>: output
</span></span><span style=display:flex><span>            })
</span></span><span style=display:flex><span>            
</span></span><span style=display:flex><span>            final_response <span style=color:#ff79c6>=</span> llm_client<span style=color:#ff79c6>.</span>chat<span style=color:#ff79c6>.</span>completions<span style=color:#ff79c6>.</span>create(
</span></span><span style=display:flex><span>                model<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#34;gpt-4o&#34;</span>,
</span></span><span style=display:flex><span>                messages<span style=color:#ff79c6>=</span>messages
</span></span><span style=display:flex><span>            )
</span></span><span style=display:flex><span>            <span style=color:#8be9fd;font-style:italic>print</span>(final_response<span style=color:#ff79c6>.</span>choices[<span style=color:#bd93f9>0</span>]<span style=color:#ff79c6>.</span>message<span style=color:#ff79c6>.</span>content)
</span></span></code></pre></div><h2 id=마무리>마무리<a hidden class=anchor aria-hidden=true href=#마무리>#</a></h2><p>OpenClaw나 다양한 코딩 에이전트는 결론적으로 <strong>LLM의 Function Calling 메커니즘</strong>과 <strong>로컬 시스템 간의 인터페이스 다리(Bridge)</strong> 역할을 합니다. 단편적인 프롬프팅 기술을 넘어서, <code>agent.md</code>로 기본 캐릭터와 지침을 설정하고, 구조화된 <code>skills</code> 파일로 전문 기능 영역을 확장하며, 동적인 툴 콜링(Tool Calling) 방식을 통해 물리적인 시스템 자원을 자유롭고 유연하게 제어하는 것이 최신 독립형 AI 에이전트 아키텍처의 핵심입니다.</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://cdecl.github.io/tags/ai/>Ai</a></li><li><a href=https://cdecl.github.io/tags/agent/>Agent</a></li><li><a href=https://cdecl.github.io/tags/openclaw/>Openclaw</a></li><li><a href=https://cdecl.github.io/tags/llm/>Llm</a></li><li><a href=https://cdecl.github.io/tags/tool-calling/>Tool-Calling</a></li><li><a href=https://cdecl.github.io/tags/devops/>Devops</a></li></ul></footer><script src=https://giscus.app/client.js data-repo=cdecl/cdecl.github.io data-repo-id="MDEwOlJlcG9zaXRvcnkzNDk1ODUyNjg=" data-category=General data-category-id=DIC_kwDOFNY_dM4C1XMk data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=transparent_dark data-lang=ko crossorigin=anonymous async></script></article></main><footer class=footer><span>&copy; 2026 <a href=https://cdecl.github.io/>cdeclog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");if(menu){const e=localStorage.getItem("menu-scroll-position");e&&(menu.scrollLeft=parseInt(e,10)),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}}document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{const e=document.querySelector("html");e.dataset.theme==="dark"?(e.dataset.theme="light",localStorage.setItem("pref-theme","light")):(e.dataset.theme="dark",localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>