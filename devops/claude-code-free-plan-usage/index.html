<!doctype html><html lang=en dir=auto data-theme=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Claude Code 무료 플랜 활용 가이드 (Ollama, free-claude-code) | cdeclog</title><meta name=keywords content="claude,claude-code,ollama,openrouter,nvidia-nim,lm-studio,ai-agent,devops"><meta name=description content='Claude Code를 쓰고 싶은데 유료 API 비용이 부담될 때, 실무에서는 보통 두 가지 경로를 사용합니다.

Ollama 기반 로컬 모델 연결
free-claude-code 같은 호환 레이어를 통해 NVIDIA NIM, OpenRouter, LM Studio 백엔드 연결

이 글은 각 방식의 배경, 설치/설정 방법, 그리고 운영 시 주의점을 정리합니다.
왜 &ldquo;무료 플랜&rdquo; 구성이 필요한가

코드 에이전트는 반복 호출이 많아 토큰 비용이 빠르게 증가합니다.
개인 프로젝트나 학습 단계에서는 응답 품질보다 비용 상한이 더 중요할 수 있습니다.
팀 환경에서는 &ldquo;무조건 최신 고가 모델"보다 &ldquo;저비용 + 재현 가능한 워크플로"가 더 실용적입니다.

핵심은, Claude Code UX를 유지하면서 백엔드를 교체하는 것입니다.'><meta name=author content="Byung Kyu KIM"><link rel=canonical href=https://cdecl.github.io/devops/claude-code-free-plan-usage/><link crossorigin=anonymous href=/assets/css/stylesheet.f939c4ffefb264e6fe85e04352266f79db6bb1303c8e16ae9b6064c1247b5e32.css integrity="sha256-+TnE/++yZOb+heBDUiZvedtrsTA8jhaum2BkwSR7XjI=" rel="preload stylesheet" as=style><link rel=icon href=https://cdecl.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://cdecl.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://cdecl.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://cdecl.github.io/apple-touch-icon.png><link rel=mask-icon href=https://cdecl.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://cdecl.github.io/devops/claude-code-free-plan-usage/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51);color-scheme:dark}.list{background:var(--theme)}.toc{background:var(--entry)}}@media(prefers-color-scheme:light){.list::-webkit-scrollbar-thumb{border-color:var(--code-bg)}}</style></noscript><script>localStorage.getItem("pref-theme")==="dark"?document.querySelector("html").dataset.theme="dark":localStorage.getItem("pref-theme")==="light"?document.querySelector("html").dataset.theme="light":window.matchMedia("(prefers-color-scheme: dark)").matches?document.querySelector("html").dataset.theme="dark":document.querySelector("html").dataset.theme="light"</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-VQQHHYPN7K"></script><script>var doNotTrack=!1,dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes";if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-VQQHHYPN7K")}</script><meta property="og:url" content="https://cdecl.github.io/devops/claude-code-free-plan-usage/"><meta property="og:site_name" content="cdeclog"><meta property="og:title" content="Claude Code 무료 플랜 활용 가이드 (Ollama, free-claude-code)"><meta property="og:description" content='Claude Code를 쓰고 싶은데 유료 API 비용이 부담될 때, 실무에서는 보통 두 가지 경로를 사용합니다.
Ollama 기반 로컬 모델 연결 free-claude-code 같은 호환 레이어를 통해 NVIDIA NIM, OpenRouter, LM Studio 백엔드 연결 이 글은 각 방식의 배경, 설치/설정 방법, 그리고 운영 시 주의점을 정리합니다.
왜 “무료 플랜” 구성이 필요한가 코드 에이전트는 반복 호출이 많아 토큰 비용이 빠르게 증가합니다. 개인 프로젝트나 학습 단계에서는 응답 품질보다 비용 상한이 더 중요할 수 있습니다. 팀 환경에서는 “무조건 최신 고가 모델"보다 “저비용 + 재현 가능한 워크플로"가 더 실용적입니다. 핵심은, Claude Code UX를 유지하면서 백엔드를 교체하는 것입니다.'><meta property="og:locale" content="ko-kr"><meta property="og:type" content="article"><meta property="article:section" content="devops"><meta property="article:published_time" content="2026-02-23T00:00:00+09:00"><meta property="article:modified_time" content="2026-02-23T00:00:00+09:00"><meta property="article:tag" content="Claude"><meta property="article:tag" content="Claude-Code"><meta property="article:tag" content="Ollama"><meta property="article:tag" content="Openrouter"><meta property="article:tag" content="Nvidia-Nim"><meta property="article:tag" content="Lm-Studio"><meta name=twitter:card content="summary"><meta name=twitter:title content="Claude Code 무료 플랜 활용 가이드 (Ollama, free-claude-code)"><meta name=twitter:description content='Claude Code를 쓰고 싶은데 유료 API 비용이 부담될 때, 실무에서는 보통 두 가지 경로를 사용합니다.

Ollama 기반 로컬 모델 연결
free-claude-code 같은 호환 레이어를 통해 NVIDIA NIM, OpenRouter, LM Studio 백엔드 연결

이 글은 각 방식의 배경, 설치/설정 방법, 그리고 운영 시 주의점을 정리합니다.
왜 &ldquo;무료 플랜&rdquo; 구성이 필요한가

코드 에이전트는 반복 호출이 많아 토큰 비용이 빠르게 증가합니다.
개인 프로젝트나 학습 단계에서는 응답 품질보다 비용 상한이 더 중요할 수 있습니다.
팀 환경에서는 &ldquo;무조건 최신 고가 모델"보다 &ldquo;저비용 + 재현 가능한 워크플로"가 더 실용적입니다.

핵심은, Claude Code UX를 유지하면서 백엔드를 교체하는 것입니다.'><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Devops","item":"https://cdecl.github.io/devops/"},{"@type":"ListItem","position":2,"name":"Claude Code 무료 플랜 활용 가이드 (Ollama, free-claude-code)","item":"https://cdecl.github.io/devops/claude-code-free-plan-usage/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Claude Code 무료 플랜 활용 가이드 (Ollama, free-claude-code)","name":"Claude Code 무료 플랜 활용 가이드 (Ollama, free-claude-code)","description":"Claude Code를 쓰고 싶은데 유료 API 비용이 부담될 때, 실무에서는 보통 두 가지 경로를 사용합니다.\nOllama 기반 로컬 모델 연결 free-claude-code 같은 호환 레이어를 통해 NVIDIA NIM, OpenRouter, LM Studio 백엔드 연결 이 글은 각 방식의 배경, 설치/설정 방법, 그리고 운영 시 주의점을 정리합니다.\n왜 \u0026ldquo;무료 플랜\u0026rdquo; 구성이 필요한가 코드 에이전트는 반복 호출이 많아 토큰 비용이 빠르게 증가합니다. 개인 프로젝트나 학습 단계에서는 응답 품질보다 비용 상한이 더 중요할 수 있습니다. 팀 환경에서는 \u0026ldquo;무조건 최신 고가 모델\u0026quot;보다 \u0026ldquo;저비용 + 재현 가능한 워크플로\u0026quot;가 더 실용적입니다. 핵심은, Claude Code UX를 유지하면서 백엔드를 교체하는 것입니다.\n","keywords":["claude","claude-code","ollama","openrouter","nvidia-nim","lm-studio","ai-agent","devops"],"articleBody":"Claude Code를 쓰고 싶은데 유료 API 비용이 부담될 때, 실무에서는 보통 두 가지 경로를 사용합니다.\nOllama 기반 로컬 모델 연결 free-claude-code 같은 호환 레이어를 통해 NVIDIA NIM, OpenRouter, LM Studio 백엔드 연결 이 글은 각 방식의 배경, 설치/설정 방법, 그리고 운영 시 주의점을 정리합니다.\n왜 “무료 플랜” 구성이 필요한가 코드 에이전트는 반복 호출이 많아 토큰 비용이 빠르게 증가합니다. 개인 프로젝트나 학습 단계에서는 응답 품질보다 비용 상한이 더 중요할 수 있습니다. 팀 환경에서는 “무조건 최신 고가 모델\"보다 “저비용 + 재현 가능한 워크플로\"가 더 실용적입니다. 핵심은, Claude Code UX를 유지하면서 백엔드를 교체하는 것입니다.\n방법 1) Ollama 이용 개념 Ollama는 로컬에서 오픈 모델을 구동하는 런타임입니다.\n즉, Anthropic의 Claude 모델을 직접 무료로 쓰는 방식이 아니라, Claude Code와 유사한 개발 플로우를 로컬 LLM으로 대체하는 접근입니다.\n준비 충분한 로컬 리소스(메모리/VRAM) Ollama 설치 코드 작업에 맞는 모델 선택 (qwen, llama, deepseek-coder 계열 등) 설치 # macOS (Homebrew) brew install ollama # Linux는 공식 설치 스크립트 또는 패키지 매니저로 설치 가장 쉬운 연동 (공식) ollama launch claude 위 명령은 Claude Code 연동에 필요한 설정 과정을 대화형으로 진행합니다.\n수동 환경 설정 예시 # .bashrc or.zshrc 파일에 등록, 수동 등록 export ANTHROPIC_BASE_URL=http://localhost:11434 export ANTHROPIC_AUTH_TOKEN=ollama export ANTHROPIC_MODEL=qwen3-coder 실행 예시:\nclaude --model \"$ANTHROPIC_MODEL\" 모델 선택 팁 코드 작업에서는 tool-use 성능과 긴 컨텍스트(예: 64K 이상)를 우선 확인 작은 모델은 저비용/저지연에 유리하지만, 복잡한 리팩터링 정확도는 낮아질 수 있음 팀 표준 모델 1개 + 빠른 보조 모델 1개로 운영하면 품질/비용 균형을 잡기 쉽습니다 Ollama의 Claude 지원 요약 Ollama v0.14.0 이상은 Anthropic Messages API를 구현해 Claude Code와 다른 Anthropic 클라이언트가 로컬 Ollama 모델을 그대로 사용할 수 있도록 합니다. 이 통합으로 스트리밍, 시스템 프롬프트, 툴 콜링, 확장된 thinking 토큰, 멀티모달 입력, 서브에이전트 오케스트레이션 등이 Claude 환경과 동일하게 작동하며, 기본 엔드포인트(http://localhost:11434)를 통해 Anthropic SDK와의 호환성도 유지됩니다. ollama launch claude 명령은 이 환경 변수/모델 설정을 자동으로 구성하는 단계를 감쌉니다.\ncloud 태그 모델 사용법 Ollama의 cloud 모델은 로컬 GPU가 부족해도 큰 모델을 사용할 수 있는 방식입니다.\nOllama 계정 로그인 ollama signin Claude Code에서 cloud 모델 지정 실행 claude --model glm-4.7:cloud 필요 시 ollama launch에서 cloud 모델 직접 지정 ollama launch claude --model glm-4.7:cloud 메모:\ncloud 모델은 보통 로컬 pull 없이 바로 사용 가능합니다. 모델명 suffix는 모델마다 다를 수 있으므로 (:cloud, -cloud), https://ollama.com/search?c=cloud에서 실제 이름을 확인하세요. 장단점 장점: 완전 로컬, 비용 예측 용이, 개인정보 통제에 유리 단점: 모델 품질/툴콜 안정성 편차, 로컬 머신 자원 소모 방법 2) free-claude-code 이용 (NVIDIA NIM / OpenRouter / LM Studio) 개념 free-claude-code 류 도구는 “Claude Code가 기대하는 인터페이스\"와 “다른 LLM 제공자 API” 사이를 중계하는 래퍼입니다.\nClaude Code 클라이언트는 기존처럼 사용 실제 모델 추론은 NIM/OpenRouter/LM Studio로 전달 설치 Claude Code 설정에 필요한 free-claude-code 캐시를 로컬에 clone .env.example를 .env로 복사해 기본 변수들을 채운 뒤 uv/pip 의존성을 설치 backend(providers)별 API 키/엔드포인트를 .env에 기록 git clone https://github.com/Alishahryar1/free-claude-code.git cd free-claude-code cp .env.example .env # fill ANTHROPIC_BASE_URL, API keys, MODEL overrides in .env pip install --upgrade pip pip install -r requirements.txt 공통 설정 흐름 초기 설정: free-claude-code setup 서버 실행: free-claude-code (기본 http://localhost:8082) Claude Code가 로컬 프록시를 보도록 환경변수 지정 export ANTHROPIC_AUTH_TOKEN=freecc export ANTHROPIC_BASE_URL=http://localhost:8082 모델을 즉시 지정하려면:\nexport ANTHROPIC_AUTH_TOKEN=freecc:open_router/openai/gpt-4o-mini 참고: 토큰 뒤에 :0.3처럼 temperature를 붙여서 실행 시점 제어도 가능합니다.\nProvider별 환경변수 예시 각 공급자별로 필요한 기본 환경변수를 아래처럼 설정해두면, free-claude-code 프록시가 해당 API로 요청을 포워딩합니다.\nOpenRouter export MODEL=open_router/openai/gpt-4o-mini export OPENROUTER_API_KEY= OpenRouter를 쓰려면 위처럼 MODEL 접두사를 open_router/로 두고, 오픈라우터 API 키를 함께 전달하면 됩니다.\nQuick start 체크리스트 (README 기준) 레포를 클론하고 .env.example을 .env로 복사한 다음 환경에 맞게 값들을 채우고 요구되는 pip/uv 의존성을 설치합니다. ANTHROPIC_BASE_URL을 http://localhost:8082로, ANTHROPIC_AUTH_TOKEN을 freecc로 설정한 뒤 :provider/model을 추가해 특정 모델로 고정합니다. uv run uvicorn server:app --host 0.0.0.0 --port 8082로 프록시 서버를 띄웁니다. 같은 환경변수로 claude 또는 VSCode 확장판을 실행해 Claude Code를 기동합니다. claude-pick 별칭을 이용해 .env를 바꾸지 않고도 제공자/모델 조합을 탐색합니다. 이 체크리스트는 README의 Clone \u0026 Configure 섹션 내용을 옮긴 것으로, 각 명령을 순서대로 실행해 설정을 끝내면 Claude Code가 로컬 free-claude-code 프록시를 통해 Anthropic 호환 모델을 이용합니다.\nNVIDIA NIM (recommended — 40 req/min free) export MODEL=nvidia_nim/stepfun-ai/step-3.5-flash export NVIDIA_NIM_API_KEY=nvapi-your-key-here export NIM_BASE_URL=https://api.stepfun.ai NVIDIA NIM은 nvidia_nim/ 접두사를 쓰고, NIM_BASE_URL로 엔드포인트를 설정하면 정해진 요청 속도로 무료 금액을 사용할 수 있습니다.\nLM Studio export MODEL=lmstudio/qwen2.5-coder:14b export LM_STUDIO_BASE_URL=http://127.0.0.1:1234/v1 LM Studio를 백엔드로 쓰려면 lmstudio/ 접두사와 로컬 서버 주소를 지정하고, 필요한 경우 프록시에서 API 키를 점검하세요.\nfree-claude-code 기능 uvicorn server:app 프록시를 통해 트래픽을 중개하며 Claude 특화 “사소한 요청\"을 걸러내고 reasoning_content/`` thinking 태그를 Claude Code에 맞게 다시 포맷합니다. MODEL={prefix}/{provider model} 형식으로 모델 전환을 강제하고, 접두사 오류는 프로바이더 호출 전에 검증 에러로 잡힙니다. 리포에는 Discord/Telegram 봇, 음성 노트 업로드 처리, 프록시의 동시성 제한 같은 헬퍼가 포함되어 있어 레이트 리밋을 관리할 수 있습니다. 실행 예시:\n# 서버 실행 free-claude-code 연결 테스트:\ncurl -s http://localhost:8082/health Claude Code 쪽 적용 포인트 ANTHROPIC_BASE_URL을 http://localhost:8082로 지정 ANTHROPIC_AUTH_TOKEN=freecc[:model] 패턴으로 모델 라우팅 스트리밍 모드 사용 시 timeout 값을 늘려 긴 코드 생성 중 끊김을 방지 .env 또는 셸 프로파일에 설정값을 저장하고, 팀 내 표준 이름을 통일 예시(.env):\nANTHROPIC_BASE_URL=http://localhost:8082 ANTHROPIC_AUTH_TOKEN=freecc:open_router/openai/gpt-4o-mini MODEL=open_router/openai/gpt-4o-mini OPENROUTER_API_KEY=... 참고 문서 free-claude-code README: https://github.com/Alishahryar1/free-claude-code?tab=readme-ov-file Ollama Claude Code integration: https://docs.ollama.com/integrations/claude-code Ollama docs: https://ollama.com/docs Claude Code CLI: https://www.anthropic.com/claude/docs/claude-code 운영 팁 OpenRouter는 모델별 단가/지연이 다르므로 작업 유형(리팩터링/테스트 생성/문서화)별 모델을 분리하면 비용을 줄일 수 있습니다. NIM은 기업 환경에서 성능/보안 정책을 맞추기 쉽습니다. LM Studio는 완전 로컬 테스트에 좋지만 대형 코드베이스 작업에서는 모델 크기와 컨텍스트 한계를 먼저 확인해야 합니다. 무엇을 선택할까 개인 로컬 실험: Ollama 또는 LM Studio 다양한 상용/오픈 모델 빠른 비교: OpenRouter 팀/기업 정책 중심 운영: NVIDIA NIM 결론적으로, “Claude Code 무료 플랜\"은 공식 무료 Claude 자체를 의미하기보다, Claude Code 사용 경험을 유지한 채 백엔드를 비용 효율적으로 대체하는 아키텍처 전략에 가깝습니다.\n트러블슈팅 401/403 오류: API 키 누락, provider 불일치, 잘못된 권한 스코프 확인 404 model not found: MODEL 접두사(open_router/, nvidia_nim/, lmstudio/) 오타 확인 connection refused: 로컬 서버(Ollama/LM Studio/래퍼) 미실행 또는 포트 오타 claude에서 모델 선택이 꼬일 때: claude-pick 별칭으로 모델 재선택 후 재시도 응답 지연/타임아웃: 모델 크기 축소, 컨텍스트 길이 조정, timeout 상향 주의사항 각 서비스의 이용약관/요금/레이트리밋은 수시로 바뀌므로 배포 전 최신 문서를 다시 확인하세요. 코드/비밀값이 외부 API로 전송될 수 있으므로, 저장소 필터링(.env, 키, 고객 데이터) 정책을 먼저 적용하세요. 팀 공용 환경에서는 “허용 모델 목록 + 최대 토큰 + 일일 예산\"을 강제하는 가드레일을 두는 것이 안전합니다. ","wordCount":"969","inLanguage":"en","datePublished":"2026-02-23T00:00:00+09:00","dateModified":"2026-02-23T00:00:00+09:00","author":{"@type":"Person","name":"Byung Kyu KIM"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://cdecl.github.io/devops/claude-code-free-plan-usage/"},"publisher":{"@type":"Organization","name":"cdeclog","logo":{"@type":"ImageObject","url":"https://cdecl.github.io/favicon.ico"}}}</script></head><body id=top><header class=header><nav class=nav><div class=logo><a href=https://cdecl.github.io/ accesskey=h title="cdeclog (Alt + H)">cdeclog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://cdecl.github.io/dev/ title=Dev><span>Dev</span></a></li><li><a href=https://cdecl.github.io/devops/ title=DevOps><span>DevOps</span></a></li><li><a href=https://cdecl.github.io/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://cdecl.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://cdecl.github.io/tags/ title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://cdecl.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://cdecl.github.io/devops/>Devops</a></div><h1 class="post-title entry-hint-parent">Claude Code 무료 플랜 활용 가이드 (Ollama, free-claude-code)</h1><div class=post-meta><span title='2026-02-23 00:00:00 +0900 KST'>February 23, 2026</span>&nbsp;·&nbsp;<span>Byung Kyu KIM</span></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#%ec%99%9c-%eb%ac%b4%eb%a3%8c-%ed%94%8c%eb%9e%9c-%ea%b5%ac%ec%84%b1%ec%9d%b4-%ed%95%84%ec%9a%94%ed%95%9c%ea%b0%80 aria-label="왜 &ldquo;무료 플랜&rdquo; 구성이 필요한가">왜 &ldquo;무료 플랜&rdquo; 구성이 필요한가</a><ul><li><a href=#%eb%b0%a9%eb%b2%95-1-ollama-%ec%9d%b4%ec%9a%a9 aria-label="방법 1) Ollama 이용">방법 1) Ollama 이용</a><ul><li><a href=#%ea%b0%9c%eb%85%90 aria-label=개념>개념</a></li><li><a href=#%ec%a4%80%eb%b9%84 aria-label=준비>준비</a></li><li><a href=#%ec%84%a4%ec%b9%98 aria-label=설치>설치</a></li><li><a href=#%ea%b0%80%ec%9e%a5-%ec%89%ac%ec%9a%b4-%ec%97%b0%eb%8f%99-%ea%b3%b5%ec%8b%9d aria-label="가장 쉬운 연동 (공식)">가장 쉬운 연동 (공식)</a></li><li><a href=#%ec%88%98%eb%8f%99-%ed%99%98%ea%b2%bd-%ec%84%a4%ec%a0%95-%ec%98%88%ec%8b%9c aria-label="수동 환경 설정 예시">수동 환경 설정 예시</a></li><li><a href=#%eb%aa%a8%eb%8d%b8-%ec%84%a0%ed%83%9d-%ed%8c%81 aria-label="모델 선택 팁">모델 선택 팁</a></li><li><a href=#ollama%ec%9d%98-claude-%ec%a7%80%ec%9b%90-%ec%9a%94%ec%95%bd aria-label="Ollama의 Claude 지원 요약">Ollama의 Claude 지원 요약</a></li><li><a href=#cloud-%ed%83%9c%ea%b7%b8-%eb%aa%a8%eb%8d%b8-%ec%82%ac%ec%9a%a9%eb%b2%95 aria-label="cloud 태그 모델 사용법">cloud 태그 모델 사용법</a></li><li><a href=#%ec%9e%a5%eb%8b%a8%ec%a0%90 aria-label=장단점>장단점</a></li></ul></li><li><a href=#%eb%b0%a9%eb%b2%95-2-free-claude-code-%ec%9d%b4%ec%9a%a9-nvidia-nim--openrouter--lm-studio aria-label="방법 2) free-claude-code 이용 (NVIDIA NIM / OpenRouter / LM Studio)">방법 2) free-claude-code 이용 (NVIDIA NIM / OpenRouter / LM Studio)</a><ul><li><a href=#%ea%b0%9c%eb%85%90-1 aria-label=개념>개념</a></li><li><a href=#%ec%84%a4%ec%b9%98-1 aria-label=설치>설치</a></li><li><a href=#%ea%b3%b5%ed%86%b5-%ec%84%a4%ec%a0%95-%ed%9d%90%eb%a6%84 aria-label="공통 설정 흐름">공통 설정 흐름</a></li><li><a href=#provider%eb%b3%84-%ed%99%98%ea%b2%bd%eb%b3%80%ec%88%98-%ec%98%88%ec%8b%9c aria-label="Provider별 환경변수 예시">Provider별 환경변수 예시</a></li><li><a href=#openrouter aria-label=OpenRouter>OpenRouter</a></li><li><a href=#quick-start-%ec%b2%b4%ed%81%ac%eb%a6%ac%ec%8a%a4%ed%8a%b8-readme-%ea%b8%b0%ec%a4%80 aria-label="Quick start 체크리스트 (README 기준)">Quick start 체크리스트 (README 기준)</a></li><li><a href=#nvidia-nim-recommended--40-reqmin-free aria-label="NVIDIA NIM (recommended — 40 req/min free)">NVIDIA NIM (recommended — 40 req/min free)</a></li><li><a href=#lm-studio aria-label="LM Studio">LM Studio</a></li><li><a href=#free-claude-code-%ea%b8%b0%eb%8a%a5 aria-label="free-claude-code 기능">free-claude-code 기능</a></li><li><a href=#claude-code-%ec%aa%bd-%ec%a0%81%ec%9a%a9-%ed%8f%ac%ec%9d%b8%ed%8a%b8 aria-label="Claude Code 쪽 적용 포인트">Claude Code 쪽 적용 포인트</a></li></ul></li></ul></li><li><a href=#%ec%b0%b8%ea%b3%a0-%eb%ac%b8%ec%84%9c aria-label="참고 문서">참고 문서</a></li><li><a href=#%ec%9a%b4%ec%98%81-%ed%8c%81 aria-label="운영 팁">운영 팁</a></li><li><a href=#%eb%ac%b4%ec%97%87%ec%9d%84-%ec%84%a0%ed%83%9d%ed%95%a0%ea%b9%8c aria-label="무엇을 선택할까">무엇을 선택할까</a></li><li><a href=#%ed%8a%b8%eb%9f%ac%eb%b8%94%ec%8a%88%ed%8c%85 aria-label=트러블슈팅>트러블슈팅</a></li><li><a href=#%ec%a3%bc%ec%9d%98%ec%82%ac%ed%95%ad aria-label=주의사항>주의사항</a></li></ul></div></details></div><div class=post-content><p>Claude Code를 쓰고 싶은데 유료 API 비용이 부담될 때, 실무에서는 보통 두 가지 경로를 사용합니다.</p><ol><li><code>Ollama</code> 기반 로컬 모델 연결</li><li><code>free-claude-code</code> 같은 호환 레이어를 통해 <code>NVIDIA NIM</code>, <code>OpenRouter</code>, <code>LM Studio</code> 백엔드 연결</li></ol><p>이 글은 각 방식의 배경, 설치/설정 방법, 그리고 운영 시 주의점을 정리합니다.</p><h2 id=왜-무료-플랜-구성이-필요한가>왜 &ldquo;무료 플랜&rdquo; 구성이 필요한가<a hidden class=anchor aria-hidden=true href=#왜-무료-플랜-구성이-필요한가>#</a></h2><ul><li>코드 에이전트는 반복 호출이 많아 토큰 비용이 빠르게 증가합니다.</li><li>개인 프로젝트나 학습 단계에서는 응답 품질보다 비용 상한이 더 중요할 수 있습니다.</li><li>팀 환경에서는 &ldquo;무조건 최신 고가 모델"보다 &ldquo;저비용 + 재현 가능한 워크플로"가 더 실용적입니다.</li></ul><p>핵심은, Claude Code UX를 유지하면서 백엔드를 교체하는 것입니다.</p><h3 id=방법-1-ollama-이용>방법 1) Ollama 이용<a hidden class=anchor aria-hidden=true href=#방법-1-ollama-이용>#</a></h3><h4 id=개념>개념<a hidden class=anchor aria-hidden=true href=#개념>#</a></h4><p>Ollama는 로컬에서 오픈 모델을 구동하는 런타임입니다.<br>즉, Anthropic의 Claude 모델을 직접 무료로 쓰는 방식이 아니라, Claude Code와 유사한 개발 플로우를 로컬 LLM으로 대체하는 접근입니다.</p><h4 id=준비>준비<a hidden class=anchor aria-hidden=true href=#준비>#</a></h4><ul><li>충분한 로컬 리소스(메모리/VRAM)</li><li>Ollama 설치</li><li>코드 작업에 맞는 모델 선택 (<code>qwen</code>, <code>llama</code>, <code>deepseek-coder</code> 계열 등)</li></ul><h4 id=설치>설치<a hidden class=anchor aria-hidden=true href=#설치>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#6272a4># macOS (Homebrew)</span>
</span></span><span style=display:flex><span>brew install ollama
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># Linux는 공식 설치 스크립트 또는 패키지 매니저로 설치</span>
</span></span></code></pre></div><h4 id=가장-쉬운-연동-공식>가장 쉬운 연동 (공식)<a hidden class=anchor aria-hidden=true href=#가장-쉬운-연동-공식>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class=language-bash data-lang=bash><span style=display:flex><span>ollama launch claude
</span></span></code></pre></div><p>위 명령은 Claude Code 연동에 필요한 설정 과정을 대화형으로 진행합니다.</p><h4 id=수동-환경-설정-예시>수동 환경 설정 예시<a hidden class=anchor aria-hidden=true href=#수동-환경-설정-예시>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#6272a4># .bashrc or.zshrc 파일에 등록, 수동 등록 </span>
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>export</span> <span style=color:#8be9fd;font-style:italic>ANTHROPIC_BASE_URL</span><span style=color:#ff79c6>=</span>http://localhost:11434
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>export</span> <span style=color:#8be9fd;font-style:italic>ANTHROPIC_AUTH_TOKEN</span><span style=color:#ff79c6>=</span>ollama
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>export</span> <span style=color:#8be9fd;font-style:italic>ANTHROPIC_MODEL</span><span style=color:#ff79c6>=</span>qwen3-coder
</span></span></code></pre></div><p>실행 예시:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class=language-bash data-lang=bash><span style=display:flex><span>claude --model <span style=color:#f1fa8c>&#34;</span><span style=color:#8be9fd;font-style:italic>$ANTHROPIC_MODEL</span><span style=color:#f1fa8c>&#34;</span>
</span></span></code></pre></div><h4 id=모델-선택-팁>모델 선택 팁<a hidden class=anchor aria-hidden=true href=#모델-선택-팁>#</a></h4><ul><li>코드 작업에서는 tool-use 성능과 긴 컨텍스트(예: 64K 이상)를 우선 확인</li><li>작은 모델은 저비용/저지연에 유리하지만, 복잡한 리팩터링 정확도는 낮아질 수 있음</li><li>팀 표준 모델 1개 + 빠른 보조 모델 1개로 운영하면 품질/비용 균형을 잡기 쉽습니다</li></ul><h4 id=ollama의-claude-지원-요약>Ollama의 Claude 지원 요약<a hidden class=anchor aria-hidden=true href=#ollama의-claude-지원-요약>#</a></h4><p>Ollama v0.14.0 이상은 Anthropic Messages API를 구현해 Claude Code와 다른 Anthropic 클라이언트가 로컬 Ollama 모델을 그대로 사용할 수 있도록 합니다. 이 통합으로 스트리밍, 시스템 프롬프트, 툴 콜링, 확장된 <code>thinking</code> 토큰, 멀티모달 입력, 서브에이전트 오케스트레이션 등이 Claude 환경과 동일하게 작동하며, 기본 엔드포인트(<code>http://localhost:11434</code>)를 통해 Anthropic SDK와의 호환성도 유지됩니다. <code>ollama launch claude</code> 명령은 이 환경 변수/모델 설정을 자동으로 구성하는 단계를 감쌉니다.</p><h4 id=cloud-태그-모델-사용법><code>cloud</code> 태그 모델 사용법<a hidden class=anchor aria-hidden=true href=#cloud-태그-모델-사용법>#</a></h4><p>Ollama의 cloud 모델은 로컬 GPU가 부족해도 큰 모델을 사용할 수 있는 방식입니다.</p><ol><li>Ollama 계정 로그인</li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class=language-bash data-lang=bash><span style=display:flex><span>ollama signin
</span></span></code></pre></div><ol start=2><li>Claude Code에서 cloud 모델 지정 실행</li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class=language-bash data-lang=bash><span style=display:flex><span>claude --model glm-4.7:cloud
</span></span></code></pre></div><ol start=3><li>필요 시 <code>ollama launch</code>에서 cloud 모델 직접 지정</li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class=language-bash data-lang=bash><span style=display:flex><span>ollama launch claude --model glm-4.7:cloud
</span></span></code></pre></div><p>메모:</p><ul><li>cloud 모델은 보통 로컬 <code>pull</code> 없이 바로 사용 가능합니다.</li><li>모델명 suffix는 모델마다 다를 수 있으므로 (<code>:cloud</code>, <code>-cloud</code>), <code>https://ollama.com/search?c=cloud</code>에서 실제 이름을 확인하세요.</li></ul><h4 id=장단점>장단점<a hidden class=anchor aria-hidden=true href=#장단점>#</a></h4><ul><li>장점: 완전 로컬, 비용 예측 용이, 개인정보 통제에 유리</li><li>단점: 모델 품질/툴콜 안정성 편차, 로컬 머신 자원 소모</li></ul><h3 id=방법-2-free-claude-code-이용-nvidia-nim--openrouter--lm-studio>방법 2) free-claude-code 이용 (NVIDIA NIM / OpenRouter / LM Studio)<a hidden class=anchor aria-hidden=true href=#방법-2-free-claude-code-이용-nvidia-nim--openrouter--lm-studio>#</a></h3><h4 id=개념-1>개념<a hidden class=anchor aria-hidden=true href=#개념-1>#</a></h4><p><code>free-claude-code</code> 류 도구는 &ldquo;Claude Code가 기대하는 인터페이스"와 &ldquo;다른 LLM 제공자 API&rdquo; 사이를 중계하는 래퍼입니다.</p><ul><li>Claude Code 클라이언트는 기존처럼 사용</li><li>실제 모델 추론은 NIM/OpenRouter/LM Studio로 전달</li></ul><h4 id=설치-1>설치<a hidden class=anchor aria-hidden=true href=#설치-1>#</a></h4><ul><li>Claude Code 설정에 필요한 <code>free-claude-code</code> 캐시를 로컬에 clone</li><li><code>.env.example</code>를 <code>.env</code>로 복사해 기본 변수들을 채운 뒤 <code>uv</code>/<code>pip</code> 의존성을 설치</li><li>backend(providers)별 API 키/엔드포인트를 <code>.env</code>에 기록</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class=language-bash data-lang=bash><span style=display:flex><span>git clone https://github.com/Alishahryar1/free-claude-code.git
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>cd</span> free-claude-code
</span></span><span style=display:flex><span>cp .env.example .env
</span></span><span style=display:flex><span><span style=color:#6272a4># fill ANTHROPIC_BASE_URL, API keys, MODEL overrides in .env</span>
</span></span><span style=display:flex><span>pip install --upgrade pip
</span></span><span style=display:flex><span>pip install -r requirements.txt
</span></span></code></pre></div><h4 id=공통-설정-흐름>공통 설정 흐름<a hidden class=anchor aria-hidden=true href=#공통-설정-흐름>#</a></h4><ol><li>초기 설정: <code>free-claude-code setup</code></li><li>서버 실행: <code>free-claude-code</code> (기본 <code>http://localhost:8082</code>)</li><li>Claude Code가 로컬 프록시를 보도록 환경변수 지정</li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>export</span> <span style=color:#8be9fd;font-style:italic>ANTHROPIC_AUTH_TOKEN</span><span style=color:#ff79c6>=</span>freecc
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>export</span> <span style=color:#8be9fd;font-style:italic>ANTHROPIC_BASE_URL</span><span style=color:#ff79c6>=</span>http://localhost:8082
</span></span></code></pre></div><p>모델을 즉시 지정하려면:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>export</span> <span style=color:#8be9fd;font-style:italic>ANTHROPIC_AUTH_TOKEN</span><span style=color:#ff79c6>=</span>freecc:open_router/openai/gpt-4o-mini
</span></span></code></pre></div><p>참고: 토큰 뒤에 <code>:0.3</code>처럼 temperature를 붙여서 실행 시점 제어도 가능합니다.</p><h4 id=provider별-환경변수-예시>Provider별 환경변수 예시<a hidden class=anchor aria-hidden=true href=#provider별-환경변수-예시>#</a></h4><p>각 공급자별로 필요한 기본 환경변수를 아래처럼 설정해두면, <code>free-claude-code</code> 프록시가 해당 API로 요청을 포워딩합니다.</p><h4 id=openrouter>OpenRouter<a hidden class=anchor aria-hidden=true href=#openrouter>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>export</span> <span style=color:#8be9fd;font-style:italic>MODEL</span><span style=color:#ff79c6>=</span>open_router/openai/gpt-4o-mini
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>export</span> <span style=color:#8be9fd;font-style:italic>OPENROUTER_API_KEY</span><span style=color:#ff79c6>=</span>&lt;your_key&gt;
</span></span></code></pre></div><p>OpenRouter를 쓰려면 위처럼 <code>MODEL</code> 접두사를 <code>open_router/</code>로 두고, 오픈라우터 API 키를 함께 전달하면 됩니다.</p><h4 id=quick-start-체크리스트-readme-기준>Quick start 체크리스트 (README 기준)<a hidden class=anchor aria-hidden=true href=#quick-start-체크리스트-readme-기준>#</a></h4><ol><li>레포를 클론하고 <code>.env.example</code>을 <code>.env</code>로 복사한 다음 환경에 맞게 값들을 채우고 요구되는 <code>pip</code>/<code>uv</code> 의존성을 설치합니다.</li><li><code>ANTHROPIC_BASE_URL</code>을 <code>http://localhost:8082</code>로, <code>ANTHROPIC_AUTH_TOKEN</code>을 <code>freecc</code>로 설정한 뒤 <code>:provider/model</code>을 추가해 특정 모델로 고정합니다.</li><li><code>uv run uvicorn server:app --host 0.0.0.0 --port 8082</code>로 프록시 서버를 띄웁니다.</li><li>같은 환경변수로 <code>claude</code> 또는 VSCode 확장판을 실행해 Claude Code를 기동합니다.</li><li><code>claude-pick</code> 별칭을 이용해 <code>.env</code>를 바꾸지 않고도 제공자/모델 조합을 탐색합니다.</li></ol><p>이 체크리스트는 README의 Clone & Configure 섹션 내용을 옮긴 것으로, 각 명령을 순서대로 실행해 설정을 끝내면 Claude Code가 로컬 <code>free-claude-code</code> 프록시를 통해 Anthropic 호환 모델을 이용합니다.</p><h4 id=nvidia-nim-recommended--40-reqmin-free>NVIDIA NIM (recommended — 40 req/min free)<a hidden class=anchor aria-hidden=true href=#nvidia-nim-recommended--40-reqmin-free>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>export</span> <span style=color:#8be9fd;font-style:italic>MODEL</span><span style=color:#ff79c6>=</span>nvidia_nim/stepfun-ai/step-3.5-flash
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>export</span> <span style=color:#8be9fd;font-style:italic>NVIDIA_NIM_API_KEY</span><span style=color:#ff79c6>=</span>nvapi-your-key-here
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>export</span> <span style=color:#8be9fd;font-style:italic>NIM_BASE_URL</span><span style=color:#ff79c6>=</span>https://api.stepfun.ai
</span></span></code></pre></div><p>NVIDIA NIM은 <code>nvidia_nim/</code> 접두사를 쓰고, <code>NIM_BASE_URL</code>로 엔드포인트를 설정하면 정해진 요청 속도로 무료 금액을 사용할 수 있습니다.</p><h4 id=lm-studio>LM Studio<a hidden class=anchor aria-hidden=true href=#lm-studio>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>export</span> <span style=color:#8be9fd;font-style:italic>MODEL</span><span style=color:#ff79c6>=</span>lmstudio/qwen2.5-coder:14b
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>export</span> <span style=color:#8be9fd;font-style:italic>LM_STUDIO_BASE_URL</span><span style=color:#ff79c6>=</span>http://127.0.0.1:1234/v1
</span></span></code></pre></div><p>LM Studio를 백엔드로 쓰려면 <code>lmstudio/</code> 접두사와 로컬 서버 주소를 지정하고, 필요한 경우 프록시에서 API 키를 점검하세요.</p><h4 id=free-claude-code-기능>free-claude-code 기능<a hidden class=anchor aria-hidden=true href=#free-claude-code-기능>#</a></h4><ul><li><code>uvicorn server:app</code> 프록시를 통해 트래픽을 중개하며 Claude 특화 &ldquo;사소한 요청"을 걸러내고 <code>reasoning_content</code>/`` thinking 태그를 Claude Code에 맞게 다시 포맷합니다.</li><li><code>MODEL={prefix}/{provider model}</code> 형식으로 모델 전환을 강제하고, 접두사 오류는 프로바이더 호출 전에 검증 에러로 잡힙니다.</li><li>리포에는 Discord/Telegram 봇, 음성 노트 업로드 처리, 프록시의 동시성 제한 같은 헬퍼가 포함되어 있어 레이트 리밋을 관리할 수 있습니다.</li></ul><p>실행 예시:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#6272a4># 서버 실행</span>
</span></span><span style=display:flex><span>free-claude-code
</span></span></code></pre></div><p>연결 테스트:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class=language-bash data-lang=bash><span style=display:flex><span>curl -s http://localhost:8082/health
</span></span></code></pre></div><h4 id=claude-code-쪽-적용-포인트>Claude Code 쪽 적용 포인트<a hidden class=anchor aria-hidden=true href=#claude-code-쪽-적용-포인트>#</a></h4><ul><li><code>ANTHROPIC_BASE_URL</code>을 <code>http://localhost:8082</code>로 지정</li><li><code>ANTHROPIC_AUTH_TOKEN=freecc[:model]</code> 패턴으로 모델 라우팅</li><li>스트리밍 모드 사용 시 timeout 값을 늘려 긴 코드 생성 중 끊김을 방지</li><li><code>.env</code> 또는 셸 프로파일에 설정값을 저장하고, 팀 내 표준 이름을 통일</li></ul><p>예시(<code>.env</code>):</p><pre tabindex=0><code class=language-dotenv data-lang=dotenv>ANTHROPIC_BASE_URL=http://localhost:8082
ANTHROPIC_AUTH_TOKEN=freecc:open_router/openai/gpt-4o-mini
MODEL=open_router/openai/gpt-4o-mini
OPENROUTER_API_KEY=...
</code></pre><h2 id=참고-문서>참고 문서<a hidden class=anchor aria-hidden=true href=#참고-문서>#</a></h2><ul><li><code>free-claude-code</code> README: <a href="https://github.com/Alishahryar1/free-claude-code?tab=readme-ov-file">https://github.com/Alishahryar1/free-claude-code?tab=readme-ov-file</a></li><li>Ollama Claude Code integration: <a href=https://docs.ollama.com/integrations/claude-code>https://docs.ollama.com/integrations/claude-code</a></li><li>Ollama docs: <a href=https://ollama.com/docs>https://ollama.com/docs</a></li><li>Claude Code CLI: <a href=https://www.anthropic.com/claude/docs/claude-code>https://www.anthropic.com/claude/docs/claude-code</a></li></ul><h2 id=운영-팁>운영 팁<a hidden class=anchor aria-hidden=true href=#운영-팁>#</a></h2><ul><li>OpenRouter는 모델별 단가/지연이 다르므로 작업 유형(리팩터링/테스트 생성/문서화)별 모델을 분리하면 비용을 줄일 수 있습니다.</li><li>NIM은 기업 환경에서 성능/보안 정책을 맞추기 쉽습니다.</li><li>LM Studio는 완전 로컬 테스트에 좋지만 대형 코드베이스 작업에서는 모델 크기와 컨텍스트 한계를 먼저 확인해야 합니다.</li></ul><h2 id=무엇을-선택할까>무엇을 선택할까<a hidden class=anchor aria-hidden=true href=#무엇을-선택할까>#</a></h2><ul><li>개인 로컬 실험: <code>Ollama</code> 또는 <code>LM Studio</code></li><li>다양한 상용/오픈 모델 빠른 비교: <code>OpenRouter</code></li><li>팀/기업 정책 중심 운영: <code>NVIDIA NIM</code></li></ul><p>결론적으로, &ldquo;Claude Code 무료 플랜"은 공식 무료 Claude 자체를 의미하기보다, Claude Code 사용 경험을 유지한 채 백엔드를 비용 효율적으로 대체하는 아키텍처 전략에 가깝습니다.</p><h2 id=트러블슈팅>트러블슈팅<a hidden class=anchor aria-hidden=true href=#트러블슈팅>#</a></h2><ul><li><code>401/403</code> 오류: API 키 누락, provider 불일치, 잘못된 권한 스코프 확인</li><li><code>404 model not found</code>: <code>MODEL</code> 접두사(<code>open_router/</code>, <code>nvidia_nim/</code>, <code>lmstudio/</code>) 오타 확인</li><li><code>connection refused</code>: 로컬 서버(Ollama/LM Studio/래퍼) 미실행 또는 포트 오타</li><li><code>claude</code>에서 모델 선택이 꼬일 때: <code>claude-pick</code> 별칭으로 모델 재선택 후 재시도</li><li>응답 지연/타임아웃: 모델 크기 축소, 컨텍스트 길이 조정, timeout 상향</li></ul><h2 id=주의사항>주의사항<a hidden class=anchor aria-hidden=true href=#주의사항>#</a></h2><ul><li>각 서비스의 이용약관/요금/레이트리밋은 수시로 바뀌므로 배포 전 최신 문서를 다시 확인하세요.</li><li>코드/비밀값이 외부 API로 전송될 수 있으므로, 저장소 필터링(<code>.env</code>, 키, 고객 데이터) 정책을 먼저 적용하세요.</li><li>팀 공용 환경에서는 &ldquo;허용 모델 목록 + 최대 토큰 + 일일 예산"을 강제하는 가드레일을 두는 것이 안전합니다.</li></ul></div><footer class=post-footer><ul class=post-tags><li><a href=https://cdecl.github.io/tags/claude/>Claude</a></li><li><a href=https://cdecl.github.io/tags/claude-code/>Claude-Code</a></li><li><a href=https://cdecl.github.io/tags/ollama/>Ollama</a></li><li><a href=https://cdecl.github.io/tags/openrouter/>Openrouter</a></li><li><a href=https://cdecl.github.io/tags/nvidia-nim/>Nvidia-Nim</a></li><li><a href=https://cdecl.github.io/tags/lm-studio/>Lm-Studio</a></li><li><a href=https://cdecl.github.io/tags/ai-agent/>Ai-Agent</a></li><li><a href=https://cdecl.github.io/tags/devops/>Devops</a></li></ul></footer><script src=https://giscus.app/client.js data-repo=cdecl/cdecl.github.io data-repo-id="MDEwOlJlcG9zaXRvcnkzNDk1ODUyNjg=" data-category=General data-category-id=DIC_kwDOFNY_dM4C1XMk data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=transparent_dark data-lang=ko crossorigin=anonymous async></script></article></main><footer class=footer><span>&copy; 2026 <a href=https://cdecl.github.io/>cdeclog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");if(menu){const e=localStorage.getItem("menu-scroll-position");e&&(menu.scrollLeft=parseInt(e,10)),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}}document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{const e=document.querySelector("html");e.dataset.theme==="dark"?(e.dataset.theme="light",localStorage.setItem("pref-theme","light")):(e.dataset.theme="dark",localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>