<!doctype html><html lang=en dir=auto data-theme=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>2026 글로벌 LLM 생태계 비교: 파운데이션 모델부터 인프라 서비스까지 | cdeclog</title><meta name=keywords content="ai,llm,deepseek,openai,gemini,claude,devops"><meta name=description content="2026년 현재 LLM 시장은 모델을 직접 학습시켜 배포하는 파운데이션 모델 제공자(Builders) 와, 이 모델들을 기업 및 개발자가 쉽게 도입·최적화할 수 있도록 돕는 인프라 및 통합 서비스 제공자(Enablers) 로 생태계가 양분되어 있습니다.
북미의 프론티어 모델과 중국의 고효율 모델들이 치열하게 경쟁하는 가운데, Provider 관점에서 각 모델의 세부 특징과 인프라 서비스를 총정리합니다.

1. 파운데이션 모델 생태계 (Builders): 북미 vs 중국
LLM의 원천 지능을 제공하는 기업들입니다.
북미는 범용적 에이전트와 멀티모달에, 중국은 극강의 가성비와 오픈소스 생태계에 집중하고 있습니다."><meta name=author content="Byung Kyu KIM"><link rel=canonical href=https://cdecl.github.io/devops/ai-models-comparison/><link crossorigin=anonymous href=/assets/css/stylesheet.f939c4ffefb264e6fe85e04352266f79db6bb1303c8e16ae9b6064c1247b5e32.css integrity="sha256-+TnE/++yZOb+heBDUiZvedtrsTA8jhaum2BkwSR7XjI=" rel="preload stylesheet" as=style><link rel=icon href=https://cdecl.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://cdecl.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://cdecl.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://cdecl.github.io/apple-touch-icon.png><link rel=mask-icon href=https://cdecl.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://cdecl.github.io/devops/ai-models-comparison/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51);color-scheme:dark}.list{background:var(--theme)}.toc{background:var(--entry)}}@media(prefers-color-scheme:light){.list::-webkit-scrollbar-thumb{border-color:var(--code-bg)}}</style></noscript><script>localStorage.getItem("pref-theme")==="dark"?document.querySelector("html").dataset.theme="dark":localStorage.getItem("pref-theme")==="light"?document.querySelector("html").dataset.theme="light":window.matchMedia("(prefers-color-scheme: dark)").matches?document.querySelector("html").dataset.theme="dark":document.querySelector("html").dataset.theme="light"</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-VQQHHYPN7K"></script><script>var doNotTrack=!1,dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes";if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-VQQHHYPN7K")}</script><meta property="og:url" content="https://cdecl.github.io/devops/ai-models-comparison/"><meta property="og:site_name" content="cdeclog"><meta property="og:title" content="2026 글로벌 LLM 생태계 비교: 파운데이션 모델부터 인프라 서비스까지"><meta property="og:description" content="2026년 현재 LLM 시장은 모델을 직접 학습시켜 배포하는 파운데이션 모델 제공자(Builders) 와, 이 모델들을 기업 및 개발자가 쉽게 도입·최적화할 수 있도록 돕는 인프라 및 통합 서비스 제공자(Enablers) 로 생태계가 양분되어 있습니다.
북미의 프론티어 모델과 중국의 고효율 모델들이 치열하게 경쟁하는 가운데, Provider 관점에서 각 모델의 세부 특징과 인프라 서비스를 총정리합니다.
1. 파운데이션 모델 생태계 (Builders): 북미 vs 중국 LLM의 원천 지능을 제공하는 기업들입니다.
북미는 범용적 에이전트와 멀티모달에, 중국은 극강의 가성비와 오픈소스 생태계에 집중하고 있습니다."><meta property="og:locale" content="ko-kr"><meta property="og:type" content="article"><meta property="article:section" content="devops"><meta property="article:published_time" content="2026-02-25T00:00:00+09:00"><meta property="article:modified_time" content="2026-02-25T00:00:00+09:00"><meta property="article:tag" content="Ai"><meta property="article:tag" content="Llm"><meta property="article:tag" content="Deepseek"><meta property="article:tag" content="Openai"><meta property="article:tag" content="Gemini"><meta property="article:tag" content="Claude"><meta name=twitter:card content="summary"><meta name=twitter:title content="2026 글로벌 LLM 생태계 비교: 파운데이션 모델부터 인프라 서비스까지"><meta name=twitter:description content="2026년 현재 LLM 시장은 모델을 직접 학습시켜 배포하는 파운데이션 모델 제공자(Builders) 와, 이 모델들을 기업 및 개발자가 쉽게 도입·최적화할 수 있도록 돕는 인프라 및 통합 서비스 제공자(Enablers) 로 생태계가 양분되어 있습니다.
북미의 프론티어 모델과 중국의 고효율 모델들이 치열하게 경쟁하는 가운데, Provider 관점에서 각 모델의 세부 특징과 인프라 서비스를 총정리합니다.

1. 파운데이션 모델 생태계 (Builders): 북미 vs 중국
LLM의 원천 지능을 제공하는 기업들입니다.
북미는 범용적 에이전트와 멀티모달에, 중국은 극강의 가성비와 오픈소스 생태계에 집중하고 있습니다."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Devops","item":"https://cdecl.github.io/devops/"},{"@type":"ListItem","position":2,"name":"2026 글로벌 LLM 생태계 비교: 파운데이션 모델부터 인프라 서비스까지","item":"https://cdecl.github.io/devops/ai-models-comparison/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"2026 글로벌 LLM 생태계 비교: 파운데이션 모델부터 인프라 서비스까지","name":"2026 글로벌 LLM 생태계 비교: 파운데이션 모델부터 인프라 서비스까지","description":"2026년 현재 LLM 시장은 모델을 직접 학습시켜 배포하는 파운데이션 모델 제공자(Builders) 와, 이 모델들을 기업 및 개발자가 쉽게 도입·최적화할 수 있도록 돕는 인프라 및 통합 서비스 제공자(Enablers) 로 생태계가 양분되어 있습니다.\n북미의 프론티어 모델과 중국의 고효율 모델들이 치열하게 경쟁하는 가운데, Provider 관점에서 각 모델의 세부 특징과 인프라 서비스를 총정리합니다.\n1. 파운데이션 모델 생태계 (Builders): 북미 vs 중국 LLM의 원천 지능을 제공하는 기업들입니다.\n북미는 범용적 에이전트와 멀티모달에, 중국은 극강의 가성비와 오픈소스 생태계에 집중하고 있습니다.\n","keywords":["ai","llm","deepseek","openai","gemini","claude","devops"],"articleBody":"2026년 현재 LLM 시장은 모델을 직접 학습시켜 배포하는 파운데이션 모델 제공자(Builders) 와, 이 모델들을 기업 및 개발자가 쉽게 도입·최적화할 수 있도록 돕는 인프라 및 통합 서비스 제공자(Enablers) 로 생태계가 양분되어 있습니다.\n북미의 프론티어 모델과 중국의 고효율 모델들이 치열하게 경쟁하는 가운데, Provider 관점에서 각 모델의 세부 특징과 인프라 서비스를 총정리합니다.\n1. 파운데이션 모델 생태계 (Builders): 북미 vs 중국 LLM의 원천 지능을 제공하는 기업들입니다.\n북미는 범용적 에이전트와 멀티모달에, 중국은 극강의 가성비와 오픈소스 생태계에 집중하고 있습니다.\n지역 Provider 대표 모델 핵심 특징 (추론 / Tool / Vision) 북미 OpenAI o3 / GPT-5 추론: o3의 사고의 연쇄(CoT) 알고리즘 탑재 Tool: 자율 컴퓨팅을 수행하는 ‘Operator’ 에이전트 Google Gemini 3.0 Vision: 실시간 영상 및 오디오 프레임 동시 분석 특징: 200만 토큰 이상의 초장문 컨텍스트 윈도우 Anthropic Claude 4.5 Tool: 컴퓨터 화면과 마우스를 제어하는 ‘Computer Use’ 특징: 가장 뛰어난 문서 구조 해석 및 안전성(거짓 정보 억제) Meta Llama 4 특징: 온프레미스 구축이 가능한 최고 성능의 오픈소스 모델 추론: 400B 파라미터급 모델의 뛰어난 범용 성능 중국 DeepSeek V3 / R1 추론: R1의 내부 사고 과정을 투명하게 공개하는 추론 모드 특징: API 비용이 북미 모델 대비 최대 1/10 수준의 극강 가성비 Alibaba Qwen 2.5/3 Vision: 영수증·설계도면 등의 다국어 OCR 인식에 독보적 Tool: 중국 및 아시아권 이커머스/물류 API 통합에 최적화 Zhipu AI GLM-5 Vision: 고해상도 이미지 및 비디오 분석 특징: 중국 내 가장 범용적인 AI 생태계 Moonshot Kimi k1.5 특징: 수백만 토큰의 논문/보고서 분석 추론: 복잡한 학술 자료 요약 능력 2. 모델별 기술 세부 분석 단순한 성능 비교를 넘어, 모델이 내부적으로 어떤 방식으로 ‘추론’하고 ‘도구’를 사용하는지 파헤칩니다.\nOpenAI o3 / GPT-5 — System 2 Thinking 추론 메커니즘: Reinforcement Learning을 통한 사고의 연쇄(CoT)를 고도화. 답변 전 내부적으로 수천 개의 경로를 탐색한 후 최적의 논리만 출력 에이전트 기능: ‘Operator’라는 전용 인터페이스를 통해 브라우저 자동화, 파일 시스템 접근, 복잡한 코딩 디버깅을 스스로 수행 Google Gemini 3.0 — Native Multimodal 비전 및 오디오: 텍스트로 변환하는 과정을 거치지 않고 영상의 프레임과 소리의 파형을 직접 이해. 실시간 CCTV 영상을 보며 즉답이 가능 컨텍스트 캐싱: 200만 토큰 이상의 방대한 데이터를 메모리에 상주시켜 반복적인 대규모 문서 질의 시 비용과 속도를 획기적으로 개선 Anthropic Claude 4.5 — Artifacts \u0026 Computer Use 사용자 경험: ‘Artifacts’ UI를 통해 모델이 작성한 코드나 웹사이트, 도표를 실시간으로 렌더링하며 협업 도구 활용: ‘Computer Use’ API는 모델이 직접 화면의 좌표를 인식하고 클릭하며, 인간의 업무 프로세스를 그대로 모방하도록 설계 DeepSeek-V3 / R1 — MoE \u0026 Reasoning 아키텍처: MoE(Mixture of Experts) 기술을 극도로 효율화하여, 매우 적은 비용으로도 거대 모델급 성능 오픈 추론: R1 모델은 추론 과정(Thought process)을 사용자에게 투명하게 공개하여, 모델이 왜 이런 결론에 도달했는지 검증 가능 Alibaba Qwen 3 — Multilingual OCR 특화 기능: 전 세계 30개국 이상의 언어를 지원하며, 특히 아시아권 언어의 뉘앙스 파악 능력이 뛰어남 산업 적용: 물류 및 제조 현장의 복잡한 도면이나 손글씨 영수증을 분석하는 비전 성능이 북미 모델을 상회하는 구간이 존재 3. LLM 인프라 및 통합 서비스 (Enablers): 14대 핵심 플랫폼 파운데이션 모델을 서비스에 안전하고 빠르게, 그리고 저렴하게 연결해 주는 인프라 기업들입니다.\n용도에 따라 4가지 계층으로 분류할 수 있습니다.\n분류 서비스명 주요 역할 핵심 활용 포인트 통합 API / 라우팅 OpenRouter LLM API 게이트웨이 수백 개의 오픈/상용 모델을 단일 API로 통합. 장애 시 자동 대체 기능 Cloudflare AI 엣지(Edge) 추론망 글로벌 서버망을 통해 사용자 위치에서 가장 가까운 곳에서 저지연 LLM 응답 제공 LiteLLM 표준화 프록시 OpenAI 포맷이 아닌 모델도 OpenAI 표준 API 구조로 통일해 호출 가능 고속 추론 가속기 Groq LPU 기반 초고속 추론 GPU가 아닌 독자적 LPU(Language Processing Unit)를 사용하여 초저지연 실시간 텍스트 생성 특화 NVIDIA NIM 마이크로서비스 (엔터프라이즈) 기업이 보유한 NVIDIA GPU 서버의 메모리와 연산 효율을 극대화하여 추론 속도를 높임 Together AI 오픈소스 특화 호스팅 Llama, Mixtral 등 오픈소스 모델의 초고속 추론 및 기업 맞춤형 파인튜닝 제공 vLLM 서빙 엔진 (오픈소스) 대규모 트래픽 처리 시 메모리 병목을 줄이는 PagedAttention 기술을 통해 서버 유지비 절감 엔터프라이즈 클라우드 AWS Bedrock 완전 관리형 AI 서비스 강력한 IAM 보안 인증과 VPC 환경을 통해 금융/의료 데이터 유출을 막는 AWS 생태계 Azure AI Studio MS 기반 통합 AI 툴링 OpenAI 모델과 MS 생태계(Office, Teams)를 쉽게 결합하고, 데이터 기반 RAG 시스템 구축 용이 에이전트 / 로컬 개발 LangGraph 에이전트 오케스트레이션 복잡한 다중 에이전트(Multi-agent) 워크플로를 설계하고 상태를 관리하는 핵심 프레임워크 Dify 노코드 LLM 워크플로 개발 지식 없이도 시각적 UI를 통해 RAG 앱과 AI 에이전트 파이프라인을 구축 가능 Perplexity 검색 증강(RAG) 엔진 최신 정보를 크롤링하여 웹 검색 결과와 모델을 결합하는 환각 없는 검색 API 제공 Ollama 로컬 CLI 구동기 개발자의 Mac/Linux 환경에서 단 한 줄의 명령어로 오픈소스 LLM을 오프라인 구동 LM Studio 로컬 GUI 데스크톱 직관적인 그래픽 인터페이스를 통해 개인 PC에서 모델을 쉽게 다운로드 및 실행 4. 특징별 모델 추천 가이드 서비스를 기획 중인 제공자라면 아래 기준에 따라 모델을 선택할 수 있습니다.\n심층 추론 및 복잡한 알고리즘 설계: OpenAI o3, DeepSeek R1, Claude 4.5 Opus 실시간 멀티모달 및 영상 분석: Google Gemini 3.0, OpenAI GPT-5 PC 제어 및 복잡한 에이전트 작업: Claude Computer Use, OpenAI Operator 데이터 보안 및 내부 커스텀 시스템: Meta Llama 4, Mistral Large 3 (오픈소스 계열) 중국어권 비즈니스 및 고가성비 코딩: Alibaba Qwen 2.5/3, DeepSeek V3 5. 서비스 아키텍처 설계 가이드 2026년의 LLM 도입 전략은 “어떤 모델을 쓰느냐” 에서 “어떻게 조합하느냐” 로 바뀌었습니다.\n초저지연 실시간 서비스 (실시간 음성 번역, 콜센터) Groq의 LPU 인프라에 Llama 4 (8B) 나 DeepSeek-V3 같은 가벼운 오픈소스 모델을 올려 밀리초(ms) 단위의 응답 속도를 확보합니다. 서버 유지비를 낮추면서도 사용자 경험을 극대화할 수 있습니다.\n복잡한 내부 업무 자동화 에이전트 (자동 코드 리뷰, 데이터 분석) 논리 추론이 가장 뛰어난 OpenAI o3나 화면을 직접 조작할 수 있는 Claude 4.5를 메인 ‘두뇌’로 사용합니다. 이 두뇌가 순차적으로 일을 처리하고 과거의 기억을 유지할 수 있도록 LangGraph를 통해 에이전트의 파이프라인을 구성합니다.\n보안이 생명인 엔터프라이즈 B2B 인프라 (금융권 로보어드바이저) 퍼블릭 클라우드로 데이터가 나가는 것을 막기 위해 AWS Bedrock 환경 내에서 모델을 호출하거나, 자체 서버에 vLLM과 Ollama를 설치해 내부망에서 폐쇄적으로 구동하는 아키텍처를 채택합니다.\n복합 모델 전략 (Hybrid Orchestration) 일반 상담 및 검색: Perplexity API 또는 Gemini (최신성 및 장문 분석) 복잡한 로직 및 계산: OpenAI o3 (심층 추론) 단순 반복 및 비용 절감: DeepSeek 또는 Llama 4 (가성비 및 오픈소스) 6. 개발 환경 구축 워크플로 프로토타입 단계: Ollama를 통해 로컬에서 가벼운 모델로 프로토타입을 만들고, OpenRouter를 통해 다양한 유료 모델을 테스트 성능 최적화 단계: 대규모 서비스 배포 시 NVIDIA NIM을 활용하여 GPU 효율을 극대화하고 응답 속도를 확보 프로덕션 배포: AWS Bedrock 또는 Azure AI Studio에서 엔터프라이즈급 보안과 스케일링을 적용 참고 자료 2026년 주요 LLM 비교 총정리 Chinese AI Models — DeepSeek Best LLM for Vision Compare Reasoning Models Top 5 AI Gateways to Reduce LLM Cost Best AI Agent Frameworks 2026 Best Open Source LLM Hosting Providers ","wordCount":"1044","inLanguage":"en","datePublished":"2026-02-25T00:00:00+09:00","dateModified":"2026-02-25T00:00:00+09:00","author":{"@type":"Person","name":"Byung Kyu KIM"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://cdecl.github.io/devops/ai-models-comparison/"},"publisher":{"@type":"Organization","name":"cdeclog","logo":{"@type":"ImageObject","url":"https://cdecl.github.io/favicon.ico"}}}</script></head><body id=top><header class=header><nav class=nav><div class=logo><a href=https://cdecl.github.io/ accesskey=h title="cdeclog (Alt + H)">cdeclog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://cdecl.github.io/dev/ title=Dev><span>Dev</span></a></li><li><a href=https://cdecl.github.io/devops/ title=DevOps><span>DevOps</span></a></li><li><a href=https://cdecl.github.io/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://cdecl.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://cdecl.github.io/tags/ title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://cdecl.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://cdecl.github.io/devops/>Devops</a></div><h1 class="post-title entry-hint-parent">2026 글로벌 LLM 생태계 비교: 파운데이션 모델부터 인프라 서비스까지</h1><div class=post-meta><span title='2026-02-25 00:00:00 +0900 KST'>February 25, 2026</span>&nbsp;·&nbsp;<span>Byung Kyu KIM</span></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#1-%ed%8c%8c%ec%9a%b4%eb%8d%b0%ec%9d%b4%ec%85%98-%eb%aa%a8%eb%8d%b8-%ec%83%9d%ed%83%9c%ea%b3%84-builders-%eb%b6%81%eb%af%b8-vs-%ec%a4%91%ea%b5%ad aria-label="1. 파운데이션 모델 생태계 (Builders): 북미 vs 중국">1. 파운데이션 모델 생태계 (Builders): 북미 vs 중국</a></li><li><a href=#2-%eb%aa%a8%eb%8d%b8%eb%b3%84-%ea%b8%b0%ec%88%a0-%ec%84%b8%eb%b6%80-%eb%b6%84%ec%84%9d aria-label="2. 모델별 기술 세부 분석">2. 모델별 기술 세부 분석</a><ul><li><a href=#openai-o3--gpt-5--system-2-thinking aria-label="OpenAI o3 / GPT-5 — System 2 Thinking">OpenAI o3 / GPT-5 — System 2 Thinking</a></li><li><a href=#google-gemini-30--native-multimodal aria-label="Google Gemini 3.0 — Native Multimodal">Google Gemini 3.0 — Native Multimodal</a></li><li><a href=#anthropic-claude-45--artifacts--computer-use aria-label="Anthropic Claude 4.5 — Artifacts & Computer Use">Anthropic Claude 4.5 — Artifacts & Computer Use</a></li><li><a href=#deepseek-v3--r1--moe--reasoning aria-label="DeepSeek-V3 / R1 — MoE & Reasoning">DeepSeek-V3 / R1 — MoE & Reasoning</a></li><li><a href=#alibaba-qwen-3--multilingual-ocr aria-label="Alibaba Qwen 3 — Multilingual OCR">Alibaba Qwen 3 — Multilingual OCR</a></li></ul></li><li><a href=#3-llm-%ec%9d%b8%ed%94%84%eb%9d%bc-%eb%b0%8f-%ed%86%b5%ed%95%a9-%ec%84%9c%eb%b9%84%ec%8a%a4-enablers-14%eb%8c%80-%ed%95%b5%ec%8b%ac-%ed%94%8c%eb%9e%ab%ed%8f%bc aria-label="3. LLM 인프라 및 통합 서비스 (Enablers): 14대 핵심 플랫폼">3. LLM 인프라 및 통합 서비스 (Enablers): 14대 핵심 플랫폼</a></li><li><a href=#4-%ed%8a%b9%ec%a7%95%eb%b3%84-%eb%aa%a8%eb%8d%b8-%ec%b6%94%ec%b2%9c-%ea%b0%80%ec%9d%b4%eb%93%9c aria-label="4. 특징별 모델 추천 가이드">4. 특징별 모델 추천 가이드</a></li><li><a href=#5-%ec%84%9c%eb%b9%84%ec%8a%a4-%ec%95%84%ed%82%a4%ed%85%8d%ec%b2%98-%ec%84%a4%ea%b3%84-%ea%b0%80%ec%9d%b4%eb%93%9c aria-label="5. 서비스 아키텍처 설계 가이드">5. 서비스 아키텍처 설계 가이드</a><ul><li><a href=#%ec%b4%88%ec%a0%80%ec%a7%80%ec%97%b0-%ec%8b%a4%ec%8b%9c%ea%b0%84-%ec%84%9c%eb%b9%84%ec%8a%a4-%ec%8b%a4%ec%8b%9c%ea%b0%84-%ec%9d%8c%ec%84%b1-%eb%b2%88%ec%97%ad-%ec%bd%9c%ec%84%bc%ed%84%b0 aria-label="초저지연 실시간 서비스 (실시간 음성 번역, 콜센터)">초저지연 실시간 서비스 (실시간 음성 번역, 콜센터)</a></li><li><a href=#%eb%b3%b5%ec%9e%a1%ed%95%9c-%eb%82%b4%eb%b6%80-%ec%97%85%eb%ac%b4-%ec%9e%90%eb%8f%99%ed%99%94-%ec%97%90%ec%9d%b4%ec%a0%84%ed%8a%b8-%ec%9e%90%eb%8f%99-%ec%bd%94%eb%93%9c-%eb%a6%ac%eb%b7%b0-%eb%8d%b0%ec%9d%b4%ed%84%b0-%eb%b6%84%ec%84%9d aria-label="복잡한 내부 업무 자동화 에이전트 (자동 코드 리뷰, 데이터 분석)">복잡한 내부 업무 자동화 에이전트 (자동 코드 리뷰, 데이터 분석)</a></li><li><a href=#%eb%b3%b4%ec%95%88%ec%9d%b4-%ec%83%9d%eb%aa%85%ec%9d%b8-%ec%97%94%ed%84%b0%ed%94%84%eb%9d%bc%ec%9d%b4%ec%a6%88-b2b-%ec%9d%b8%ed%94%84%eb%9d%bc-%ea%b8%88%ec%9c%b5%ea%b6%8c-%eb%a1%9c%eb%b3%b4%ec%96%b4%eb%93%9c%eb%b0%94%ec%9d%b4%ec%a0%80 aria-label="보안이 생명인 엔터프라이즈 B2B 인프라 (금융권 로보어드바이저)">보안이 생명인 엔터프라이즈 B2B 인프라 (금융권 로보어드바이저)</a></li><li><a href=#%eb%b3%b5%ed%95%a9-%eb%aa%a8%eb%8d%b8-%ec%a0%84%eb%9e%b5-hybrid-orchestration aria-label="복합 모델 전략 (Hybrid Orchestration)">복합 모델 전략 (Hybrid Orchestration)</a></li></ul></li><li><a href=#6-%ea%b0%9c%eb%b0%9c-%ed%99%98%ea%b2%bd-%ea%b5%ac%ec%b6%95-%ec%9b%8c%ed%81%ac%ed%94%8c%eb%a1%9c aria-label="6. 개발 환경 구축 워크플로">6. 개발 환경 구축 워크플로</a></li><li><a href=#%ec%b0%b8%ea%b3%a0-%ec%9e%90%eb%a3%8c aria-label="참고 자료">참고 자료</a></li></ul></div></details></div><div class=post-content><p>2026년 현재 LLM 시장은 모델을 직접 학습시켜 배포하는 <strong>파운데이션 모델 제공자(Builders)</strong> 와, 이 모델들을 기업 및 개발자가 쉽게 도입·최적화할 수 있도록 돕는 <strong>인프라 및 통합 서비스 제공자(Enablers)</strong> 로 생태계가 양분되어 있습니다.</p><p>북미의 프론티어 모델과 중국의 고효율 모델들이 치열하게 경쟁하는 가운데, Provider 관점에서 각 모델의 세부 특징과 인프라 서비스를 총정리합니다.</p><hr><h2 id=1-파운데이션-모델-생태계-builders-북미-vs-중국>1. 파운데이션 모델 생태계 (Builders): 북미 vs 중국<a hidden class=anchor aria-hidden=true href=#1-파운데이션-모델-생태계-builders-북미-vs-중국>#</a></h2><p>LLM의 원천 지능을 제공하는 기업들입니다.<br>북미는 범용적 에이전트와 멀티모달에, 중국은 극강의 가성비와 오픈소스 생태계에 집중하고 있습니다.</p><table><thead><tr><th style=text-align:left>지역</th><th style=text-align:left>Provider</th><th style=text-align:left>대표 모델</th><th style=text-align:left>핵심 특징 (추론 / Tool / Vision)</th></tr></thead><tbody><tr><td style=text-align:left><strong>북미</strong></td><td style=text-align:left><strong>OpenAI</strong></td><td style=text-align:left><strong>o3 / GPT-5</strong></td><td style=text-align:left><strong>추론:</strong> o3의 사고의 연쇄(CoT) 알고리즘 탑재<br><strong>Tool:</strong> 자율 컴퓨팅을 수행하는 &lsquo;Operator&rsquo; 에이전트</td></tr><tr><td style=text-align:left></td><td style=text-align:left><strong>Google</strong></td><td style=text-align:left><strong>Gemini 3.0</strong></td><td style=text-align:left><strong>Vision:</strong> 실시간 영상 및 오디오 프레임 동시 분석<br><strong>특징:</strong> 200만 토큰 이상의 초장문 컨텍스트 윈도우</td></tr><tr><td style=text-align:left></td><td style=text-align:left><strong>Anthropic</strong></td><td style=text-align:left><strong>Claude 4.5</strong></td><td style=text-align:left><strong>Tool:</strong> 컴퓨터 화면과 마우스를 제어하는 &lsquo;Computer Use&rsquo;<br><strong>특징:</strong> 가장 뛰어난 문서 구조 해석 및 안전성(거짓 정보 억제)</td></tr><tr><td style=text-align:left></td><td style=text-align:left><strong>Meta</strong></td><td style=text-align:left><strong>Llama 4</strong></td><td style=text-align:left><strong>특징:</strong> 온프레미스 구축이 가능한 최고 성능의 오픈소스 모델<br><strong>추론:</strong> 400B 파라미터급 모델의 뛰어난 범용 성능</td></tr><tr><td style=text-align:left><strong>중국</strong></td><td style=text-align:left><strong>DeepSeek</strong></td><td style=text-align:left><strong>V3 / R1</strong></td><td style=text-align:left><strong>추론:</strong> R1의 내부 사고 과정을 투명하게 공개하는 추론 모드<br><strong>특징:</strong> API 비용이 북미 모델 대비 최대 1/10 수준의 극강 가성비</td></tr><tr><td style=text-align:left></td><td style=text-align:left><strong>Alibaba</strong></td><td style=text-align:left><strong>Qwen 2.5/3</strong></td><td style=text-align:left><strong>Vision:</strong> 영수증·설계도면 등의 다국어 OCR 인식에 독보적<br><strong>Tool:</strong> 중국 및 아시아권 이커머스/물류 API 통합에 최적화</td></tr><tr><td style=text-align:left></td><td style=text-align:left><strong>Zhipu AI</strong></td><td style=text-align:left><strong>GLM-5</strong></td><td style=text-align:left><strong>Vision:</strong> 고해상도 이미지 및 비디오 분석<br><strong>특징:</strong> 중국 내 가장 범용적인 AI 생태계</td></tr><tr><td style=text-align:left></td><td style=text-align:left><strong>Moonshot</strong></td><td style=text-align:left><strong>Kimi k1.5</strong></td><td style=text-align:left><strong>특징:</strong> 수백만 토큰의 논문/보고서 분석<br><strong>추론:</strong> 복잡한 학술 자료 요약 능력</td></tr></tbody></table><hr><h2 id=2-모델별-기술-세부-분석>2. 모델별 기술 세부 분석<a hidden class=anchor aria-hidden=true href=#2-모델별-기술-세부-분석>#</a></h2><p>단순한 성능 비교를 넘어, 모델이 내부적으로 어떤 방식으로 &lsquo;추론&rsquo;하고 &lsquo;도구&rsquo;를 사용하는지 파헤칩니다.</p><h3 id=openai-o3--gpt-5--system-2-thinking>OpenAI o3 / GPT-5 — System 2 Thinking<a hidden class=anchor aria-hidden=true href=#openai-o3--gpt-5--system-2-thinking>#</a></h3><ul><li><strong>추론 메커니즘:</strong> Reinforcement Learning을 통한 사고의 연쇄(CoT)를 고도화. 답변 전 내부적으로 수천 개의 경로를 탐색한 후 최적의 논리만 출력</li><li><strong>에이전트 기능:</strong> &lsquo;Operator&rsquo;라는 전용 인터페이스를 통해 브라우저 자동화, 파일 시스템 접근, 복잡한 코딩 디버깅을 스스로 수행</li></ul><h3 id=google-gemini-30--native-multimodal>Google Gemini 3.0 — Native Multimodal<a hidden class=anchor aria-hidden=true href=#google-gemini-30--native-multimodal>#</a></h3><ul><li><strong>비전 및 오디오:</strong> 텍스트로 변환하는 과정을 거치지 않고 영상의 프레임과 소리의 파형을 직접 이해. 실시간 CCTV 영상을 보며 즉답이 가능</li><li><strong>컨텍스트 캐싱:</strong> 200만 토큰 이상의 방대한 데이터를 메모리에 상주시켜 반복적인 대규모 문서 질의 시 비용과 속도를 획기적으로 개선</li></ul><h3 id=anthropic-claude-45--artifacts--computer-use>Anthropic Claude 4.5 — Artifacts & Computer Use<a hidden class=anchor aria-hidden=true href=#anthropic-claude-45--artifacts--computer-use>#</a></h3><ul><li><strong>사용자 경험:</strong> &lsquo;Artifacts&rsquo; UI를 통해 모델이 작성한 코드나 웹사이트, 도표를 실시간으로 렌더링하며 협업</li><li><strong>도구 활용:</strong> &lsquo;Computer Use&rsquo; API는 모델이 직접 화면의 좌표를 인식하고 클릭하며, 인간의 업무 프로세스를 그대로 모방하도록 설계</li></ul><h3 id=deepseek-v3--r1--moe--reasoning>DeepSeek-V3 / R1 — MoE & Reasoning<a hidden class=anchor aria-hidden=true href=#deepseek-v3--r1--moe--reasoning>#</a></h3><ul><li><strong>아키텍처:</strong> MoE(Mixture of Experts) 기술을 극도로 효율화하여, 매우 적은 비용으로도 거대 모델급 성능</li><li><strong>오픈 추론:</strong> R1 모델은 추론 과정(Thought process)을 사용자에게 투명하게 공개하여, 모델이 왜 이런 결론에 도달했는지 검증 가능</li></ul><h3 id=alibaba-qwen-3--multilingual-ocr>Alibaba Qwen 3 — Multilingual OCR<a hidden class=anchor aria-hidden=true href=#alibaba-qwen-3--multilingual-ocr>#</a></h3><ul><li><strong>특화 기능:</strong> 전 세계 30개국 이상의 언어를 지원하며, 특히 아시아권 언어의 뉘앙스 파악 능력이 뛰어남</li><li><strong>산업 적용:</strong> 물류 및 제조 현장의 복잡한 도면이나 손글씨 영수증을 분석하는 비전 성능이 북미 모델을 상회하는 구간이 존재</li></ul><hr><h2 id=3-llm-인프라-및-통합-서비스-enablers-14대-핵심-플랫폼>3. LLM 인프라 및 통합 서비스 (Enablers): 14대 핵심 플랫폼<a hidden class=anchor aria-hidden=true href=#3-llm-인프라-및-통합-서비스-enablers-14대-핵심-플랫폼>#</a></h2><p>파운데이션 모델을 서비스에 안전하고 빠르게, 그리고 저렴하게 연결해 주는 인프라 기업들입니다.<br>용도에 따라 4가지 계층으로 분류할 수 있습니다.</p><table><thead><tr><th style=text-align:left>분류</th><th style=text-align:left>서비스명</th><th style=text-align:left>주요 역할</th><th style=text-align:left>핵심 활용 포인트</th></tr></thead><tbody><tr><td style=text-align:left><strong>통합 API / 라우팅</strong></td><td style=text-align:left><strong>OpenRouter</strong></td><td style=text-align:left>LLM API 게이트웨이</td><td style=text-align:left>수백 개의 오픈/상용 모델을 단일 API로 통합. 장애 시 자동 대체 기능</td></tr><tr><td style=text-align:left></td><td style=text-align:left><strong>Cloudflare AI</strong></td><td style=text-align:left>엣지(Edge) 추론망</td><td style=text-align:left>글로벌 서버망을 통해 사용자 위치에서 가장 가까운 곳에서 저지연 LLM 응답 제공</td></tr><tr><td style=text-align:left></td><td style=text-align:left><strong>LiteLLM</strong></td><td style=text-align:left>표준화 프록시</td><td style=text-align:left>OpenAI 포맷이 아닌 모델도 OpenAI 표준 API 구조로 통일해 호출 가능</td></tr><tr><td style=text-align:left><strong>고속 추론 가속기</strong></td><td style=text-align:left><strong>Groq</strong></td><td style=text-align:left>LPU 기반 초고속 추론</td><td style=text-align:left>GPU가 아닌 독자적 LPU(Language Processing Unit)를 사용하여 초저지연 실시간 텍스트 생성 특화</td></tr><tr><td style=text-align:left></td><td style=text-align:left><strong>NVIDIA NIM</strong></td><td style=text-align:left>마이크로서비스 (엔터프라이즈)</td><td style=text-align:left>기업이 보유한 NVIDIA GPU 서버의 메모리와 연산 효율을 극대화하여 추론 속도를 높임</td></tr><tr><td style=text-align:left></td><td style=text-align:left><strong>Together AI</strong></td><td style=text-align:left>오픈소스 특화 호스팅</td><td style=text-align:left>Llama, Mixtral 등 오픈소스 모델의 초고속 추론 및 기업 맞춤형 파인튜닝 제공</td></tr><tr><td style=text-align:left></td><td style=text-align:left><strong>vLLM</strong></td><td style=text-align:left>서빙 엔진 (오픈소스)</td><td style=text-align:left>대규모 트래픽 처리 시 메모리 병목을 줄이는 PagedAttention 기술을 통해 서버 유지비 절감</td></tr><tr><td style=text-align:left><strong>엔터프라이즈 클라우드</strong></td><td style=text-align:left><strong>AWS Bedrock</strong></td><td style=text-align:left>완전 관리형 AI 서비스</td><td style=text-align:left>강력한 IAM 보안 인증과 VPC 환경을 통해 금융/의료 데이터 유출을 막는 AWS 생태계</td></tr><tr><td style=text-align:left></td><td style=text-align:left><strong>Azure AI Studio</strong></td><td style=text-align:left>MS 기반 통합 AI 툴링</td><td style=text-align:left>OpenAI 모델과 MS 생태계(Office, Teams)를 쉽게 결합하고, 데이터 기반 RAG 시스템 구축 용이</td></tr><tr><td style=text-align:left><strong>에이전트 / 로컬 개발</strong></td><td style=text-align:left><strong>LangGraph</strong></td><td style=text-align:left>에이전트 오케스트레이션</td><td style=text-align:left>복잡한 다중 에이전트(Multi-agent) 워크플로를 설계하고 상태를 관리하는 핵심 프레임워크</td></tr><tr><td style=text-align:left></td><td style=text-align:left><strong>Dify</strong></td><td style=text-align:left>노코드 LLM 워크플로</td><td style=text-align:left>개발 지식 없이도 시각적 UI를 통해 RAG 앱과 AI 에이전트 파이프라인을 구축 가능</td></tr><tr><td style=text-align:left></td><td style=text-align:left><strong>Perplexity</strong></td><td style=text-align:left>검색 증강(RAG) 엔진</td><td style=text-align:left>최신 정보를 크롤링하여 웹 검색 결과와 모델을 결합하는 환각 없는 검색 API 제공</td></tr><tr><td style=text-align:left></td><td style=text-align:left><strong>Ollama</strong></td><td style=text-align:left>로컬 CLI 구동기</td><td style=text-align:left>개발자의 Mac/Linux 환경에서 단 한 줄의 명령어로 오픈소스 LLM을 오프라인 구동</td></tr><tr><td style=text-align:left></td><td style=text-align:left><strong>LM Studio</strong></td><td style=text-align:left>로컬 GUI 데스크톱</td><td style=text-align:left>직관적인 그래픽 인터페이스를 통해 개인 PC에서 모델을 쉽게 다운로드 및 실행</td></tr></tbody></table><hr><h2 id=4-특징별-모델-추천-가이드>4. 특징별 모델 추천 가이드<a hidden class=anchor aria-hidden=true href=#4-특징별-모델-추천-가이드>#</a></h2><p>서비스를 기획 중인 제공자라면 아래 기준에 따라 모델을 선택할 수 있습니다.</p><ul><li><strong>심층 추론 및 복잡한 알고리즘 설계:</strong> OpenAI <strong>o3</strong>, DeepSeek <strong>R1</strong>, Claude <strong>4.5 Opus</strong></li><li><strong>실시간 멀티모달 및 영상 분석:</strong> Google <strong>Gemini 3.0</strong>, OpenAI <strong>GPT-5</strong></li><li><strong>PC 제어 및 복잡한 에이전트 작업:</strong> Claude <strong>Computer Use</strong>, OpenAI <strong>Operator</strong></li><li><strong>데이터 보안 및 내부 커스텀 시스템:</strong> Meta <strong>Llama 4</strong>, Mistral <strong>Large 3</strong> (오픈소스 계열)</li><li><strong>중국어권 비즈니스 및 고가성비 코딩:</strong> Alibaba <strong>Qwen 2.5/3</strong>, DeepSeek <strong>V3</strong></li></ul><hr><h2 id=5-서비스-아키텍처-설계-가이드>5. 서비스 아키텍처 설계 가이드<a hidden class=anchor aria-hidden=true href=#5-서비스-아키텍처-설계-가이드>#</a></h2><p>2026년의 LLM 도입 전략은 <strong>&ldquo;어떤 모델을 쓰느냐&rdquo;</strong> 에서 <strong>&ldquo;어떻게 조합하느냐&rdquo;</strong> 로 바뀌었습니다.</p><h3 id=초저지연-실시간-서비스-실시간-음성-번역-콜센터>초저지연 실시간 서비스 (실시간 음성 번역, 콜센터)<a hidden class=anchor aria-hidden=true href=#초저지연-실시간-서비스-실시간-음성-번역-콜센터>#</a></h3><p><strong>Groq</strong>의 LPU 인프라에 <strong>Llama 4 (8B)</strong> 나 <strong>DeepSeek-V3</strong> 같은 가벼운 오픈소스 모델을 올려 밀리초(ms) 단위의 응답 속도를 확보합니다. 서버 유지비를 낮추면서도 사용자 경험을 극대화할 수 있습니다.</p><h3 id=복잡한-내부-업무-자동화-에이전트-자동-코드-리뷰-데이터-분석>복잡한 내부 업무 자동화 에이전트 (자동 코드 리뷰, 데이터 분석)<a hidden class=anchor aria-hidden=true href=#복잡한-내부-업무-자동화-에이전트-자동-코드-리뷰-데이터-분석>#</a></h3><p>논리 추론이 가장 뛰어난 <strong>OpenAI o3</strong>나 화면을 직접 조작할 수 있는 <strong>Claude 4.5</strong>를 메인 &lsquo;두뇌&rsquo;로 사용합니다. 이 두뇌가 순차적으로 일을 처리하고 과거의 기억을 유지할 수 있도록 <strong>LangGraph</strong>를 통해 에이전트의 파이프라인을 구성합니다.</p><h3 id=보안이-생명인-엔터프라이즈-b2b-인프라-금융권-로보어드바이저>보안이 생명인 엔터프라이즈 B2B 인프라 (금융권 로보어드바이저)<a hidden class=anchor aria-hidden=true href=#보안이-생명인-엔터프라이즈-b2b-인프라-금융권-로보어드바이저>#</a></h3><p>퍼블릭 클라우드로 데이터가 나가는 것을 막기 위해 <strong>AWS Bedrock</strong> 환경 내에서 모델을 호출하거나, 자체 서버에 <strong>vLLM</strong>과 <strong>Ollama</strong>를 설치해 내부망에서 폐쇄적으로 구동하는 아키텍처를 채택합니다.</p><h3 id=복합-모델-전략-hybrid-orchestration>복합 모델 전략 (Hybrid Orchestration)<a hidden class=anchor aria-hidden=true href=#복합-모델-전략-hybrid-orchestration>#</a></h3><ul><li>일반 상담 및 검색: <strong>Perplexity API</strong> 또는 <strong>Gemini</strong> (최신성 및 장문 분석)</li><li>복잡한 로직 및 계산: <strong>OpenAI o3</strong> (심층 추론)</li><li>단순 반복 및 비용 절감: <strong>DeepSeek</strong> 또는 <strong>Llama 4</strong> (가성비 및 오픈소스)</li></ul><hr><h2 id=6-개발-환경-구축-워크플로>6. 개발 환경 구축 워크플로<a hidden class=anchor aria-hidden=true href=#6-개발-환경-구축-워크플로>#</a></h2><ol><li><strong>프로토타입 단계:</strong> <strong>Ollama</strong>를 통해 로컬에서 가벼운 모델로 프로토타입을 만들고, <strong>OpenRouter</strong>를 통해 다양한 유료 모델을 테스트</li><li><strong>성능 최적화 단계:</strong> 대규모 서비스 배포 시 <strong>NVIDIA NIM</strong>을 활용하여 GPU 효율을 극대화하고 응답 속도를 확보</li><li><strong>프로덕션 배포:</strong> <strong>AWS Bedrock</strong> 또는 <strong>Azure AI Studio</strong>에서 엔터프라이즈급 보안과 스케일링을 적용</li></ol><hr><h2 id=참고-자료>참고 자료<a hidden class=anchor aria-hidden=true href=#참고-자료>#</a></h2><ul><li><a href=https://blog.kwt.co.kr/2026%EB%85%84-2%EC%9B%94-%EC%A3%BC%EC%9A%94-llm-%EB%B9%84%EA%B5%90-%EC%B4%9D%EC%A0%95%EB%A6%AC-chatgpt-vs-claude-vs-gemini/>2026년 주요 LLM 비교 총정리</a></li><li><a href=https://www.index.dev/blog/chinese-ai-models-deepseek>Chinese AI Models — DeepSeek</a></li><li><a href=https://visionvix.com/best-llm-for-vision/>Best LLM for Vision</a></li><li><a href=https://www.labellerr.com/blog/compare-reasoning-models/>Compare Reasoning Models</a></li><li><a href=https://www.getmaxim.ai/articles/top-5-ai-gateways-to-reduce-llm-cost-in-2026/>Top 5 AI Gateways to Reduce LLM Cost</a></li><li><a href=https://genta.dev/resources/best-ai-agent-frameworks-2026>Best AI Agent Frameworks 2026</a></li><li><a href=https://thinkpeak.ai/best-open-source-llm-hosting-providers-2026/>Best Open Source LLM Hosting Providers</a></li></ul></div><footer class=post-footer><ul class=post-tags><li><a href=https://cdecl.github.io/tags/ai/>Ai</a></li><li><a href=https://cdecl.github.io/tags/llm/>Llm</a></li><li><a href=https://cdecl.github.io/tags/deepseek/>Deepseek</a></li><li><a href=https://cdecl.github.io/tags/openai/>Openai</a></li><li><a href=https://cdecl.github.io/tags/gemini/>Gemini</a></li><li><a href=https://cdecl.github.io/tags/claude/>Claude</a></li><li><a href=https://cdecl.github.io/tags/devops/>Devops</a></li></ul></footer><script src=https://giscus.app/client.js data-repo=cdecl/cdecl.github.io data-repo-id="MDEwOlJlcG9zaXRvcnkzNDk1ODUyNjg=" data-category=General data-category-id=DIC_kwDOFNY_dM4C1XMk data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=transparent_dark data-lang=ko crossorigin=anonymous async></script></article></main><footer class=footer><span>&copy; 2026 <a href=https://cdecl.github.io/>cdeclog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");if(menu){const e=localStorage.getItem("menu-scroll-position");e&&(menu.scrollLeft=parseInt(e,10)),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}}document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{const e=document.querySelector("html");e.dataset.theme==="dark"?(e.dataset.theme="light",localStorage.setItem("pref-theme","light")):(e.dataset.theme="dark",localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>