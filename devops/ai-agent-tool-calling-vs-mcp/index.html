<!doctype html><html lang=en dir=auto data-theme=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>AI Agent 구현의 두 갈래: 일반 Tool Calling vs MCP 비교 | cdeclog</title><meta name=keywords content="ai,agent,tool-calling,mcp,llm,json-rpc,devops"><meta name=description content="AI 에이전트를 구축할 때, LLM이 외부 도구를 사용하게 만드는 과정은 필수적입니다. 하지만 최근 등장한 **MCP(Model Context Protocol)**와 기존의 Function/Tool Calling은 비슷해 보이면서도 구조적으로 큰 차이가 있습니다. 오늘은 이 두 방식의 특징과 실제 구현 관점에서의 차이를 상세히 비교해 보겠습니다.
1. 한눈에 보는 비교 요약

  
      
          구분
          일반 Tool Calling (기존 방식)
          MCP (Model Context Protocol)
      
  
  
      
          핵심 개념
          함수 정의와 실행 로직의 수동 연결
          도구의 정의와 실행이 결합된 표준화된 서버
      
      
          실행 주체
          에이전트 애플리케이션 (Local, Tightly Coupled)
          독립된 MCP 서버 (Remote/Isolated)
      
      
          통신 규격
          모델별 전용 API (OpenAI, Anthropic 등)
          JSON-RPC 2.0 표준 프로토콜
      
      
          툴 목록 관리
          코드에 하드코딩, 앱 재배포 필요
          서버에서 동적으로 list_tools() 조회
      
      
          확장성
          새 툴 추가 시 앱 코드 수정 및 재배포
          MCP 서버만 추가·재시작하면 즉시 연동
      
      
          상호운용성
          모델별 규격 변환 코드 직접 작성 필요
          MCP 지원 클라이언트라면 어떤 모델이든 재사용
      
      
          컨텍스트 제공
          주로 &lsquo;액션(함수 호출)&lsquo;에 집중
          툴 + 리소스(파일, DB) + 프롬프트 템플릿 패키지
      
      
          보안/격리
          에이전트 프로세스 내에서 직접 실행
          실행 로직이 서버에 캡슐화, 권한 경계 명확
      
  


2. 일반 Tool Calling: &ldquo;직접 요리하기&rdquo; 방식
일반적인 방식에서 에이전트는 요리사(LLM)가 준 레시피(JSON)를 보고 **직접 요리(함수 실행)**를 합니다.
실행 로직이 에이전트 코드 내부에 깊게 박혀 있는 구조(Tightly Coupled)입니다."><meta name=author content="Byung Kyu KIM"><link rel=canonical href=https://cdecl.github.io/devops/ai-agent-tool-calling-vs-mcp/><link crossorigin=anonymous href=/assets/css/stylesheet.f939c4ffefb264e6fe85e04352266f79db6bb1303c8e16ae9b6064c1247b5e32.css integrity="sha256-+TnE/++yZOb+heBDUiZvedtrsTA8jhaum2BkwSR7XjI=" rel="preload stylesheet" as=style><link rel=icon href=https://cdecl.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://cdecl.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://cdecl.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://cdecl.github.io/apple-touch-icon.png><link rel=mask-icon href=https://cdecl.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://cdecl.github.io/devops/ai-agent-tool-calling-vs-mcp/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51);color-scheme:dark}.list{background:var(--theme)}.toc{background:var(--entry)}}@media(prefers-color-scheme:light){.list::-webkit-scrollbar-thumb{border-color:var(--code-bg)}}</style></noscript><script>localStorage.getItem("pref-theme")==="dark"?document.querySelector("html").dataset.theme="dark":localStorage.getItem("pref-theme")==="light"?document.querySelector("html").dataset.theme="light":window.matchMedia("(prefers-color-scheme: dark)").matches?document.querySelector("html").dataset.theme="dark":document.querySelector("html").dataset.theme="light"</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-VQQHHYPN7K"></script><script>var doNotTrack=!1,dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes";if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-VQQHHYPN7K")}</script><meta property="og:url" content="https://cdecl.github.io/devops/ai-agent-tool-calling-vs-mcp/"><meta property="og:site_name" content="cdeclog"><meta property="og:title" content="AI Agent 구현의 두 갈래: 일반 Tool Calling vs MCP 비교"><meta property="og:description" content="AI 에이전트를 구축할 때, LLM이 외부 도구를 사용하게 만드는 과정은 필수적입니다. 하지만 최근 등장한 **MCP(Model Context Protocol)**와 기존의 Function/Tool Calling은 비슷해 보이면서도 구조적으로 큰 차이가 있습니다. 오늘은 이 두 방식의 특징과 실제 구현 관점에서의 차이를 상세히 비교해 보겠습니다.
1. 한눈에 보는 비교 요약 구분 일반 Tool Calling (기존 방식) MCP (Model Context Protocol) 핵심 개념 함수 정의와 실행 로직의 수동 연결 도구의 정의와 실행이 결합된 표준화된 서버 실행 주체 에이전트 애플리케이션 (Local, Tightly Coupled) 독립된 MCP 서버 (Remote/Isolated) 통신 규격 모델별 전용 API (OpenAI, Anthropic 등) JSON-RPC 2.0 표준 프로토콜 툴 목록 관리 코드에 하드코딩, 앱 재배포 필요 서버에서 동적으로 list_tools() 조회 확장성 새 툴 추가 시 앱 코드 수정 및 재배포 MCP 서버만 추가·재시작하면 즉시 연동 상호운용성 모델별 규격 변환 코드 직접 작성 필요 MCP 지원 클라이언트라면 어떤 모델이든 재사용 컨텍스트 제공 주로 ‘액션(함수 호출)‘에 집중 툴 + 리소스(파일, DB) + 프롬프트 템플릿 패키지 보안/격리 에이전트 프로세스 내에서 직접 실행 실행 로직이 서버에 캡슐화, 권한 경계 명확 2. 일반 Tool Calling: “직접 요리하기” 방식 일반적인 방식에서 에이전트는 요리사(LLM)가 준 레시피(JSON)를 보고 **직접 요리(함수 실행)**를 합니다.
실행 로직이 에이전트 코드 내부에 깊게 박혀 있는 구조(Tightly Coupled)입니다."><meta property="og:locale" content="ko-kr"><meta property="og:type" content="article"><meta property="article:section" content="devops"><meta property="article:published_time" content="2026-02-23T00:00:00+09:00"><meta property="article:modified_time" content="2026-02-23T00:00:00+09:00"><meta property="article:tag" content="AI"><meta property="article:tag" content="Agent"><meta property="article:tag" content="Tool-Calling"><meta property="article:tag" content="Mcp"><meta property="article:tag" content="LLM"><meta property="article:tag" content="Json-Rpc"><meta name=twitter:card content="summary"><meta name=twitter:title content="AI Agent 구현의 두 갈래: 일반 Tool Calling vs MCP 비교"><meta name=twitter:description content="AI 에이전트를 구축할 때, LLM이 외부 도구를 사용하게 만드는 과정은 필수적입니다. 하지만 최근 등장한 **MCP(Model Context Protocol)**와 기존의 Function/Tool Calling은 비슷해 보이면서도 구조적으로 큰 차이가 있습니다. 오늘은 이 두 방식의 특징과 실제 구현 관점에서의 차이를 상세히 비교해 보겠습니다.
1. 한눈에 보는 비교 요약

  
      
          구분
          일반 Tool Calling (기존 방식)
          MCP (Model Context Protocol)
      
  
  
      
          핵심 개념
          함수 정의와 실행 로직의 수동 연결
          도구의 정의와 실행이 결합된 표준화된 서버
      
      
          실행 주체
          에이전트 애플리케이션 (Local, Tightly Coupled)
          독립된 MCP 서버 (Remote/Isolated)
      
      
          통신 규격
          모델별 전용 API (OpenAI, Anthropic 등)
          JSON-RPC 2.0 표준 프로토콜
      
      
          툴 목록 관리
          코드에 하드코딩, 앱 재배포 필요
          서버에서 동적으로 list_tools() 조회
      
      
          확장성
          새 툴 추가 시 앱 코드 수정 및 재배포
          MCP 서버만 추가·재시작하면 즉시 연동
      
      
          상호운용성
          모델별 규격 변환 코드 직접 작성 필요
          MCP 지원 클라이언트라면 어떤 모델이든 재사용
      
      
          컨텍스트 제공
          주로 &lsquo;액션(함수 호출)&lsquo;에 집중
          툴 + 리소스(파일, DB) + 프롬프트 템플릿 패키지
      
      
          보안/격리
          에이전트 프로세스 내에서 직접 실행
          실행 로직이 서버에 캡슐화, 권한 경계 명확
      
  


2. 일반 Tool Calling: &ldquo;직접 요리하기&rdquo; 방식
일반적인 방식에서 에이전트는 요리사(LLM)가 준 레시피(JSON)를 보고 **직접 요리(함수 실행)**를 합니다.
실행 로직이 에이전트 코드 내부에 깊게 박혀 있는 구조(Tightly Coupled)입니다."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Devops","item":"https://cdecl.github.io/devops/"},{"@type":"ListItem","position":2,"name":"AI Agent 구현의 두 갈래: 일반 Tool Calling vs MCP 비교","item":"https://cdecl.github.io/devops/ai-agent-tool-calling-vs-mcp/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"AI Agent 구현의 두 갈래: 일반 Tool Calling vs MCP 비교","name":"AI Agent 구현의 두 갈래: 일반 Tool Calling vs MCP 비교","description":"AI 에이전트를 구축할 때, LLM이 외부 도구를 사용하게 만드는 과정은 필수적입니다. 하지만 최근 등장한 **MCP(Model Context Protocol)**와 기존의 Function/Tool Calling은 비슷해 보이면서도 구조적으로 큰 차이가 있습니다. 오늘은 이 두 방식의 특징과 실제 구현 관점에서의 차이를 상세히 비교해 보겠습니다.\n1. 한눈에 보는 비교 요약 구분 일반 Tool Calling (기존 방식) MCP (Model Context Protocol) 핵심 개념 함수 정의와 실행 로직의 수동 연결 도구의 정의와 실행이 결합된 표준화된 서버 실행 주체 에이전트 애플리케이션 (Local, Tightly Coupled) 독립된 MCP 서버 (Remote/Isolated) 통신 규격 모델별 전용 API (OpenAI, Anthropic 등) JSON-RPC 2.0 표준 프로토콜 툴 목록 관리 코드에 하드코딩, 앱 재배포 필요 서버에서 동적으로 list_tools() 조회 확장성 새 툴 추가 시 앱 코드 수정 및 재배포 MCP 서버만 추가·재시작하면 즉시 연동 상호운용성 모델별 규격 변환 코드 직접 작성 필요 MCP 지원 클라이언트라면 어떤 모델이든 재사용 컨텍스트 제공 주로 \u0026lsquo;액션(함수 호출)\u0026lsquo;에 집중 툴 + 리소스(파일, DB) + 프롬프트 템플릿 패키지 보안/격리 에이전트 프로세스 내에서 직접 실행 실행 로직이 서버에 캡슐화, 권한 경계 명확 2. 일반 Tool Calling: \u0026ldquo;직접 요리하기\u0026rdquo; 방식 일반적인 방식에서 에이전트는 요리사(LLM)가 준 레시피(JSON)를 보고 **직접 요리(함수 실행)**를 합니다.\n실행 로직이 에이전트 코드 내부에 깊게 박혀 있는 구조(Tightly Coupled)입니다.\n","keywords":["ai","agent","tool-calling","mcp","llm","json-rpc","devops"],"articleBody":"AI 에이전트를 구축할 때, LLM이 외부 도구를 사용하게 만드는 과정은 필수적입니다. 하지만 최근 등장한 **MCP(Model Context Protocol)**와 기존의 Function/Tool Calling은 비슷해 보이면서도 구조적으로 큰 차이가 있습니다. 오늘은 이 두 방식의 특징과 실제 구현 관점에서의 차이를 상세히 비교해 보겠습니다.\n1. 한눈에 보는 비교 요약 구분 일반 Tool Calling (기존 방식) MCP (Model Context Protocol) 핵심 개념 함수 정의와 실행 로직의 수동 연결 도구의 정의와 실행이 결합된 표준화된 서버 실행 주체 에이전트 애플리케이션 (Local, Tightly Coupled) 독립된 MCP 서버 (Remote/Isolated) 통신 규격 모델별 전용 API (OpenAI, Anthropic 등) JSON-RPC 2.0 표준 프로토콜 툴 목록 관리 코드에 하드코딩, 앱 재배포 필요 서버에서 동적으로 list_tools() 조회 확장성 새 툴 추가 시 앱 코드 수정 및 재배포 MCP 서버만 추가·재시작하면 즉시 연동 상호운용성 모델별 규격 변환 코드 직접 작성 필요 MCP 지원 클라이언트라면 어떤 모델이든 재사용 컨텍스트 제공 주로 ‘액션(함수 호출)‘에 집중 툴 + 리소스(파일, DB) + 프롬프트 템플릿 패키지 보안/격리 에이전트 프로세스 내에서 직접 실행 실행 로직이 서버에 캡슐화, 권한 경계 명확 2. 일반 Tool Calling: “직접 요리하기” 방식 일반적인 방식에서 에이전트는 요리사(LLM)가 준 레시피(JSON)를 보고 **직접 요리(함수 실행)**를 합니다.\n실행 로직이 에이전트 코드 내부에 깊게 박혀 있는 구조(Tightly Coupled)입니다.\n동작 흐름 사용자 요청 ↓ 에이전트 앱 (툴 스키마 정의 보유) ↓ (1) 툴 스키마 + 메시지 전달 LLM API ↓ (2) tool_calls JSON 반환 에이전트 앱 (if/else 분기로 직접 실행) ↓ (3) 로컬 함수 호출 → 결과 획득 LLM API (결과를 포함해 재호출) ↓ (4) 최종 텍스트 응답 사용자 구현 예시 (Python) import json # 1. 툴 정의 (JSON 스키마 — 에이전트 코드에 하드코딩) tools = [ { \"type\": \"function\", \"function\": { \"name\": \"adder\", \"description\": \"두 정수를 더합니다.\", \"parameters\": { \"type\": \"object\", \"properties\": { \"a\": {\"type\": \"integer\"}, \"b\": {\"type\": \"integer\"}, }, \"required\": [\"a\", \"b\"], }, }, } ] # 2. LLM 호출 response = llm_client.chat.completions.create( model=\"gpt-4o\", messages=messages, tools=tools, ) # 3. 직접 매핑 및 실행 (에이전트가 실행 오너십 보유) if response.choices[0].message.tool_calls: tool_call = response.choices[0].message.tool_calls[0] name = tool_call.function.name args = json.loads(tool_call.function.arguments) # 툴이 늘어날수록 if/else 분기가 계속 증가 if name == \"adder\": result = args[\"a\"] + args[\"b\"] # 에이전트가 직접 실행! elif name == \"another_tool\": result = another_local_func(**args) # ... # 결과를 메시지에 추가하고 재호출 messages.append(response.choices[0].message) messages.append({ \"role\": \"tool\", \"tool_call_id\": tool_call.id, \"content\": str(result), }) final = llm_client.chat.completions.create(model=\"gpt-4o\", messages=messages) print(final.choices[0].message.content) 특징 요약\n구현이 직관적이고 별도 인프라가 필요 없어 프로토타이핑에 적합 툴이 늘어날수록 if/else 분기가 길어지고 유지보수 비용 증가 OpenAI용 코드를 Anthropic/Gemini에 사용하려면 규격 변환 코드를 직접 작성 필요 에이전트 프로세스가 중단되면 툴 실행도 함께 중단 3. MCP Calling: “배달 주문하기” 방식 MCP 방식에서 에이전트는 요리사(LLM)의 요청을 보고 **전문 식당(MCP 서버)에 주문(Call)**을 넣습니다.\n에이전트는 내부 로직을 몰라도 표준 규격(JSON-RPC 2.0)만 맞추면 됩니다.\n동작 흐름 사용자 요청 ↓ 에이전트 앱 ↓ (1) list_tools() — 툴 목록 동적 조회 MCP 서버 (독립 프로세스) ↓ 툴 스키마 반환 에이전트 앱 ↓ (2) 툴 스키마 + 메시지 전달 LLM API ↓ (3) tool_calls JSON 반환 에이전트 앱 ↓ (4) call_tool() — 실행 위임 (JSON-RPC) MCP 서버 (실행 오너십 보유) ↓ 결과 반환 에이전트 앱 → LLM 재호출 → 최종 응답 ↓ 사용자 구현 예시 (Python — mcp 라이브러리 사용) from mcp import ClientSession, StdioServerParameters from mcp.client.stdio import stdio_client # 1. MCP 서버와 연결 (독립된 서버 프로세스) server_params = StdioServerParameters(command=\"python\", args=[\"mcp_server.py\"]) async with stdio_client(server_params) as (read, write): async with ClientSession(read, write) as session: await session.initialize() # 2. 툴 목록을 서버에서 동적으로 가져옴 — 하드코딩 불필요 tools_result = await session.list_tools() mcp_tools = [ { \"type\": \"function\", \"function\": { \"name\": t.name, \"description\": t.description, \"parameters\": t.inputSchema, }, } for t in tools_result.tools ] # 3. LLM 호출 response = llm_client.chat.completions.create( model=\"gpt-4o\", messages=messages, tools=mcp_tools, ) # 4. 실행 위임 — 에이전트는 단순히 중계만 수행 if response.choices[0].message.tool_calls: tool_call = response.choices[0].message.tool_calls[0] # MCP 서버로 실행 요청 위임 (실행 Ownership: Server) result = await session.call_tool( name=tool_call.function.name, arguments=json.loads(tool_call.function.arguments), ) messages.append(response.choices[0].message) messages.append({ \"role\": \"tool\", \"tool_call_id\": tool_call.id, \"content\": str(result.content), }) final = llm_client.chat.completions.create(model=\"gpt-4o\", messages=messages) print(final.choices[0].message.content) 특징 요약\n실행 로직이 MCP 서버에 캡슐화되어 보안성·격리성 우수 list_tools()로 툴 목록을 동적으로 수신 — 서버 재시작만으로 신규 툴 적용 한 번 만든 MCP 서버를 Claude, GPT, Gemini 등 여러 모델에서 공용 사용 가능 툴 외에도 Resources(파일, DB 데이터)와 Prompt Templates를 패키지로 제공 4. 핵심 차이점 상세 분석 실행 오너십 (Ownership) 항목 Tool Calling MCP 실행 주체 에이전트 앱 MCP 서버 프로세스 격리 ❌ 동일 프로세스 ✅ 독립 프로세스 오너십 위치 에이전트 코드 내 하드코딩 서버 내 캡슐화 에이전트가 중단되어도 MCP 서버는 독립적으로 동작할 수 있습니다.\n컨텍스트 제공 범위 (Context Sharing) MCP는 툴(Tool), 리소스(Resource), 프롬프트 템플릿(Prompt)의 세 가지 원시 타입을 통해 모델에게 풍부한 컨텍스트를 전달합니다.\nMCP 서버가 제공하는 것 ├── Tools — 함수 호출 (기존 Tool Calling과 동일) ├── Resources — 파일, DB 쿼리 결과 등 정적 컨텍스트 └── Prompts — 재사용 가능한 프롬프트 템플릿 일반 Tool Calling은 주로 **액션(함수 호출)**에만 집중하지만, MCP는 데이터 컨텍스트까지 패키지로 제공합니다.\n상호운용성 (Interoperability) 일반 Tool Calling: OpenAI 툴 스키마 ──→ Anthropic 포맷 변환 코드 직접 작성 필요 MCP: MCP 서버 ──→ (JSON-RPC 2.0 표준) ──→ 어떤 MCP 클라이언트도 즉시 연동 JSON-RPC 2.0을 표준 전송 계층으로 사용하므로, MCP를 지원하는 클라이언트라면\n모델 종류에 관계없이 동일한 서버를 재사용할 수 있습니다.\n통신 방식 (Transport) 및 마샬링 (Marshaling) 데이터 규약: JSON-RPC 2.0 MCP의 모든 메시지는 JSON-RPC 2.0 표준 형식을 따릅니다.\n데이터는 **JSON(UTF-8 인코딩)**으로 직렬화(Marshaling)되어 전송됩니다.\n// tool_call 발생 시 에이전트 → MCP 서버로 전달되는 실제 메시지 { \"jsonrpc\": \"2.0\", \"id\": \"123\", \"method\": \"tools/call\", \"params\": { \"name\": \"adder\", \"arguments\": { \"a\": 10, \"b\": 20 } } } 에이전트 코드에서 session.call_tool()을 호출하면, MCP 라이브러리가 내부적으로 위와 같은 JSON-RPC 메시지를 만들어 서버로 전송합니다. 개발자는 직접 JSON-RPC를 다루지 않아도 됩니다.\n전송 계층별 차이 두 방식 모두 동일한 JSON-RPC 2.0 메시지를 사용하지만, 메시지를 실어 나르는 통로와 **구분 방식(Framing)**이 다릅니다.\n구분 Stdio 방식 HTTP/SSE 방식 위치 로컬 (같은 컴퓨터 내 프로세스) 원격 (네트워크) 실행 방식 에이전트가 서버를 자식 프로세스로 직접 실행 외부 서버 URL로 접속 메시지 구분자 \\n (Newline) — JSON 한 줄로 직렬화 SSE 스펙 (data: 접두사 등) 속도 매우 빠름 (네트워크 오버헤드 없음) 상대적으로 느림 (TCP/HTTP 핸드셰이크) 주요 용도 로컬 도구 (파일, 셸, DB 등) 원격 서비스, 클라우드 배포 # Stdio wire 예시 — 개행(\\n)으로 메시지 경계 구분 {\"jsonrpc\":\"2.0\",\"id\":\"1\",\"method\":\"tools/call\",\"params\":{\"name\":\"adder\",\"arguments\":{\"a\":10,\"b\":20}}}\\n # HTTP/SSE wire 예시 — SSE 규격으로 메시지 경계 구분 event: message data: {\"jsonrpc\":\"2.0\",\"id\":\"1\",\"method\":\"tools/call\",\"params\":{\"name\":\"adder\",\"arguments\":{\"a\":10,\"b\":20}}} 요약: “마샬링된 JSON-RPC 메시지를 보낸다\"는 내용물은 동일합니다.\nStdio는 옆 프로세스에 개행 구분 텍스트를 던지는 것이고,\nHTTP는 원격 서버에 SSE 규격 스트림으로 보내는 것입니다.\n에이전트 코드 입장에서는 두 방식 모두 같은 session.call_tool() 인터페이스로 투명하게 사용할 수 있습니다.\n이러한 표준 규격 덕분에 Python 클라이언트와 Go 또는 TypeScript로 작성된 MCP 서버가 아무런 수정 없이 통신할 수 있습니다.\n5. 언제 무엇을 선택할까 일반 Tool Calling이 적합한 경우 1~3개의 간단한 내부 함수만 필요한 프로토타이핑 단일 모델(예: OpenAI만)을 고정해서 사용하는 환경 외부 서버 인프라를 운영하기 어려운 가벼운 스크립트 MCP가 적합한 경우 기업/팀 환경에서 여러 외부 서비스(Slack, GitHub, Jira 등)를 연동할 때 Claude, GPT, Gemini 등 여러 모델을 교체·비교해야 하는 에이전트 플랫폼 툴뿐 아니라 파일이나 DB 데이터도 컨텍스트로 주입해야 하는 경우 보안 경계가 필요한 환경 (툴 실행을 격리된 서버에서 처리) 다수의 에이전트가 동일한 MCP 서버를 공유해야 하는 마이크로서비스 구조 6. 참고 자료 MCP 공식 스펙 (2025-11-25) Martin Fowler — Function Calls and LLMs HuggingFace MCP Course — Architectural Components WorkOS — How MCP Servers Work JSON-RPC 2.0 in MCP ","wordCount":"1156","inLanguage":"en","datePublished":"2026-02-23T00:00:00+09:00","dateModified":"2026-02-23T00:00:00+09:00","author":{"@type":"Person","name":"Byung Kyu KIM"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://cdecl.github.io/devops/ai-agent-tool-calling-vs-mcp/"},"publisher":{"@type":"Organization","name":"cdeclog","logo":{"@type":"ImageObject","url":"https://cdecl.github.io/favicon.ico"}}}</script></head><body id=top><header class=header><nav class=nav><div class=logo><a href=https://cdecl.github.io/ accesskey=h title="cdeclog (Alt + H)">cdeclog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://cdecl.github.io/dev/ title=Dev><span>Dev</span></a></li><li><a href=https://cdecl.github.io/devops/ title=DevOps><span>DevOps</span></a></li><li><a href=https://cdecl.github.io/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://cdecl.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://cdecl.github.io/tags/ title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://cdecl.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://cdecl.github.io/devops/>Devops</a></div><h1 class="post-title entry-hint-parent">AI Agent 구현의 두 갈래: 일반 Tool Calling vs MCP 비교</h1><div class=post-meta><span title='2026-02-23 00:00:00 +0900 KST'>February 23, 2026</span>&nbsp;·&nbsp;<span>Byung Kyu KIM</span></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#1-%ed%95%9c%eb%88%88%ec%97%90-%eb%b3%b4%eb%8a%94-%eb%b9%84%ea%b5%90-%ec%9a%94%ec%95%bd aria-label="1. 한눈에 보는 비교 요약">1. 한눈에 보는 비교 요약</a></li><li><a href=#2-%ec%9d%bc%eb%b0%98-tool-calling-%ec%a7%81%ec%a0%91-%ec%9a%94%eb%a6%ac%ed%95%98%ea%b8%b0-%eb%b0%a9%ec%8b%9d aria-label="2. 일반 Tool Calling: &ldquo;직접 요리하기&rdquo; 방식">2. 일반 Tool Calling: &ldquo;직접 요리하기&rdquo; 방식</a><ul><li><a href=#%eb%8f%99%ec%9e%91-%ed%9d%90%eb%a6%84 aria-label="동작 흐름">동작 흐름</a></li><li><a href=#%ea%b5%ac%ed%98%84-%ec%98%88%ec%8b%9c-python aria-label="구현 예시 (Python)">구현 예시 (Python)</a></li></ul></li><li><a href=#3-mcp-calling-%eb%b0%b0%eb%8b%ac-%ec%a3%bc%eb%ac%b8%ed%95%98%ea%b8%b0-%eb%b0%a9%ec%8b%9d aria-label="3. MCP Calling: &ldquo;배달 주문하기&rdquo; 방식">3. MCP Calling: &ldquo;배달 주문하기&rdquo; 방식</a><ul><li><a href=#%eb%8f%99%ec%9e%91-%ed%9d%90%eb%a6%84-1 aria-label="동작 흐름">동작 흐름</a></li><li><a href=#%ea%b5%ac%ed%98%84-%ec%98%88%ec%8b%9c-python--mcp-%eb%9d%bc%ec%9d%b4%eb%b8%8c%eb%9f%ac%eb%a6%ac-%ec%82%ac%ec%9a%a9 aria-label="구현 예시 (Python — mcp 라이브러리 사용)">구현 예시 (Python — mcp 라이브러리 사용)</a></li></ul></li><li><a href=#4-%ed%95%b5%ec%8b%ac-%ec%b0%a8%ec%9d%b4%ec%a0%90-%ec%83%81%ec%84%b8-%eb%b6%84%ec%84%9d aria-label="4. 핵심 차이점 상세 분석">4. 핵심 차이점 상세 분석</a><ul><li><a href=#%ec%8b%a4%ed%96%89-%ec%98%a4%eb%84%88%ec%8b%ad-ownership aria-label="실행 오너십 (Ownership)">실행 오너십 (Ownership)</a></li><li><a href=#%ec%bb%a8%ed%85%8d%ec%8a%a4%ed%8a%b8-%ec%a0%9c%ea%b3%b5-%eb%b2%94%ec%9c%84-context-sharing aria-label="컨텍스트 제공 범위 (Context Sharing)">컨텍스트 제공 범위 (Context Sharing)</a></li><li><a href=#%ec%83%81%ed%98%b8%ec%9a%b4%ec%9a%a9%ec%84%b1-interoperability aria-label="상호운용성 (Interoperability)">상호운용성 (Interoperability)</a></li><li><a href=#%ed%86%b5%ec%8b%a0-%eb%b0%a9%ec%8b%9d-transport-%eb%b0%8f-%eb%a7%88%ec%83%ac%eb%a7%81-marshaling aria-label="통신 방식 (Transport) 및 마샬링 (Marshaling)">통신 방식 (Transport) 및 마샬링 (Marshaling)</a><ul><li><a href=#%eb%8d%b0%ec%9d%b4%ed%84%b0-%ea%b7%9c%ec%95%bd-json-rpc-20 aria-label="데이터 규약: JSON-RPC 2.0">데이터 규약: JSON-RPC 2.0</a></li><li><a href=#%ec%a0%84%ec%86%a1-%ea%b3%84%ec%b8%b5%eb%b3%84-%ec%b0%a8%ec%9d%b4 aria-label="전송 계층별 차이">전송 계층별 차이</a></li></ul></li></ul></li><li><a href=#5-%ec%96%b8%ec%a0%9c-%eb%ac%b4%ec%97%87%ec%9d%84-%ec%84%a0%ed%83%9d%ed%95%a0%ea%b9%8c aria-label="5. 언제 무엇을 선택할까">5. 언제 무엇을 선택할까</a><ul><li><a href=#%ec%9d%bc%eb%b0%98-tool-calling%ec%9d%b4-%ec%a0%81%ed%95%a9%ed%95%9c-%ea%b2%bd%ec%9a%b0 aria-label="일반 Tool Calling이 적합한 경우">일반 Tool Calling이 적합한 경우</a></li><li><a href=#mcp%ea%b0%80-%ec%a0%81%ed%95%a9%ed%95%9c-%ea%b2%bd%ec%9a%b0 aria-label="MCP가 적합한 경우">MCP가 적합한 경우</a></li></ul></li><li><a href=#6-%ec%b0%b8%ea%b3%a0-%ec%9e%90%eb%a3%8c aria-label="6. 참고 자료">6. 참고 자료</a></li></ul></div></details></div><div class=post-content><p>AI 에이전트를 구축할 때, LLM이 외부 도구를 사용하게 만드는 과정은 필수적입니다. 하지만 최근 등장한 **MCP(Model Context Protocol)**와 기존의 <strong>Function/Tool Calling</strong>은 비슷해 보이면서도 구조적으로 큰 차이가 있습니다. 오늘은 이 두 방식의 특징과 실제 구현 관점에서의 차이를 상세히 비교해 보겠습니다.</p><h2 id=1-한눈에-보는-비교-요약>1. 한눈에 보는 비교 요약<a hidden class=anchor aria-hidden=true href=#1-한눈에-보는-비교-요약>#</a></h2><table><thead><tr><th style=text-align:left>구분</th><th style=text-align:left>일반 Tool Calling (기존 방식)</th><th style=text-align:left>MCP (Model Context Protocol)</th></tr></thead><tbody><tr><td style=text-align:left><strong>핵심 개념</strong></td><td style=text-align:left>함수 정의와 실행 로직의 수동 연결</td><td style=text-align:left>도구의 정의와 실행이 결합된 표준화된 서버</td></tr><tr><td style=text-align:left><strong>실행 주체</strong></td><td style=text-align:left>에이전트 애플리케이션 (Local, Tightly Coupled)</td><td style=text-align:left>독립된 MCP 서버 (Remote/Isolated)</td></tr><tr><td style=text-align:left><strong>통신 규격</strong></td><td style=text-align:left>모델별 전용 API (OpenAI, Anthropic 등)</td><td style=text-align:left><strong>JSON-RPC 2.0</strong> 표준 프로토콜</td></tr><tr><td style=text-align:left><strong>툴 목록 관리</strong></td><td style=text-align:left>코드에 하드코딩, 앱 재배포 필요</td><td style=text-align:left>서버에서 동적으로 <code>list_tools()</code> 조회</td></tr><tr><td style=text-align:left><strong>확장성</strong></td><td style=text-align:left>새 툴 추가 시 앱 코드 수정 및 재배포</td><td style=text-align:left>MCP 서버만 추가·재시작하면 즉시 연동</td></tr><tr><td style=text-align:left><strong>상호운용성</strong></td><td style=text-align:left>모델별 규격 변환 코드 직접 작성 필요</td><td style=text-align:left>MCP 지원 클라이언트라면 어떤 모델이든 재사용</td></tr><tr><td style=text-align:left><strong>컨텍스트 제공</strong></td><td style=text-align:left>주로 &lsquo;액션(함수 호출)&lsquo;에 집중</td><td style=text-align:left>툴 + <strong>리소스(파일, DB)</strong> + <strong>프롬프트 템플릿</strong> 패키지</td></tr><tr><td style=text-align:left><strong>보안/격리</strong></td><td style=text-align:left>에이전트 프로세스 내에서 직접 실행</td><td style=text-align:left>실행 로직이 서버에 캡슐화, 권한 경계 명확</td></tr></tbody></table><hr><h2 id=2-일반-tool-calling-직접-요리하기-방식>2. 일반 Tool Calling: &ldquo;직접 요리하기&rdquo; 방식<a hidden class=anchor aria-hidden=true href=#2-일반-tool-calling-직접-요리하기-방식>#</a></h2><p>일반적인 방식에서 에이전트는 요리사(LLM)가 준 레시피(JSON)를 보고 **직접 요리(함수 실행)**를 합니다.<br>실행 로직이 에이전트 코드 내부에 깊게 박혀 있는 구조(Tightly Coupled)입니다.</p><h3 id=동작-흐름>동작 흐름<a hidden class=anchor aria-hidden=true href=#동작-흐름>#</a></h3><pre tabindex=0><code>사용자 요청
    ↓
에이전트 앱 (툴 스키마 정의 보유)
    ↓ (1) 툴 스키마 + 메시지 전달
LLM API
    ↓ (2) tool_calls JSON 반환
에이전트 앱 (if/else 분기로 직접 실행)
    ↓ (3) 로컬 함수 호출 → 결과 획득
LLM API (결과를 포함해 재호출)
    ↓ (4) 최종 텍스트 응답
사용자
</code></pre><h3 id=구현-예시-python>구현 예시 (Python)<a hidden class=anchor aria-hidden=true href=#구현-예시-python>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#ff79c6>import</span> json
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 1. 툴 정의 (JSON 스키마 — 에이전트 코드에 하드코딩)</span>
</span></span><span style=display:flex><span>tools <span style=color:#ff79c6>=</span> [
</span></span><span style=display:flex><span>    {
</span></span><span style=display:flex><span>        <span style=color:#f1fa8c>&#34;type&#34;</span>: <span style=color:#f1fa8c>&#34;function&#34;</span>,
</span></span><span style=display:flex><span>        <span style=color:#f1fa8c>&#34;function&#34;</span>: {
</span></span><span style=display:flex><span>            <span style=color:#f1fa8c>&#34;name&#34;</span>: <span style=color:#f1fa8c>&#34;adder&#34;</span>,
</span></span><span style=display:flex><span>            <span style=color:#f1fa8c>&#34;description&#34;</span>: <span style=color:#f1fa8c>&#34;두 정수를 더합니다.&#34;</span>,
</span></span><span style=display:flex><span>            <span style=color:#f1fa8c>&#34;parameters&#34;</span>: {
</span></span><span style=display:flex><span>                <span style=color:#f1fa8c>&#34;type&#34;</span>: <span style=color:#f1fa8c>&#34;object&#34;</span>,
</span></span><span style=display:flex><span>                <span style=color:#f1fa8c>&#34;properties&#34;</span>: {
</span></span><span style=display:flex><span>                    <span style=color:#f1fa8c>&#34;a&#34;</span>: {<span style=color:#f1fa8c>&#34;type&#34;</span>: <span style=color:#f1fa8c>&#34;integer&#34;</span>},
</span></span><span style=display:flex><span>                    <span style=color:#f1fa8c>&#34;b&#34;</span>: {<span style=color:#f1fa8c>&#34;type&#34;</span>: <span style=color:#f1fa8c>&#34;integer&#34;</span>},
</span></span><span style=display:flex><span>                },
</span></span><span style=display:flex><span>                <span style=color:#f1fa8c>&#34;required&#34;</span>: [<span style=color:#f1fa8c>&#34;a&#34;</span>, <span style=color:#f1fa8c>&#34;b&#34;</span>],
</span></span><span style=display:flex><span>            },
</span></span><span style=display:flex><span>        },
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 2. LLM 호출</span>
</span></span><span style=display:flex><span>response <span style=color:#ff79c6>=</span> llm_client<span style=color:#ff79c6>.</span>chat<span style=color:#ff79c6>.</span>completions<span style=color:#ff79c6>.</span>create(
</span></span><span style=display:flex><span>    model<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#34;gpt-4o&#34;</span>,
</span></span><span style=display:flex><span>    messages<span style=color:#ff79c6>=</span>messages,
</span></span><span style=display:flex><span>    tools<span style=color:#ff79c6>=</span>tools,
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 3. 직접 매핑 및 실행 (에이전트가 실행 오너십 보유)</span>
</span></span><span style=display:flex><span><span style=color:#ff79c6>if</span> response<span style=color:#ff79c6>.</span>choices[<span style=color:#bd93f9>0</span>]<span style=color:#ff79c6>.</span>message<span style=color:#ff79c6>.</span>tool_calls:
</span></span><span style=display:flex><span>    tool_call <span style=color:#ff79c6>=</span> response<span style=color:#ff79c6>.</span>choices[<span style=color:#bd93f9>0</span>]<span style=color:#ff79c6>.</span>message<span style=color:#ff79c6>.</span>tool_calls[<span style=color:#bd93f9>0</span>]
</span></span><span style=display:flex><span>    name <span style=color:#ff79c6>=</span> tool_call<span style=color:#ff79c6>.</span>function<span style=color:#ff79c6>.</span>name
</span></span><span style=display:flex><span>    args <span style=color:#ff79c6>=</span> json<span style=color:#ff79c6>.</span>loads(tool_call<span style=color:#ff79c6>.</span>function<span style=color:#ff79c6>.</span>arguments)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#6272a4># 툴이 늘어날수록 if/else 분기가 계속 증가</span>
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>if</span> name <span style=color:#ff79c6>==</span> <span style=color:#f1fa8c>&#34;adder&#34;</span>:
</span></span><span style=display:flex><span>        result <span style=color:#ff79c6>=</span> args[<span style=color:#f1fa8c>&#34;a&#34;</span>] <span style=color:#ff79c6>+</span> args[<span style=color:#f1fa8c>&#34;b&#34;</span>]   <span style=color:#6272a4># 에이전트가 직접 실행!</span>
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>elif</span> name <span style=color:#ff79c6>==</span> <span style=color:#f1fa8c>&#34;another_tool&#34;</span>:
</span></span><span style=display:flex><span>        result <span style=color:#ff79c6>=</span> another_local_func(<span style=color:#ff79c6>**</span>args)
</span></span><span style=display:flex><span>    <span style=color:#6272a4># ...</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#6272a4># 결과를 메시지에 추가하고 재호출</span>
</span></span><span style=display:flex><span>    messages<span style=color:#ff79c6>.</span>append(response<span style=color:#ff79c6>.</span>choices[<span style=color:#bd93f9>0</span>]<span style=color:#ff79c6>.</span>message)
</span></span><span style=display:flex><span>    messages<span style=color:#ff79c6>.</span>append({
</span></span><span style=display:flex><span>        <span style=color:#f1fa8c>&#34;role&#34;</span>: <span style=color:#f1fa8c>&#34;tool&#34;</span>,
</span></span><span style=display:flex><span>        <span style=color:#f1fa8c>&#34;tool_call_id&#34;</span>: tool_call<span style=color:#ff79c6>.</span>id,
</span></span><span style=display:flex><span>        <span style=color:#f1fa8c>&#34;content&#34;</span>: <span style=color:#8be9fd;font-style:italic>str</span>(result),
</span></span><span style=display:flex><span>    })
</span></span><span style=display:flex><span>    final <span style=color:#ff79c6>=</span> llm_client<span style=color:#ff79c6>.</span>chat<span style=color:#ff79c6>.</span>completions<span style=color:#ff79c6>.</span>create(model<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#34;gpt-4o&#34;</span>, messages<span style=color:#ff79c6>=</span>messages)
</span></span><span style=display:flex><span>    <span style=color:#8be9fd;font-style:italic>print</span>(final<span style=color:#ff79c6>.</span>choices[<span style=color:#bd93f9>0</span>]<span style=color:#ff79c6>.</span>message<span style=color:#ff79c6>.</span>content)
</span></span></code></pre></div><p><strong>특징 요약</strong></p><ul><li>구현이 직관적이고 별도 인프라가 필요 없어 <strong>프로토타이핑에 적합</strong></li><li>툴이 늘어날수록 <code>if/else</code> 분기가 길어지고 유지보수 비용 증가</li><li>OpenAI용 코드를 Anthropic/Gemini에 사용하려면 <strong>규격 변환 코드를 직접 작성</strong> 필요</li><li>에이전트 프로세스가 중단되면 툴 실행도 함께 중단</li></ul><hr><h2 id=3-mcp-calling-배달-주문하기-방식>3. MCP Calling: &ldquo;배달 주문하기&rdquo; 방식<a hidden class=anchor aria-hidden=true href=#3-mcp-calling-배달-주문하기-방식>#</a></h2><p>MCP 방식에서 에이전트는 요리사(LLM)의 요청을 보고 **전문 식당(MCP 서버)에 주문(Call)**을 넣습니다.<br>에이전트는 내부 로직을 몰라도 표준 규격(JSON-RPC 2.0)만 맞추면 됩니다.</p><h3 id=동작-흐름-1>동작 흐름<a hidden class=anchor aria-hidden=true href=#동작-흐름-1>#</a></h3><pre tabindex=0><code>사용자 요청
    ↓
에이전트 앱
    ↓ (1) list_tools() — 툴 목록 동적 조회
MCP 서버 (독립 프로세스)
    ↓ 툴 스키마 반환
에이전트 앱
    ↓ (2) 툴 스키마 + 메시지 전달
LLM API
    ↓ (3) tool_calls JSON 반환
에이전트 앱
    ↓ (4) call_tool() — 실행 위임 (JSON-RPC)
MCP 서버 (실행 오너십 보유)
    ↓ 결과 반환
에이전트 앱 → LLM 재호출 → 최종 응답
    ↓
사용자
</code></pre><h3 id=구현-예시-python--mcp-라이브러리-사용>구현 예시 (Python — mcp 라이브러리 사용)<a hidden class=anchor aria-hidden=true href=#구현-예시-python--mcp-라이브러리-사용>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#ff79c6>from</span> mcp <span style=color:#ff79c6>import</span> ClientSession, StdioServerParameters
</span></span><span style=display:flex><span><span style=color:#ff79c6>from</span> mcp.client.stdio <span style=color:#ff79c6>import</span> stdio_client
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 1. MCP 서버와 연결 (독립된 서버 프로세스)</span>
</span></span><span style=display:flex><span>server_params <span style=color:#ff79c6>=</span> StdioServerParameters(command<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#34;python&#34;</span>, args<span style=color:#ff79c6>=</span>[<span style=color:#f1fa8c>&#34;mcp_server.py&#34;</span>])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff79c6>async</span> <span style=color:#ff79c6>with</span> stdio_client(server_params) <span style=color:#ff79c6>as</span> (read, write):
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>async</span> <span style=color:#ff79c6>with</span> ClientSession(read, write) <span style=color:#ff79c6>as</span> session:
</span></span><span style=display:flex><span>        <span style=color:#ff79c6>await</span> session<span style=color:#ff79c6>.</span>initialize()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#6272a4># 2. 툴 목록을 서버에서 동적으로 가져옴 — 하드코딩 불필요</span>
</span></span><span style=display:flex><span>        tools_result <span style=color:#ff79c6>=</span> <span style=color:#ff79c6>await</span> session<span style=color:#ff79c6>.</span>list_tools()
</span></span><span style=display:flex><span>        mcp_tools <span style=color:#ff79c6>=</span> [
</span></span><span style=display:flex><span>            {
</span></span><span style=display:flex><span>                <span style=color:#f1fa8c>&#34;type&#34;</span>: <span style=color:#f1fa8c>&#34;function&#34;</span>,
</span></span><span style=display:flex><span>                <span style=color:#f1fa8c>&#34;function&#34;</span>: {
</span></span><span style=display:flex><span>                    <span style=color:#f1fa8c>&#34;name&#34;</span>: t<span style=color:#ff79c6>.</span>name,
</span></span><span style=display:flex><span>                    <span style=color:#f1fa8c>&#34;description&#34;</span>: t<span style=color:#ff79c6>.</span>description,
</span></span><span style=display:flex><span>                    <span style=color:#f1fa8c>&#34;parameters&#34;</span>: t<span style=color:#ff79c6>.</span>inputSchema,
</span></span><span style=display:flex><span>                },
</span></span><span style=display:flex><span>            }
</span></span><span style=display:flex><span>            <span style=color:#ff79c6>for</span> t <span style=color:#ff79c6>in</span> tools_result<span style=color:#ff79c6>.</span>tools
</span></span><span style=display:flex><span>        ]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#6272a4># 3. LLM 호출</span>
</span></span><span style=display:flex><span>        response <span style=color:#ff79c6>=</span> llm_client<span style=color:#ff79c6>.</span>chat<span style=color:#ff79c6>.</span>completions<span style=color:#ff79c6>.</span>create(
</span></span><span style=display:flex><span>            model<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#34;gpt-4o&#34;</span>,
</span></span><span style=display:flex><span>            messages<span style=color:#ff79c6>=</span>messages,
</span></span><span style=display:flex><span>            tools<span style=color:#ff79c6>=</span>mcp_tools,
</span></span><span style=display:flex><span>        )
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#6272a4># 4. 실행 위임 — 에이전트는 단순히 중계만 수행</span>
</span></span><span style=display:flex><span>        <span style=color:#ff79c6>if</span> response<span style=color:#ff79c6>.</span>choices[<span style=color:#bd93f9>0</span>]<span style=color:#ff79c6>.</span>message<span style=color:#ff79c6>.</span>tool_calls:
</span></span><span style=display:flex><span>            tool_call <span style=color:#ff79c6>=</span> response<span style=color:#ff79c6>.</span>choices[<span style=color:#bd93f9>0</span>]<span style=color:#ff79c6>.</span>message<span style=color:#ff79c6>.</span>tool_calls[<span style=color:#bd93f9>0</span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>            <span style=color:#6272a4># MCP 서버로 실행 요청 위임 (실행 Ownership: Server)</span>
</span></span><span style=display:flex><span>            result <span style=color:#ff79c6>=</span> <span style=color:#ff79c6>await</span> session<span style=color:#ff79c6>.</span>call_tool(
</span></span><span style=display:flex><span>                name<span style=color:#ff79c6>=</span>tool_call<span style=color:#ff79c6>.</span>function<span style=color:#ff79c6>.</span>name,
</span></span><span style=display:flex><span>                arguments<span style=color:#ff79c6>=</span>json<span style=color:#ff79c6>.</span>loads(tool_call<span style=color:#ff79c6>.</span>function<span style=color:#ff79c6>.</span>arguments),
</span></span><span style=display:flex><span>            )
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>            messages<span style=color:#ff79c6>.</span>append(response<span style=color:#ff79c6>.</span>choices[<span style=color:#bd93f9>0</span>]<span style=color:#ff79c6>.</span>message)
</span></span><span style=display:flex><span>            messages<span style=color:#ff79c6>.</span>append({
</span></span><span style=display:flex><span>                <span style=color:#f1fa8c>&#34;role&#34;</span>: <span style=color:#f1fa8c>&#34;tool&#34;</span>,
</span></span><span style=display:flex><span>                <span style=color:#f1fa8c>&#34;tool_call_id&#34;</span>: tool_call<span style=color:#ff79c6>.</span>id,
</span></span><span style=display:flex><span>                <span style=color:#f1fa8c>&#34;content&#34;</span>: <span style=color:#8be9fd;font-style:italic>str</span>(result<span style=color:#ff79c6>.</span>content),
</span></span><span style=display:flex><span>            })
</span></span><span style=display:flex><span>            final <span style=color:#ff79c6>=</span> llm_client<span style=color:#ff79c6>.</span>chat<span style=color:#ff79c6>.</span>completions<span style=color:#ff79c6>.</span>create(model<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#34;gpt-4o&#34;</span>, messages<span style=color:#ff79c6>=</span>messages)
</span></span><span style=display:flex><span>            <span style=color:#8be9fd;font-style:italic>print</span>(final<span style=color:#ff79c6>.</span>choices[<span style=color:#bd93f9>0</span>]<span style=color:#ff79c6>.</span>message<span style=color:#ff79c6>.</span>content)
</span></span></code></pre></div><p><strong>특징 요약</strong></p><ul><li>실행 로직이 MCP 서버에 캡슐화되어 <strong>보안성·격리성</strong> 우수</li><li><code>list_tools()</code>로 툴 목록을 동적으로 수신 — 서버 재시작만으로 신규 툴 적용</li><li>한 번 만든 MCP 서버를 Claude, GPT, Gemini 등 <strong>여러 모델에서 공용</strong> 사용 가능</li><li>툴 외에도 <strong>Resources</strong>(파일, DB 데이터)와 <strong>Prompt Templates</strong>를 패키지로 제공</li></ul><hr><h2 id=4-핵심-차이점-상세-분석>4. 핵심 차이점 상세 분석<a hidden class=anchor aria-hidden=true href=#4-핵심-차이점-상세-분석>#</a></h2><h3 id=실행-오너십-ownership>실행 오너십 (Ownership)<a hidden class=anchor aria-hidden=true href=#실행-오너십-ownership>#</a></h3><table><thead><tr><th style=text-align:left>항목</th><th style=text-align:left>Tool Calling</th><th style=text-align:left>MCP</th></tr></thead><tbody><tr><td style=text-align:left>실행 주체</td><td style=text-align:left>에이전트 앱</td><td style=text-align:left>MCP 서버</td></tr><tr><td style=text-align:left>프로세스 격리</td><td style=text-align:left>❌ 동일 프로세스</td><td style=text-align:left>✅ 독립 프로세스</td></tr><tr><td style=text-align:left>오너십 위치</td><td style=text-align:left>에이전트 코드 내 하드코딩</td><td style=text-align:left>서버 내 캡슐화</td></tr></tbody></table><p>에이전트가 중단되어도 MCP 서버는 독립적으로 동작할 수 있습니다.</p><h3 id=컨텍스트-제공-범위-context-sharing>컨텍스트 제공 범위 (Context Sharing)<a hidden class=anchor aria-hidden=true href=#컨텍스트-제공-범위-context-sharing>#</a></h3><p>MCP는 툴(Tool), 리소스(Resource), 프롬프트 템플릿(Prompt)의 세 가지 원시 타입을 통해 모델에게 풍부한 컨텍스트를 전달합니다.</p><pre tabindex=0><code>MCP 서버가 제공하는 것
├── Tools      — 함수 호출 (기존 Tool Calling과 동일)
├── Resources  — 파일, DB 쿼리 결과 등 정적 컨텍스트
└── Prompts    — 재사용 가능한 프롬프트 템플릿
</code></pre><p>일반 Tool Calling은 주로 **액션(함수 호출)**에만 집중하지만, MCP는 <strong>데이터 컨텍스트까지 패키지</strong>로 제공합니다.</p><h3 id=상호운용성-interoperability>상호운용성 (Interoperability)<a hidden class=anchor aria-hidden=true href=#상호운용성-interoperability>#</a></h3><pre tabindex=0><code>일반 Tool Calling:
OpenAI 툴 스키마 ──→ Anthropic 포맷 변환 코드 직접 작성 필요

MCP:
MCP 서버 ──→ (JSON-RPC 2.0 표준) ──→ 어떤 MCP 클라이언트도 즉시 연동
</code></pre><p>JSON-RPC 2.0을 표준 전송 계층으로 사용하므로, MCP를 지원하는 클라이언트라면<br>모델 종류에 관계없이 <strong>동일한 서버</strong>를 재사용할 수 있습니다.</p><h3 id=통신-방식-transport-및-마샬링-marshaling>통신 방식 (Transport) 및 마샬링 (Marshaling)<a hidden class=anchor aria-hidden=true href=#통신-방식-transport-및-마샬링-marshaling>#</a></h3><h4 id=데이터-규약-json-rpc-20>데이터 규약: JSON-RPC 2.0<a hidden class=anchor aria-hidden=true href=#데이터-규약-json-rpc-20>#</a></h4><p>MCP의 모든 메시지는 <strong>JSON-RPC 2.0</strong> 표준 형식을 따릅니다.<br>데이터는 **JSON(UTF-8 인코딩)**으로 직렬화(Marshaling)되어 전송됩니다.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class=language-json data-lang=json><span style=display:flex><span><span style=color:#6272a4>// tool_call 발생 시 에이전트 → MCP 서버로 전달되는 실제 메시지
</span></span></span><span style=display:flex><span>{
</span></span><span style=display:flex><span>  <span style=color:#ff79c6>&#34;jsonrpc&#34;</span>: <span style=color:#f1fa8c>&#34;2.0&#34;</span>,
</span></span><span style=display:flex><span>  <span style=color:#ff79c6>&#34;id&#34;</span>: <span style=color:#f1fa8c>&#34;123&#34;</span>,
</span></span><span style=display:flex><span>  <span style=color:#ff79c6>&#34;method&#34;</span>: <span style=color:#f1fa8c>&#34;tools/call&#34;</span>,
</span></span><span style=display:flex><span>  <span style=color:#ff79c6>&#34;params&#34;</span>: {
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>&#34;name&#34;</span>: <span style=color:#f1fa8c>&#34;adder&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>&#34;arguments&#34;</span>: {
</span></span><span style=display:flex><span>      <span style=color:#ff79c6>&#34;a&#34;</span>: <span style=color:#bd93f9>10</span>,
</span></span><span style=display:flex><span>      <span style=color:#ff79c6>&#34;b&#34;</span>: <span style=color:#bd93f9>20</span>
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>  }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>에이전트 코드에서 <code>session.call_tool()</code>을 호출하면, MCP 라이브러리가 내부적으로 위와 같은 JSON-RPC 메시지를 만들어 서버로 전송합니다. <strong>개발자는 직접 JSON-RPC를 다루지 않아도</strong> 됩니다.</p><h4 id=전송-계층별-차이>전송 계층별 차이<a hidden class=anchor aria-hidden=true href=#전송-계층별-차이>#</a></h4><p>두 방식 모두 동일한 JSON-RPC 2.0 메시지를 사용하지만, <strong>메시지를 실어 나르는 통로</strong>와 **구분 방식(Framing)**이 다릅니다.</p><table><thead><tr><th style=text-align:left>구분</th><th style=text-align:left>Stdio 방식</th><th style=text-align:left>HTTP/SSE 방식</th></tr></thead><tbody><tr><td style=text-align:left><strong>위치</strong></td><td style=text-align:left>로컬 (같은 컴퓨터 내 프로세스)</td><td style=text-align:left>원격 (네트워크)</td></tr><tr><td style=text-align:left><strong>실행 방식</strong></td><td style=text-align:left>에이전트가 서버를 자식 프로세스로 직접 실행</td><td style=text-align:left>외부 서버 URL로 접속</td></tr><tr><td style=text-align:left><strong>메시지 구분자</strong></td><td style=text-align:left><code>\n</code> (Newline) — JSON 한 줄로 직렬화</td><td style=text-align:left>SSE 스펙 (<code>data:</code> 접두사 등)</td></tr><tr><td style=text-align:left><strong>속도</strong></td><td style=text-align:left><strong>매우 빠름</strong> (네트워크 오버헤드 없음)</td><td style=text-align:left>상대적으로 느림 (TCP/HTTP 핸드셰이크)</td></tr><tr><td style=text-align:left><strong>주요 용도</strong></td><td style=text-align:left>로컬 도구 (파일, 셸, DB 등)</td><td style=text-align:left>원격 서비스, 클라우드 배포</td></tr></tbody></table><pre tabindex=0><code># Stdio wire 예시 — 개행(\n)으로 메시지 경계 구분
{&#34;jsonrpc&#34;:&#34;2.0&#34;,&#34;id&#34;:&#34;1&#34;,&#34;method&#34;:&#34;tools/call&#34;,&#34;params&#34;:{&#34;name&#34;:&#34;adder&#34;,&#34;arguments&#34;:{&#34;a&#34;:10,&#34;b&#34;:20}}}\n

# HTTP/SSE wire 예시 — SSE 규격으로 메시지 경계 구분
event: message
data: {&#34;jsonrpc&#34;:&#34;2.0&#34;,&#34;id&#34;:&#34;1&#34;,&#34;method&#34;:&#34;tools/call&#34;,&#34;params&#34;:{&#34;name&#34;:&#34;adder&#34;,&#34;arguments&#34;:{&#34;a&#34;:10,&#34;b&#34;:20}}}
</code></pre><blockquote><p><strong>요약</strong>: &ldquo;마샬링된 JSON-RPC 메시지를 보낸다"는 내용물은 동일합니다.<br><strong>Stdio</strong>는 옆 프로세스에 개행 구분 텍스트를 던지는 것이고,<br><strong>HTTP</strong>는 원격 서버에 SSE 규격 스트림으로 보내는 것입니다.<br>에이전트 코드 입장에서는 두 방식 모두 같은 <code>session.call_tool()</code> 인터페이스로 투명하게 사용할 수 있습니다.</p></blockquote><p>이러한 표준 규격 덕분에 <strong>Python</strong> 클라이언트와 <strong>Go</strong> 또는 <strong>TypeScript</strong>로 작성된 MCP 서버가 아무런 수정 없이 통신할 수 있습니다.</p><hr><h2 id=5-언제-무엇을-선택할까>5. 언제 무엇을 선택할까<a hidden class=anchor aria-hidden=true href=#5-언제-무엇을-선택할까>#</a></h2><h3 id=일반-tool-calling이-적합한-경우>일반 Tool Calling이 적합한 경우<a hidden class=anchor aria-hidden=true href=#일반-tool-calling이-적합한-경우>#</a></h3><ul><li><strong>1~3개</strong>의 간단한 내부 함수만 필요한 프로토타이핑</li><li>단일 모델(예: OpenAI만)을 고정해서 사용하는 환경</li><li>외부 서버 인프라를 운영하기 어려운 가벼운 스크립트</li></ul><h3 id=mcp가-적합한-경우>MCP가 적합한 경우<a hidden class=anchor aria-hidden=true href=#mcp가-적합한-경우>#</a></h3><ul><li><strong>기업/팀 환경</strong>에서 여러 외부 서비스(Slack, GitHub, Jira 등)를 연동할 때</li><li>Claude, GPT, Gemini 등 <strong>여러 모델을 교체·비교</strong>해야 하는 에이전트 플랫폼</li><li>툴뿐 아니라 <strong>파일이나 DB 데이터</strong>도 컨텍스트로 주입해야 하는 경우</li><li>보안 경계가 필요한 환경 (툴 실행을 격리된 서버에서 처리)</li><li>다수의 에이전트가 <strong>동일한 MCP 서버를 공유</strong>해야 하는 마이크로서비스 구조</li></ul><hr><h2 id=6-참고-자료>6. 참고 자료<a hidden class=anchor aria-hidden=true href=#6-참고-자료>#</a></h2><ul><li><a href=https://modelcontextprotocol.io/specification/2025-11-25>MCP 공식 스펙 (2025-11-25)</a></li><li><a href=https://martinfowler.com/articles/function-call-LLM.html>Martin Fowler — Function Calls and LLMs</a></li><li><a href=https://huggingface.co/learn/mcp-course/en/unit1/architectural-components>HuggingFace MCP Course — Architectural Components</a></li><li><a href=https://workos.com/blog/how-mcp-servers-work>WorkOS — How MCP Servers Work</a></li><li><a href=https://mcpcat.io/guides/understanding-json-rpc-protocol-mcp/>JSON-RPC 2.0 in MCP</a></li></ul></div><footer class=post-footer><ul class=post-tags><li><a href=https://cdecl.github.io/tags/ai/>AI</a></li><li><a href=https://cdecl.github.io/tags/agent/>Agent</a></li><li><a href=https://cdecl.github.io/tags/tool-calling/>Tool-Calling</a></li><li><a href=https://cdecl.github.io/tags/mcp/>Mcp</a></li><li><a href=https://cdecl.github.io/tags/llm/>LLM</a></li><li><a href=https://cdecl.github.io/tags/json-rpc/>Json-Rpc</a></li><li><a href=https://cdecl.github.io/tags/devops/>DevOps</a></li></ul></footer><script src=https://giscus.app/client.js data-repo=cdecl/cdecl.github.io data-repo-id="MDEwOlJlcG9zaXRvcnkzNDk1ODUyNjg=" data-category=General data-category-id=DIC_kwDOFNY_dM4C1XMk data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=transparent_dark data-lang=ko crossorigin=anonymous async></script></article></main><footer class=footer><span>&copy; 2026 <a href=https://cdecl.github.io/>cdeclog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");if(menu){const e=localStorage.getItem("menu-scroll-position");e&&(menu.scrollLeft=parseInt(e,10)),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}}document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{const e=document.querySelector("html");e.dataset.theme==="dark"?(e.dataset.theme="light",localStorage.setItem("pref-theme","light")):(e.dataset.theme="dark",localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>