<!doctype html><html lang=en dir=auto data-theme=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>AI | cdeclog</title><meta name=keywords content><meta name=description content="cdecl's Dev.Ops Blog"><meta name=author content="Byung Kyu KIM"><link rel=canonical href=https://cdecl.github.io/tags/ai/><link crossorigin=anonymous href=/assets/css/stylesheet.f939c4ffefb264e6fe85e04352266f79db6bb1303c8e16ae9b6064c1247b5e32.css integrity="sha256-+TnE/++yZOb+heBDUiZvedtrsTA8jhaum2BkwSR7XjI=" rel="preload stylesheet" as=style><link rel=icon href=https://cdecl.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://cdecl.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://cdecl.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://cdecl.github.io/apple-touch-icon.png><link rel=mask-icon href=https://cdecl.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://cdecl.github.io/tags/ai/index.xml title=rss><link rel=alternate hreflang=en href=https://cdecl.github.io/tags/ai/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51);color-scheme:dark}.list{background:var(--theme)}.toc{background:var(--entry)}}@media(prefers-color-scheme:light){.list::-webkit-scrollbar-thumb{border-color:var(--code-bg)}}</style></noscript><script>localStorage.getItem("pref-theme")==="dark"?document.querySelector("html").dataset.theme="dark":localStorage.getItem("pref-theme")==="light"?document.querySelector("html").dataset.theme="light":window.matchMedia("(prefers-color-scheme: dark)").matches?document.querySelector("html").dataset.theme="dark":document.querySelector("html").dataset.theme="light"</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-VQQHHYPN7K"></script><script>var doNotTrack=!1,dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes";if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-VQQHHYPN7K")}</script><meta property="og:url" content="https://cdecl.github.io/tags/ai/"><meta property="og:site_name" content="cdeclog"><meta property="og:title" content="AI"><meta property="og:description" content="cdecl's Dev.Ops Blog"><meta property="og:locale" content="ko-kr"><meta property="og:type" content="website"><meta name=twitter:card content="summary"><meta name=twitter:title content="AI"><meta name=twitter:description content="cdecl's Dev.Ops Blog"></head><body class=list id=top><header class=header><nav class=nav><div class=logo><a href=https://cdecl.github.io/ accesskey=h title="cdeclog (Alt + H)">cdeclog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://cdecl.github.io/dev/ title=Dev><span>Dev</span></a></li><li><a href=https://cdecl.github.io/devops/ title=DevOps><span>DevOps</span></a></li><li><a href=https://cdecl.github.io/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://cdecl.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://cdecl.github.io/tags/ title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><header class=page-header><div class=breadcrumbs><a href=https://cdecl.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://cdecl.github.io/tags/>Tags</a></div><h1>AI</h1></header><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>2026 글로벌 LLM 생태계 비교: 파운데이션 모델부터 인프라 서비스까지</h2></header><div class=entry-content><p>2026년 현재 LLM 시장은 모델을 직접 학습시켜 배포하는 파운데이션 모델 제공자(Builders) 와, 이 모델들을 기업 및 개발자가 쉽게 도입·최적화할 수 있도록 돕는 인프라 및 통합 서비스 제공자(Enablers) 로 생태계가 양분되어 있습니다.
북미의 프론티어 모델과 중국의 고효율 모델들이 치열하게 경쟁하는 가운데, Provider 관점에서 각 모델의 세부 특징과 인프라 서비스를 총정리합니다.
1. 파운데이션 모델 생태계 (Builders): 북미 vs 중국 LLM의 원천 지능을 제공하는 기업들입니다.
북미는 범용적 에이전트와 멀티모달에, 중국은 극강의 가성비와 오픈소스 생태계에 집중하고 있습니다.
...</p></div><footer class=entry-footer><span title='2026-02-25 00:00:00 +0900 KST'>February 25, 2026</span>&nbsp;·&nbsp;<span>Byung Kyu KIM</span></footer><a class=entry-link aria-label="post link to 2026 글로벌 LLM 생태계 비교: 파운데이션 모델부터 인프라 서비스까지" href=https://cdecl.github.io/devops/ai-models-comparison/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>LLM 핵심 능력 해부: 추론 vs 코드 생성 vs Tool Calling, 그리고 자율 에이전트</h2></header><div class=entry-content><p>LLM은 모두 같은 방식으로 작동하는 것일까요? 최근 OpenAI o3, DeepSeek R1 같은 추론 모델(Reasoning Model) 이 등장하면서, 기존 LLM과는 근본적으로 다른 사고 방식이 주목받고 있습니다. 또한 코드 생성이나 Tool Calling 능력은 추론과 어떤 관계에 있을까요?
이 글에서는 LLM의 세 가지 핵심 능력 — 일반 생성, 추론, 코드/Tool Calling — 이 어떻게 다르고, 서로 어떤 관계를 갖는지 정리합니다.
1. 일반 LLM: “직감으로 답하기” (System 1) 일반 LLM(GPT-4o, Claude 3.5 Sonnet 등)은 본질적으로 다음 토큰 예측기(Next-Token Predictor) 입니다. 학습된 수십억 개의 파라미터 속에서 패턴을 매칭하여, 입력에 가장 그럴듯한 다음 단어를 즉각적으로 생성합니다.
...</p></div><footer class=entry-footer><span title='2026-02-25 00:00:00 +0900 KST'>February 25, 2026</span>&nbsp;·&nbsp;<span>Byung Kyu KIM</span></footer><a class=entry-link aria-label="post link to LLM 핵심 능력 해부: 추론 vs 코드 생성 vs Tool Calling, 그리고 자율 에이전트" href=https://cdecl.github.io/devops/llm-reasoning-vs-tool-calling/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>AI Agent 구현의 두 갈래: 일반 Tool Calling vs MCP 비교</h2></header><div class=entry-content><p>AI 에이전트를 구축할 때, LLM이 외부 도구를 사용하게 만드는 과정은 필수적입니다. 하지만 최근 등장한 **MCP(Model Context Protocol)**와 기존의 Function/Tool Calling은 비슷해 보이면서도 구조적으로 큰 차이가 있습니다. 오늘은 이 두 방식의 특징과 실제 구현 관점에서의 차이를 상세히 비교해 보겠습니다.
1. 한눈에 보는 비교 요약 구분 일반 Tool Calling (기존 방식) MCP (Model Context Protocol) 핵심 개념 함수 정의와 실행 로직의 수동 연결 도구의 정의와 실행이 결합된 표준화된 서버 실행 주체 에이전트 애플리케이션 (Local, Tightly Coupled) 독립된 MCP 서버 (Remote/Isolated) 통신 규격 모델별 전용 API (OpenAI, Anthropic 등) JSON-RPC 2.0 표준 프로토콜 툴 목록 관리 코드에 하드코딩, 앱 재배포 필요 서버에서 동적으로 list_tools() 조회 확장성 새 툴 추가 시 앱 코드 수정 및 재배포 MCP 서버만 추가·재시작하면 즉시 연동 상호운용성 모델별 규격 변환 코드 직접 작성 필요 MCP 지원 클라이언트라면 어떤 모델이든 재사용 컨텍스트 제공 주로 ‘액션(함수 호출)‘에 집중 툴 + 리소스(파일, DB) + 프롬프트 템플릿 패키지 보안/격리 에이전트 프로세스 내에서 직접 실행 실행 로직이 서버에 캡슐화, 권한 경계 명확 2. 일반 Tool Calling: “직접 요리하기” 방식 일반적인 방식에서 에이전트는 요리사(LLM)가 준 레시피(JSON)를 보고 **직접 요리(함수 실행)**를 합니다.
실행 로직이 에이전트 코드 내부에 깊게 박혀 있는 구조(Tightly Coupled)입니다.
...</p></div><footer class=entry-footer><span title='2026-02-23 00:00:00 +0900 KST'>February 23, 2026</span>&nbsp;·&nbsp;<span>Byung Kyu KIM</span></footer><a class=entry-link aria-label="post link to AI Agent 구현의 두 갈래: 일반 Tool Calling vs MCP 비교" href=https://cdecl.github.io/devops/ai-agent-tool-calling-vs-mcp/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>AI 에이전트(OpenClaw 등)의 LLM 인터페이스 구현 및 툴 콜링 기술 개요</h2></header><div class=entry-content><p>OpenClaw, Claude 데스크톱 앱, 혹은 로컬 기반의 여러 AI 에이전트들은 내부적으로 LLM(대형 언어 모델)과 어떻게 소통하고, 로컬 환경의 도구(Tool)들을 사용할까요? 이 글에서는 에이전트가 LLM과 인터페이스를 맺는 기술적 구현 내용과 핵심 요소들을 살펴봅니다.
1. 지침 파일(agent.md 등) 적용 방법 AI 에이전트의 페르소나, 역할, 기본 규칙을 정의하기 위해 주로 .md 형태의 지침 파일을 사용합니다. (예: agent.md, system_prompt.txt, SOUL.md 등)
기술적 구현: 이러한 지침 파일은 LLM에 전달되는 **시스템 프롬프트(System Prompt)**로 로드됩니다. 에이전트 프로그램이 실행될 때 혹은 세션이 시작될 때 파일 시스템에서 문서를 읽어 LLM의 system 역할(role) 메시지에 주입합니다.
...</p></div><footer class=entry-footer><span title='2026-02-21 00:00:00 +0900 KST'>February 21, 2026</span>&nbsp;·&nbsp;<span>Byung Kyu KIM</span></footer><a class=entry-link aria-label="post link to AI 에이전트(OpenClaw 등)의 LLM 인터페이스 구현 및 툴 콜링 기술 개요" href=https://cdecl.github.io/devops/ai-agent-openclaw-llm-interface/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>[AI 엔지니어링] 에이전트의 'Skills' 환상과 56%의 실패율: 왜 우리는 다시 시스템 프롬프트로 돌아가는가?</h2></header><div class=entry-content><p>최근 AI 개발자 커뮤니티, 특히 Vercel AI SDK와 Cursor 사용자들 사이에서 매우 흥미로운 화두가 던져졌습니다. Vercel의 소프트웨어 엔지니어 Jude Gao가 발표한 **"AGENTS.md outperforms skills in our agent evals"**라는 벤치마크 결과입니다.
많은 개발자가 프로젝트를 진행하며 직감적으로 느끼던 현상—“도구(Skills)를 쥐여주는 것보다, 그냥 문서를 통째로 읽게 시키는 게 훨씬 낫다”—가 실제 데이터로 증명되었습니다. 오늘은 이 벤치마크 데이터와 이를 둘러싼 ‘Skills vs Context vs Subagents’ 아키텍처의 변화를 심도 있게 분석해 봅니다.
1. 충격적인 데이터: 56%의 무시율 (Ignore Rate) 우리는 흔히 “LLM에게 도구(Tool/Skill/Function Calling)를 주면, 필요할 때마다 똑똑하게 꺼내 쓸 것"이라고 기대합니다. 하지만 Next.js 16 API(당시 미학습 데이터)를 대상으로 한 벤치마크 결과는 이 믿음을 배신했습니다.
...</p></div><footer class=entry-footer><span title='2026-01-30 00:00:00 +0900 KST'>January 30, 2026</span>&nbsp;·&nbsp;<span>Byung Kyu KIM</span></footer><a class=entry-link aria-label="post link to [AI 엔지니어링] 에이전트의 'Skills' 환상과 56%의 실패율: 왜 우리는 다시 시스템 프롬프트로 돌아가는가?" href=https://cdecl.github.io/posts/ai-agent-skills-vs-context/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>Gemini CLI와 Antigravity에서 antigravity-awesome-skills로 Agent Skills 강화하기</h2></header><div class=entry-content><p>서론 AI 에이전트의 능력을 한 단계 더 끌어올릴 수 있는 “Agent Skills"를 활용
이 글에서는 antigravity-awesome-skills라는 훌륭한 오픈소스 스킬셋을 Gemini CLI 및 Antigravity 환경에 설치하고, 적용하며, 테스트하는 방법과 유용한 스킬 예제 13가지를 소개합니다.
1. Antigravity Awesome Skills란 무엇인가? “Agent Skills"는 AI 에이전트에게 특정 작업을 수행하는 방법을 알려주는 작은 마크다운 파일 형식의 지침서입니다. 예를 들어, “API 문서를 작성해줘"라는 막연한 요청 대신, @api-documentation 스킬을 사용하여 정형화되고 일관된 형식의 문서를 생성하도록 지시할 수 있습니다.
...</p></div><footer class=entry-footer><span title='2026-01-25 00:00:00 +0900 KST'>January 25, 2026</span>&nbsp;·&nbsp;<span>Byung Kyu KIM</span></footer><a class=entry-link aria-label="post link to Gemini CLI와 Antigravity에서 antigravity-awesome-skills로 Agent Skills 강화하기" href=https://cdecl.github.io/devops/agent-skills-antigravity-gemini-guide/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>클라우드 2.0의 의의 - AI 시대를 위한 차세대 컴퓨팅</h2></header><div class=entry-content><p>클라우드 컴퓨팅은 IT 인프라의 핵심으로 자리 잡았지만, AI의 급속한 발전과 함께 새로운 진화 단계에 접어들고 있습니다. 클라우드 2.0은 이러한 변화의 중심에 있으며, 기존 클라우드의 한계를 넘어 더 지능적이고 분산된 형태로 발전하고 있습니다. 이 글에서는 온프레미스와 클라우드의 기본 정의 및 비교를 시작으로 클라우드 1.0과 2.0의 정의, 특징, 비교를 살펴보고, AI 시대에서 클라우드 2.0의 의의를 자세히 탐구
온프레미스와 클라우드의 정의 및 비교 온프레미스(On-Premises)와 클라우드 컴퓨팅은 IT 인프라를 구축하는 두 가지 주요 접근 방식입니다. 이 둘의 차이를 이해하는 것은 클라우드 2.0의 맥락을 파악하는 데 필수적입니다.
...</p></div><footer class=entry-footer><span title='2025-10-01 00:00:00 +0900 KST'>October 1, 2025</span>&nbsp;·&nbsp;<span>Byung Kyu KIM</span></footer><a class=entry-link aria-label="post link to 클라우드 2.0의 의의 - AI 시대를 위한 차세대 컴퓨팅" href=https://cdecl.github.io/devops/cloud-2/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>Obsidian Smart Composer - 내 모든 노트를 아는 AI 글쓰기 비서</h2></header><div class=entry-content><p>Obsidian은 강력한 노트 테이킹 앱이지만, 방대하게 쌓인 노트를 활용해 새로운 콘텐츠를 만드는 것은 종종 어려운 과제입니다. Obsidian Smart Composer는 이러한 문제를 해결하기 위해 등장한 플러그인으로, 내 볼트(Vault)의 모든 콘텐츠를 이해하는 개인 AI 비서처럼 작동합니다. 이 글에서는 Smart Composer의 핵심 기능과 함께, 실제 시나리오 기반의 효율적인 활용법을 자세히 알아보겠습니다.
Smart Composer란? Smart Composer(GitHub)는 Obsidian 내에서 AI를 활용하여 글쓰기 효율을 극대화하는 플러그인입니다. 단순히 ChatGPT를 연동하는 것을 넘어, 특정 노트나 폴더, 심지어 웹사이트와 유튜브 영상까지 ‘컨텍스트’로 참조하여 AI와 대화할 수 있습니다. 이를 통해 내 지식 기반 위에서 더욱 정확하고 맥락에 맞는 결과물을 얻을 수 있습니다.
...</p></div><footer class=entry-footer><span title='2025-07-24 00:00:00 +0900 KST'>July 24, 2025</span>&nbsp;·&nbsp;<span>Byung Kyu KIM</span></footer><a class=entry-link aria-label="post link to Obsidian Smart Composer - 내 모든 노트를 아는 AI 글쓰기 비서" href=https://cdecl.github.io/devops/obsidian-smart-composer-guide/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>Obsidian - Smart Connections 플러그인</h2></header><div class=entry-content><p>이 글에서는 Obsidian Smart Connections 플러그인의 개념부터 기능, 설정 방법, 주요 기능과 예제, 그리고 비슷한 플러그인까지 상세히 알아보겠습니다.
1. Obsidian Smart Connections 플러그인이란? Smart Connections는 Obsidian에서 AI 임베딩을 활용해 노트 간의 의미적 연결을 찾아주는 강력한 플러그인입니다. 사용자의 노트를 분석하여 관련된 콘텐츠를 실시간으로 추천하거나, 노트를 기반으로 대화형 AI와 상호작용할 수 있게 합니다. 블로그 작성, 연구, 지식 관리 등에서 생산성을 높여주며, 특히 대규모 노트 저장소에서 유용합니다.
주요 특징:
의미적 검색: 키워드가 아닌 노트의 의미를 기반으로 관련 노트를 찾아줍니다. 로컬 및 클라우드 AI 지원: Ollama, LM Studio 같은 로컬 모델과 OpenAI, Gemini, Claude 등 100개 이상의 API를 지원합니다. Smart Chat: 노트를 기반으로 AI와 대화하며 질문에 답변하거나 콘텐츠를 생성합니다. 컨텍스트 인식: 현재 노트나 선택한 텍스트를 활용해 관련 콘텐츠를 제안합니다. 오프라인 지원: 로컬 임베딩 모델을 사용해 데이터 프라이버시를 보장합니다. 2. 설치 및 설정 Smart Connections 플러그인은 Obsidian의 커뮤니티 플러그인 마켓에서 설치할 수 있습니다. 아래는 기본 설치 및 설정 방법입니다.
...</p></div><footer class=entry-footer><span title='2025-07-20 00:00:00 +0900 KST'>July 20, 2025</span>&nbsp;·&nbsp;<span>Byung Kyu KIM</span></footer><a class=entry-link aria-label="post link to Obsidian - Smart Connections 플러그인" href=https://cdecl.github.io/devops/obsidian-smart-connections-plugin/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>Obsidian Text Generator 플러그인 가이드 (selected_text, context)</h2></header><div class=entry-content><p>이 글에서는 Obsidian Text Generator 플러그인의 개념부터 기능, 설정 방법, 명령어, 예약어 사용법, 그리고 유용한 추가 기능까지 상세히 알아보겠습니다.
1. Obsidian Text Generator 플러그인이란? Obsidian Text Generator 플러그인은 Obsidian에서 AI를 활용해 텍스트를 생성하는 강력한 도구입니다. 노트 작성, 아이디어 생성, 콘텐츠 요약 등 다양한 작업을 자동화하여 생산성을 높여줍니다. 이 플러그인은 사용자가 선택한 텍스트나 노트의 컨텍스트를 기반으로 AI 모델을 통해 문장을 완성하거나 새로운 콘텐츠를 생성합니다.
주요 특징:
다양한 AI 지원: OpenAI(GPT-3, GPT-4), Google Gemini, Anthropic Claude, 그리고 LM Studio와 같은 로컬 모델을 지원합니다. 템플릿 엔진: 반복 작업을 간소화하는 사용자 정의 템플릿을 제공합니다. 컨텍스트 인식: 현재 노트, 선택한 텍스트, 링크된 노트를 활용해 문맥에 맞는 텍스트를 생성합니다. 커뮤니티 템플릿: 다른 사용자의 템플릿을 공유하거나 가져와 다양한 활용 사례를 탐색할 수 있습니다. 유연한 설정: Frontmatter를 통해 AI 모델, 토큰 수, 온도 등을 세부적으로 조정 가능합니다. 2. 설치 및 Gemini 기반 설정 Text Generator 플러그인은 Obsidian의 커뮤니티 플러그인 마켓에서 설치할 수 있습니다. Google Gemini를 사용한 설정 예시는 다음과 같습니다.
...</p></div><footer class=entry-footer><span title='2025-07-17 00:00:00 +0900 KST'>July 17, 2025</span>&nbsp;·&nbsp;<span>Byung Kyu KIM</span></footer><a class=entry-link aria-label="post link to Obsidian Text Generator 플러그인 가이드 (selected_text, context)" href=https://cdecl.github.io/devops/obsidian-text-generator-plugin/></a></article><footer class=page-footer><nav class=pagination><a class=next href=https://cdecl.github.io/tags/ai/page/2/>Next&nbsp;&nbsp;»</a></nav></footer></main><footer class=footer><span>&copy; 2026 <a href=https://cdecl.github.io/>cdeclog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");if(menu){const e=localStorage.getItem("menu-scroll-position");e&&(menu.scrollLeft=parseInt(e,10)),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}}document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{const e=document.querySelector("html");e.dataset.theme==="dark"?(e.dataset.theme="light",localStorage.setItem("pref-theme","light")):(e.dataset.theme="dark",localStorage.setItem("pref-theme","dark"))})</script></body></html>