<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>AI on cdeclog</title><link>https://cdecl.github.io/tags/ai/</link><description>Recent content in AI on cdeclog</description><generator>Hugo -- 0.157.0</generator><language>ko-kr</language><lastBuildDate>Wed, 25 Feb 2026 00:00:00 +0900</lastBuildDate><atom:link href="https://cdecl.github.io/tags/ai/index.xml" rel="self" type="application/rss+xml"/><item><title>2026 글로벌 LLM 생태계 비교: 파운데이션 모델부터 인프라 서비스까지</title><link>https://cdecl.github.io/devops/ai-models-comparison/</link><pubDate>Wed, 25 Feb 2026 00:00:00 +0900</pubDate><guid>https://cdecl.github.io/devops/ai-models-comparison/</guid><description>&lt;p&gt;2026년 현재 LLM 시장은 모델을 직접 학습시켜 배포하는 &lt;strong&gt;파운데이션 모델 제공자(Builders)&lt;/strong&gt; 와, 이 모델들을 기업 및 개발자가 쉽게 도입·최적화할 수 있도록 돕는 &lt;strong&gt;인프라 및 통합 서비스 제공자(Enablers)&lt;/strong&gt; 로 생태계가 양분되어 있습니다.&lt;/p&gt;
&lt;p&gt;북미의 프론티어 모델과 중국의 고효율 모델들이 치열하게 경쟁하는 가운데, Provider 관점에서 각 모델의 세부 특징과 인프라 서비스를 총정리합니다.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="1-파운데이션-모델-생태계-builders-북미-vs-중국"&gt;1. 파운데이션 모델 생태계 (Builders): 북미 vs 중국&lt;/h2&gt;
&lt;p&gt;LLM의 원천 지능을 제공하는 기업들입니다.&lt;br&gt;
북미는 범용적 에이전트와 멀티모달에, 중국은 극강의 가성비와 오픈소스 생태계에 집중하고 있습니다.&lt;/p&gt;</description></item><item><title>AI Agent 구현의 두 갈래: 일반 Tool Calling vs MCP 비교</title><link>https://cdecl.github.io/devops/ai-agent-tool-calling-vs-mcp/</link><pubDate>Mon, 23 Feb 2026 00:00:00 +0900</pubDate><guid>https://cdecl.github.io/devops/ai-agent-tool-calling-vs-mcp/</guid><description>&lt;p&gt;AI 에이전트를 구축할 때, LLM이 외부 도구를 사용하게 만드는 과정은 필수적입니다. 하지만 최근 등장한 **MCP(Model Context Protocol)**와 기존의 &lt;strong&gt;Function/Tool Calling&lt;/strong&gt;은 비슷해 보이면서도 구조적으로 큰 차이가 있습니다. 오늘은 이 두 방식의 특징과 실제 구현 관점에서의 차이를 상세히 비교해 보겠습니다.&lt;/p&gt;
&lt;h2 id="1-한눈에-보는-비교-요약"&gt;1. 한눈에 보는 비교 요약&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: left"&gt;구분&lt;/th&gt;
&lt;th style="text-align: left"&gt;일반 Tool Calling (기존 방식)&lt;/th&gt;
&lt;th style="text-align: left"&gt;MCP (Model Context Protocol)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: left"&gt;&lt;strong&gt;핵심 개념&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: left"&gt;함수 정의와 실행 로직의 수동 연결&lt;/td&gt;
&lt;td style="text-align: left"&gt;도구의 정의와 실행이 결합된 표준화된 서버&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left"&gt;&lt;strong&gt;실행 주체&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: left"&gt;에이전트 애플리케이션 (Local, Tightly Coupled)&lt;/td&gt;
&lt;td style="text-align: left"&gt;독립된 MCP 서버 (Remote/Isolated)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left"&gt;&lt;strong&gt;통신 규격&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: left"&gt;모델별 전용 API (OpenAI, Anthropic 등)&lt;/td&gt;
&lt;td style="text-align: left"&gt;&lt;strong&gt;JSON-RPC 2.0&lt;/strong&gt; 표준 프로토콜&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left"&gt;&lt;strong&gt;툴 목록 관리&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: left"&gt;코드에 하드코딩, 앱 재배포 필요&lt;/td&gt;
&lt;td style="text-align: left"&gt;서버에서 동적으로 &lt;code&gt;list_tools()&lt;/code&gt; 조회&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left"&gt;&lt;strong&gt;확장성&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: left"&gt;새 툴 추가 시 앱 코드 수정 및 재배포&lt;/td&gt;
&lt;td style="text-align: left"&gt;MCP 서버만 추가·재시작하면 즉시 연동&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left"&gt;&lt;strong&gt;상호운용성&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: left"&gt;모델별 규격 변환 코드 직접 작성 필요&lt;/td&gt;
&lt;td style="text-align: left"&gt;MCP 지원 클라이언트라면 어떤 모델이든 재사용&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left"&gt;&lt;strong&gt;컨텍스트 제공&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: left"&gt;주로 &amp;lsquo;액션(함수 호출)&amp;lsquo;에 집중&lt;/td&gt;
&lt;td style="text-align: left"&gt;툴 + &lt;strong&gt;리소스(파일, DB)&lt;/strong&gt; + &lt;strong&gt;프롬프트 템플릿&lt;/strong&gt; 패키지&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left"&gt;&lt;strong&gt;보안/격리&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: left"&gt;에이전트 프로세스 내에서 직접 실행&lt;/td&gt;
&lt;td style="text-align: left"&gt;실행 로직이 서버에 캡슐화, 권한 경계 명확&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;h2 id="2-일반-tool-calling-직접-요리하기-방식"&gt;2. 일반 Tool Calling: &amp;ldquo;직접 요리하기&amp;rdquo; 방식&lt;/h2&gt;
&lt;p&gt;일반적인 방식에서 에이전트는 요리사(LLM)가 준 레시피(JSON)를 보고 **직접 요리(함수 실행)**를 합니다.&lt;br&gt;
실행 로직이 에이전트 코드 내부에 깊게 박혀 있는 구조(Tightly Coupled)입니다.&lt;/p&gt;</description></item><item><title>AI 에이전트(OpenClaw 등)의 LLM 인터페이스 구현 및 툴 콜링 기술 개요</title><link>https://cdecl.github.io/devops/ai-agent-openclaw-llm-interface/</link><pubDate>Sat, 21 Feb 2026 00:00:00 +0900</pubDate><guid>https://cdecl.github.io/devops/ai-agent-openclaw-llm-interface/</guid><description>&lt;p&gt;OpenClaw, Claude 데스크톱 앱, 혹은 로컬 기반의 여러 AI 에이전트들은 내부적으로 LLM(대형 언어 모델)과 어떻게 소통하고, 로컬 환경의 도구(Tool)들을 사용할까요? 이 글에서는 에이전트가 LLM과 인터페이스를 맺는 기술적 구현 내용과 핵심 요소들을 살펴봅니다.&lt;/p&gt;
&lt;h2 id="1-지침-파일agentmd-등-적용-방법"&gt;1. 지침 파일(&lt;code&gt;agent.md&lt;/code&gt; 등) 적용 방법&lt;/h2&gt;
&lt;p&gt;AI 에이전트의 페르소나, 역할, 기본 규칙을 정의하기 위해 주로 &lt;code&gt;.md&lt;/code&gt; 형태의 지침 파일을 사용합니다. (예: &lt;code&gt;agent.md&lt;/code&gt;, &lt;code&gt;system_prompt.txt&lt;/code&gt;, &lt;code&gt;SOUL.md&lt;/code&gt; 등)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;기술적 구현:&lt;/strong&gt;
이러한 지침 파일은 LLM에 전달되는 **시스템 프롬프트(System Prompt)**로 로드됩니다. 에이전트 프로그램이 실행될 때 혹은 세션이 시작될 때 파일 시스템에서 문서를 읽어 LLM의 &lt;code&gt;system&lt;/code&gt; 역할(role) 메시지에 주입합니다.&lt;/p&gt;</description></item><item><title>[AI 엔지니어링] 에이전트의 'Skills' 환상과 56%의 실패율: 왜 우리는 다시 시스템 프롬프트로 돌아가는가?</title><link>https://cdecl.github.io/posts/ai-agent-skills-vs-context/</link><pubDate>Fri, 30 Jan 2026 00:00:00 +0900</pubDate><guid>https://cdecl.github.io/posts/ai-agent-skills-vs-context/</guid><description>&lt;p&gt;최근 AI 개발자 커뮤니티, 특히 Vercel AI SDK와 Cursor 사용자들 사이에서 매우 흥미로운 화두가 던져졌습니다. Vercel의 소프트웨어 엔지니어 Jude Gao가 발표한 **&amp;quot;&lt;a href="https://vercel.com/blog/agents-md-outperforms-skills-in-our-agent-evals"&gt;AGENTS.md outperforms skills in our agent evals&lt;/a&gt;&amp;quot;**라는 벤치마크 결과입니다.&lt;/p&gt;
&lt;p&gt;많은 개발자가 프로젝트를 진행하며 직감적으로 느끼던 현상—&amp;ldquo;도구(Skills)를 쥐여주는 것보다, 그냥 문서를 통째로 읽게 시키는 게 훨씬 낫다&amp;rdquo;—가 실제 데이터로 증명되었습니다. 오늘은 이 벤치마크 데이터와 이를 둘러싼 &amp;lsquo;Skills vs Context vs Subagents&amp;rsquo; 아키텍처의 변화를 심도 있게 분석해 봅니다.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="1-충격적인-데이터-56의-무시율-ignore-rate"&gt;1. 충격적인 데이터: 56%의 무시율 (Ignore Rate)&lt;/h2&gt;
&lt;p&gt;우리는 흔히 &amp;ldquo;LLM에게 도구(Tool/Skill/Function Calling)를 주면, 필요할 때마다 똑똑하게 꺼내 쓸 것&amp;quot;이라고 기대합니다. 하지만 Next.js 16 API(당시 미학습 데이터)를 대상으로 한 벤치마크 결과는 이 믿음을 배신했습니다.&lt;/p&gt;</description></item><item><title>Gemini CLI와 Antigravity에서 antigravity-awesome-skills로 Agent Skills 강화하기</title><link>https://cdecl.github.io/devops/agent-skills-antigravity-gemini-guide/</link><pubDate>Sun, 25 Jan 2026 00:00:00 +0900</pubDate><guid>https://cdecl.github.io/devops/agent-skills-antigravity-gemini-guide/</guid><description>&lt;h2 id="서론"&gt;서론&lt;/h2&gt;
&lt;p&gt;AI 에이전트의 능력을 한 단계 더 끌어올릴 수 있는 &amp;ldquo;Agent Skills&amp;quot;를 활용&lt;/p&gt;
&lt;p&gt;이 글에서는 &lt;code&gt;antigravity-awesome-skills&lt;/code&gt;라는 훌륭한 오픈소스 스킬셋을 Gemini CLI 및 Antigravity 환경에 설치하고, 적용하며, 테스트하는 방법과 유용한 스킬 예제 13가지를 소개합니다.&lt;/p&gt;
&lt;h2 id="1-antigravity-awesome-skills란-무엇인가"&gt;1. Antigravity Awesome Skills란 무엇인가?&lt;/h2&gt;
&lt;p&gt;&amp;ldquo;Agent Skills&amp;quot;는 AI 에이전트에게 특정 작업을 수행하는 방법을 알려주는 작은 마크다운 파일 형식의 지침서입니다. 예를 들어, &amp;ldquo;API 문서를 작성해줘&amp;quot;라는 막연한 요청 대신, &lt;code&gt;@api-documentation&lt;/code&gt; 스킬을 사용하여 정형화되고 일관된 형식의 문서를 생성하도록 지시할 수 있습니다.&lt;/p&gt;</description></item><item><title>클라우드 2.0의 의의 - AI 시대를 위한 차세대 컴퓨팅</title><link>https://cdecl.github.io/devops/cloud-2/</link><pubDate>Wed, 01 Oct 2025 00:00:00 +0900</pubDate><guid>https://cdecl.github.io/devops/cloud-2/</guid><description>&lt;p&gt;클라우드 컴퓨팅은 IT 인프라의 핵심으로 자리 잡았지만, AI의 급속한 발전과 함께 새로운 진화 단계에 접어들고 있습니다. 클라우드 2.0은 이러한 변화의 중심에 있으며, 기존 클라우드의 한계를 넘어 더 지능적이고 분산된 형태로 발전하고 있습니다. 이 글에서는 온프레미스와 클라우드의 기본 정의 및 비교를 시작으로 클라우드 1.0과 2.0의 정의, 특징, 비교를 살펴보고, AI 시대에서 클라우드 2.0의 의의를 자세히 탐구&lt;/p&gt;
&lt;h2 id="온프레미스와-클라우드의-정의-및-비교"&gt;온프레미스와 클라우드의 정의 및 비교&lt;/h2&gt;
&lt;p&gt;온프레미스(On-Premises)와 클라우드 컴퓨팅은 IT 인프라를 구축하는 두 가지 주요 접근 방식입니다. 이 둘의 차이를 이해하는 것은 클라우드 2.0의 맥락을 파악하는 데 필수적입니다.&lt;/p&gt;</description></item><item><title>Obsidian Smart Composer - 내 모든 노트를 아는 AI 글쓰기 비서</title><link>https://cdecl.github.io/devops/obsidian-smart-composer-guide/</link><pubDate>Thu, 24 Jul 2025 00:00:00 +0900</pubDate><guid>https://cdecl.github.io/devops/obsidian-smart-composer-guide/</guid><description>&lt;p&gt;Obsidian은 강력한 노트 테이킹 앱이지만, 방대하게 쌓인 노트를 활용해 새로운 콘텐츠를 만드는 것은 종종 어려운 과제입니다. Obsidian Smart Composer는 이러한 문제를 해결하기 위해 등장한 플러그인으로, 내 볼트(Vault)의 모든 콘텐츠를 이해하는 개인 AI 비서처럼 작동합니다. 이 글에서는 Smart Composer의 핵심 기능과 함께, 실제 시나리오 기반의 효율적인 활용법을 자세히 알아보겠습니다.&lt;/p&gt;
&lt;h2 id="smart-composer란"&gt;Smart Composer란?&lt;/h2&gt;
&lt;p&gt;Smart Composer(&lt;a href="https://github.com/glowingjade/obsidian-smart-composer"&gt;GitHub&lt;/a&gt;)는 Obsidian 내에서 AI를 활용하여 글쓰기 효율을 극대화하는 플러그인입니다. 단순히 ChatGPT를 연동하는 것을 넘어, 특정 노트나 폴더, 심지어 웹사이트와 유튜브 영상까지 &amp;lsquo;컨텍스트&amp;rsquo;로 참조하여 AI와 대화할 수 있습니다. 이를 통해 내 지식 기반 위에서 더욱 정확하고 맥락에 맞는 결과물을 얻을 수 있습니다.&lt;/p&gt;</description></item><item><title>Obsidian - Smart Connections 플러그인</title><link>https://cdecl.github.io/devops/obsidian-smart-connections-plugin/</link><pubDate>Sun, 20 Jul 2025 00:00:00 +0900</pubDate><guid>https://cdecl.github.io/devops/obsidian-smart-connections-plugin/</guid><description>&lt;p&gt;이 글에서는 Obsidian Smart Connections 플러그인의 개념부터 기능, 설정 방법, 주요 기능과 예제, 그리고 비슷한 플러그인까지 상세히 알아보겠습니다.&lt;/p&gt;
&lt;h3 id="1-obsidian-smart-connections-플러그인이란"&gt;1. Obsidian Smart Connections 플러그인이란?&lt;/h3&gt;
&lt;p&gt;Smart Connections는 Obsidian에서 AI 임베딩을 활용해 노트 간의 의미적 연결을 찾아주는 강력한 플러그인입니다. 사용자의 노트를 분석하여 관련된 콘텐츠를 실시간으로 추천하거나, 노트를 기반으로 대화형 AI와 상호작용할 수 있게 합니다. 블로그 작성, 연구, 지식 관리 등에서 생산성을 높여주며, 특히 대규모 노트 저장소에서 유용합니다.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;주요 특징&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;의미적 검색&lt;/strong&gt;: 키워드가 아닌 노트의 의미를 기반으로 관련 노트를 찾아줍니다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;로컬 및 클라우드 AI 지원&lt;/strong&gt;: Ollama, LM Studio 같은 로컬 모델과 OpenAI, Gemini, Claude 등 100개 이상의 API를 지원합니다.&lt;a href="https://github.com/brianpetro/obsidian-smart-connections"&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Smart Chat&lt;/strong&gt;: 노트를 기반으로 AI와 대화하며 질문에 답변하거나 콘텐츠를 생성합니다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;컨텍스트 인식&lt;/strong&gt;: 현재 노트나 선택한 텍스트를 활용해 관련 콘텐츠를 제안합니다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;오프라인 지원&lt;/strong&gt;: 로컬 임베딩 모델을 사용해 데이터 프라이버시를 보장합니다.&lt;a href="https://smartconnections.app/"&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="2-설치-및-설정"&gt;2. 설치 및 설정&lt;/h3&gt;
&lt;p&gt;Smart Connections 플러그인은 Obsidian의 커뮤니티 플러그인 마켓에서 설치할 수 있습니다. 아래는 기본 설치 및 설정 방법입니다.&lt;/p&gt;</description></item><item><title>Obsidian Text Generator 플러그인 가이드 (selected_text, context)</title><link>https://cdecl.github.io/devops/obsidian-text-generator-plugin/</link><pubDate>Thu, 17 Jul 2025 00:00:00 +0900</pubDate><guid>https://cdecl.github.io/devops/obsidian-text-generator-plugin/</guid><description>&lt;p&gt;이 글에서는 Obsidian Text Generator 플러그인의 개념부터 기능, 설정 방법, 명령어, 예약어 사용법, 그리고 유용한 추가 기능까지 상세히 알아보겠습니다.&lt;/p&gt;
&lt;h3 id="1-obsidian-text-generator-플러그인이란"&gt;1. Obsidian Text Generator 플러그인이란?&lt;/h3&gt;
&lt;p&gt;Obsidian Text Generator 플러그인은 Obsidian에서 AI를 활용해 텍스트를 생성하는 강력한 도구입니다. 노트 작성, 아이디어 생성, 콘텐츠 요약 등 다양한 작업을 자동화하여 생산성을 높여줍니다. 이 플러그인은 사용자가 선택한 텍스트나 노트의 컨텍스트를 기반으로 AI 모델을 통해 문장을 완성하거나 새로운 콘텐츠를 생성합니다.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;주요 특징&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;다양한 AI 지원&lt;/strong&gt;: OpenAI(GPT-3, GPT-4), Google Gemini, Anthropic Claude, 그리고 LM Studio와 같은 로컬 모델을 지원합니다.&lt;a href="https://www.obsidianstats.com/plugins/obsidian-textgenerator-plugin"&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;템플릿 엔진&lt;/strong&gt;: 반복 작업을 간소화하는 사용자 정의 템플릿을 제공합니다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;컨텍스트 인식&lt;/strong&gt;: 현재 노트, 선택한 텍스트, 링크된 노트를 활용해 문맥에 맞는 텍스트를 생성합니다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;커뮤니티 템플릿&lt;/strong&gt;: 다른 사용자의 템플릿을 공유하거나 가져와 다양한 활용 사례를 탐색할 수 있습니다.&lt;a href="https://github.com/nhaouari/obsidian-textgenerator-plugin"&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;유연한 설정&lt;/strong&gt;: Frontmatter를 통해 AI 모델, 토큰 수, 온도 등을 세부적으로 조정 가능합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="2-설치-및-gemini-기반-설정"&gt;2. 설치 및 Gemini 기반 설정&lt;/h3&gt;
&lt;p&gt;Text Generator 플러그인은 Obsidian의 커뮤니티 플러그인 마켓에서 설치할 수 있습니다. Google Gemini를 사용한 설정 예시는 다음과 같습니다.&lt;/p&gt;</description></item><item><title>MCP-SuperAssistant 사용법</title><link>https://cdecl.github.io/dev/superassistant/</link><pubDate>Tue, 24 Jun 2025 00:00:00 +0900</pubDate><guid>https://cdecl.github.io/dev/superassistant/</guid><description>&lt;h2 id="model-context-pro"&gt;Model Context Pro&lt;/h2&gt;
&lt;p&gt;**Model Context Pro&lt;/p&gt;
&lt;h2 id="mcp-superassistant란"&gt;MCP-SuperAssistant란?&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;MCP-SuperAssistant&lt;/strong&gt;는 MCP를 활용해 AI 플랫폼(ChatGPT, Perplexity, Google Gemini, Grok 등)과 외부 데이터 및 도구를 연결하는 크롬 확장 프로그램입니다. 이 도구는 AI 대화 내에서 MCP 도구 호출을 감지하고, 실행 결과를 자동 또는 수동으로 대화에 삽입하여 워크플로우를 간소화합니다. MCP-SuperAssistant는 다양한 AI 플랫폼과의 호환성과 유연한 설정을 통해 개발자와 비즈니스 사용자의 생산성을 극대화합니다.&lt;/p&gt;
&lt;h3 id="mcp-superassistant의-주요-기능"&gt;MCP-SuperAssistant의 주요 기능&lt;/h3&gt;
&lt;p&gt;MCP-SuperAssistant는 다음과 같은 기능을 제공합니다:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;다양한 AI 플랫폼 지원&lt;/strong&gt;: ChatGPT, Perplexity, Google Gemini, Grok, Google AI Studio, OpenRouter, DeepSeek 등에서 MCP 도구 실행 가능&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;MCP 도구 실행 및 결과 삽입&lt;/strong&gt;: AI 대화 내 도구 호출을 감지해 실행하고 결과를 대화에 삽입&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;실시간 데이터 연결&lt;/strong&gt;: MCP를 통해 콘텐츠 저장소, 비즈니스 앱, 개발 환경 등과 안전하게 연결&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;자동/수동 모드&lt;/strong&gt;: 자동 모드(도구 실행 및 결과 제출 자동화)와 수동 모드(사용자 제어) 지원&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;확장성과 모듈성&lt;/strong&gt;: 플러그인 기반 아키텍처로 새로운 플랫폼 및 도구 추가 가능, WebSocket 및 SSE 지원&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;보안 및 접근성&lt;/strong&gt;: 복잡한 API 키 설정 없이 기존 AI 구독 활용, 최소 설정으로 사용 가능&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;6000+ MCP 서버 지원&lt;/strong&gt;: 다양한 MCP 서버와 통합해 AI 워크플로우 강화&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;특징&lt;/strong&gt;: 확장 프로그램은 간단한 설치로 즉시 사용 가능하며, 샌드박스 환경에서 실행되어 보안성을 유지합니다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;제약사항&lt;/strong&gt;: 일부 복잡한 도구 호출은 MCP 서버 설정이 필요하며, AI 모델의 프롬프트 이해도에 따라 결과 정확도가 달라질 수 있습니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="초기-설치-및-세팅-실행-준비"&gt;초기 설치 및 세팅, 실행 준비&lt;/h2&gt;
&lt;p&gt;MCP-SuperAssistant를 사용하려면 크롬 확장 프로그램 설치와 MCP 프록시 서버 설정이 필요합니다. 아래는 단계별 설치 및 실행 준비 과정입니다.&lt;/p&gt;</description></item><item><title>Gemini CLI의 MCP(Model Context Pro</title><link>https://cdecl.github.io/dev/gemini-cli-mcp-101/</link><pubDate>Mon, 23 Jun 2025 00:00:00 +0900</pubDate><guid>https://cdecl.github.io/dev/gemini-cli-mcp-101/</guid><description>&lt;p&gt;Gemini CLI의 MCP(Model Context Pro&lt;/p&gt;
&lt;h2 id="model-context-pro"&gt;Model Context Pro&lt;/h2&gt;
&lt;p&gt;**Model Context Pro&lt;/p&gt;
&lt;h2 id="gemini-cli와-mcp-지원-개요"&gt;Gemini CLI와 MCP 지원 개요&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Gemini CLI&lt;/strong&gt;는 Google의 생성형 AI 모델인 Gemini를 터미널에서 활용할 수 있는 오픈소스 도구로, MCP를 통해 내장 및 외부 도구와의 통합을 지원합니다. MCP를 활용하면 Gemini CLI는 파일 시스템 작업, 웹 검색, 버전 관리 시스템(Git 등)과의 연동, 또는 사용자 정의 API와의 상호작용과 같은 다양한 기능을 수행할 수 있습니다. Gemini CLI는 MCP를 통해 모델의 컨텍스트를 확장하여 복잡한 작업을 처리하거나, 외부 시스템과의 실시간 데이터 교환을 가능하게 합니다.&lt;/p&gt;</description></item><item><title>Gemini CLI 툴 소개</title><link>https://cdecl.github.io/dev/gemini-cli/</link><pubDate>Sun, 22 Jun 2025 00:00:00 +0900</pubDate><guid>https://cdecl.github.io/dev/gemini-cli/</guid><description>&lt;p&gt;Gemini CLI 툴: VSCode 플러그인과의 차이, 활용법, 실전 시나리오&lt;/p&gt;
&lt;h2 id="gemini-cli-이란"&gt;Gemini CLI 이란?&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Gemini CLI&lt;/strong&gt;는 Google의 생성형 AI 모델인 Gemini를 터미널 환경에서 직접 사용할 수 있도록 지원하는 커맨드라인 도구입니다. 이 도구를 활용하여 코드 생성, 요약, 번역, 문서화 등 다양한 AI 기능을 명령어 한 줄로 빠르게 수행할 수 있습니다. 특히, 별도의 통합 개발 환경(IDE) 없이도 쉘 스크립트, 자동화, 지속적 통합(CI)과 같은 다양한 환경에서 AI 기능을 활용할 수 있다는 점이 큰 특징입니다. Gemini CLI는 또한 **mcp(Model Context Pro&lt;/p&gt;</description></item><item><title>MCP 101</title><link>https://cdecl.github.io/dev/mcp-101/</link><pubDate>Thu, 10 Apr 2025 00:00:00 +0900</pubDate><guid>https://cdecl.github.io/dev/mcp-101/</guid><description>&lt;p&gt;Model Context Pro&lt;/p&gt;
&lt;h2 id="mcp-101-model-context-pro"&gt;MCP 101: Model Context Pro&lt;/h2&gt;
&lt;p&gt;Model Context Pro&lt;/p&gt;
&lt;h2 id="1-mcp란-무엇인가"&gt;1. MCP란 무엇인가?&lt;/h2&gt;
&lt;p&gt;MCP(Model Context Pro&lt;/p&gt;
&lt;h3 id="주요-기능"&gt;주요 기능&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;동적 도구 탐색&lt;/strong&gt;: 도구가 JSON 메타데이터로 자신의 기능을 제공하여 AI가 자동으로 이해하고 활용.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;양방향 통신&lt;/strong&gt;: WebSocket 또는 SSE(Server-Sent Events)를 통해 실시간 상호작용 지원.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;AI 중심 설계&lt;/strong&gt;: AI의 의도(intent)를 기반으로 적합한 도구를 동적으로 호출.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="사용-시기"&gt;사용 시기&lt;/h3&gt;
&lt;p&gt;MCP는 다음과 같은 경우에 적합합니다:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;AI가 외부 리소스(예: GitHub, Google Drive)에 접근하거나 작업을 수행할 때.&lt;/li&gt;
&lt;li&gt;새로운 도구를 동적으로 추가하거나 복잡한 워크플로우를 자동화할 때.&lt;/li&gt;
&lt;li&gt;예: AI가 &amp;ldquo;파일을 읽고 Slack에 공유&amp;quot;하거나 &amp;ldquo;GitHub에서 코드 검색&amp;quot;하는 작업.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="2-mcp와-다른-api의-차이점"&gt;2. MCP와 다른 API의 차이점&lt;/h2&gt;
&lt;p&gt;MCP는 REST API, SOAP와 비교해 AI 중심의 유연성을 제공합니다. 아래는 셀프 디스크립션(self-description)을 중심으로 주요 차이점입니다.&lt;/p&gt;</description></item></channel></rss>