<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Ollama on cdeclog</title><link>https://cdecl.github.io/tags/ollama/</link><description>Recent content in Ollama on cdeclog</description><generator>Hugo -- 0.155.0</generator><language>ko-kr</language><lastBuildDate>Sat, 27 Jan 2024 00:00:00 +0900</lastBuildDate><atom:link href="https://cdecl.github.io/tags/ollama/index.xml" rel="self" type="application/rss+xml"/><item><title>Ollama를 이용한 Mistral 로컬 실행 가이드</title><link>https://cdecl.github.io/devops/ollama-mistral/</link><pubDate>Sat, 27 Jan 2024 00:00:00 +0900</pubDate><guid>https://cdecl.github.io/devops/ollama-mistral/</guid><description>&lt;p&gt;ollama, ollama-webui, mistral 설치 및 테스트&lt;/p&gt;
&lt;h2 id="ollama"&gt;Ollama&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;OLLAMA는 Open Large Language Model for AI Applications의 약자로, Google AI에서 개발한 대규모 언어 모델 (LLM)입니다.
OLLAMA는 텍스트 생성, 번역, 질문 응답 등 다양한 AI 애플리케이션 개발을 위해 사용할 수 있는 강력한 도구&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;다양한 기능: OLLAMA는 텍스트 생성, 번역, 질문 응답, 요약, 코드 생성 등 다양한 기능을 제공합니다.&lt;/li&gt;
&lt;li&gt;강력한 성능: OLLAMA는 Google AI의 최첨단 기술을 기반으로 개발되어 강력한 성능을 제공합니다.&lt;/li&gt;
&lt;li&gt;쉬운 사용: OLLAMA는 Python API를 제공하여 쉽게 사용할 수 있습니다.&lt;/li&gt;
&lt;li&gt;다양한 모델: OLLAMA는 다양한 크기와 기능을 가진 모델을 제공하여 사용자의 필요에 맞게 선택할 수 있습니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="ollama-설치"&gt;Ollama 설치&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;다운로드 : &lt;a href="https://ollama.ai/download"&gt;https://ollama.ai/download&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;
&lt;li&gt;설치 및 활용 가능한 모델 : &lt;a href="https://ollama.ai/library"&gt;https://ollama.ai/library&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none;"&gt;&lt;code class="language-sh" data-lang="sh"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;$ ollama
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;Usage:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; ollama &lt;span style="color:#ff79c6"&gt;[&lt;/span&gt;flags&lt;span style="color:#ff79c6"&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; ollama &lt;span style="color:#ff79c6"&gt;[&lt;/span&gt;command&lt;span style="color:#ff79c6"&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;Available Commands:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; serve Start ollama
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; create Create a model from a Modelfile
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; show Show information &lt;span style="color:#ff79c6"&gt;for&lt;/span&gt; a model
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; run Run a model
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; pull Pull a model from a registry
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; push Push a model to a registry
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; list List models
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; cp Copy a model
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; rm Remove a model
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#8be9fd;font-style:italic"&gt;help&lt;/span&gt; Help about any &lt;span style="color:#8be9fd;font-style:italic"&gt;command&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;Flags:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; -h, --help &lt;span style="color:#8be9fd;font-style:italic"&gt;help&lt;/span&gt; &lt;span style="color:#ff79c6"&gt;for&lt;/span&gt; ollama
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; -v, --version Show version information
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;Use &lt;span style="color:#f1fa8c"&gt;&amp;#34;ollama [command] --help&amp;#34;&lt;/span&gt; &lt;span style="color:#ff79c6"&gt;for&lt;/span&gt; more information about a command.
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id="mistral-모델-설치"&gt;mistral 모델 설치&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://ollama.ai/library/mistral"&gt;https://ollama.ai/library/mistral&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Mistral은 최근에 개발된 대형 언어 모델 중 하나입니다.
이 모델은 7.3 billion 개의 파라미터를 가지고 있으며, 자연어 처리 분야에서 매우 높은 성능을 보입니다.
Mistral은 다양한 자연어 처리 작업에서 사용될 수 있습니다.
예를 들어, 이 모델은 텍스트 생성, 기계 번역, 질문 응답, 감성 분석 등의 작업에 사용될 수 있습니다.&lt;/p&gt;</description></item></channel></rss>